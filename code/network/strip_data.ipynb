{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "realistic-senate",
   "metadata": {},
   "source": [
    "# Load and strip the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noticed-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "from bcrypt import gensalt, hashpw\n",
    "\n",
    "# parallelisation functionality\n",
    "from multiprocess import Pool\n",
    "import psutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empty-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/original/Grunddaten-Simulation\"\n",
    "dst = \"../../data/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "northern-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_id(ID):\n",
    "    hashed_id = hashpw(str(ID).encode('utf-8'), salt=salt)\n",
    "    return hashed_id[29:].decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "important-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hashing the student and lecturer IDs\n",
    "salt = gensalt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "honey-mount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'$2b$12$moTL.FsFqoZnhSFv7vjkme'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-prince",
   "metadata": {},
   "source": [
    "## Students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-rotation",
   "metadata": {},
   "source": [
    "File `Studiendaten.csv`, sample stored in `studies_P.csv`\n",
    "* `ST_PERSON_NR`: rename to `student_id`, hash\n",
    "* `STUDIENIDENTIFIKATOR`: rename to `study_id`\n",
    "* `STUDIENBEZEICHNUNG`: rename to `study_name`\n",
    "* `SEMESTERANZAHL`: rename to `term_number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "worth-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24475/24475 [10:14<00:00, 39.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# List of studies for every student. A student can have more than one study,\n",
    "# which will show up as separate entries (row) for the same student_id. Each\n",
    "# study also has a term number, i.e. the number of semesters the student has\n",
    "# been enrolled in the given study.\n",
    "df = pd.read_csv(join(src, 'Studiendaten.csv'), encoding='latin_1')\n",
    "df = df.rename(columns={\n",
    "    'ST_PERSON_NR':'student_id', # unique student identifier\n",
    "    'STUDIENIDENTIFIKATOR':'study_id', # unique study identifier\n",
    "    'STUDIENBEZEICHNUNG':'study_name', # (german) name of the study\n",
    "    'SEMESTERANZAHL':'term_number' # number of terms a student has been enrolled\n",
    "})\n",
    "\n",
    "# hash student IDs with the given salt\n",
    "hashed_IDs = []\n",
    "pool = Pool(12)\n",
    "for hashed_ID in tqdm(\n",
    "        pool.imap_unordered(func=hash_id, iterable=df[\"student_id\"]),\n",
    "        total=len(df[\"student_id\"])\n",
    "    ):\n",
    "    hashed_IDs.append(hashed_ID)\n",
    "    \n",
    "df[\"student_id\"] = hashed_IDs   \n",
    "df.to_csv(join(dst, \"students.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-intent",
   "metadata": {},
   "source": [
    "## Lecturers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-fireplace",
   "metadata": {},
   "source": [
    "File `Bedienstete_mit_DV_an_Org.csv` (Organisationseinheiten), sample stored in `organisations_P.csv`\n",
    "* `PERSON_NR`: rename to `lecturer_id`, hash\n",
    "* `ORG_NR`: rename to `organisation_id`\n",
    "* `TUG_NEW.PUORG.GETNAME(A.ORG_NR)`: rename to `organisation_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "featured-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5707/5707 [02:22<00:00, 40.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Mapping of lecturers to organisations (institute, faculty). A lecturer can\n",
    "# be associated with more than one organisation.\n",
    "df = pd.read_csv(join(src, 'Bedienstete_mit_DV_an_Org.csv'),\n",
    "                            encoding='latin_1')\n",
    "df = df.rename(columns={\n",
    "    'PERSON_NR':'lecturer_id', # unique lecturer id\n",
    "    'ORG_NR':'organisation_id', # unique organisation id\n",
    "    'TUG_NEW.PUORG.GETNAME(A.ORG_NR)':'organisation_name' # German organisation name\n",
    "})\n",
    "\n",
    "# hash lecturer IDs with the given salt\n",
    "hashed_IDs = []\n",
    "pool = Pool(12)\n",
    "for hashed_ID in tqdm(\n",
    "        pool.imap_unordered(func=hash_id, iterable=df[\"lecturer_id\"]),\n",
    "        total=len(df[\"lecturer_id\"])\n",
    "    ):\n",
    "    hashed_IDs.append(hashed_ID)\n",
    "    \n",
    "df[\"lecturer_id\"] = hashed_IDs\n",
    "df.to_csv(join(dst, \"lecturers.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-polls",
   "metadata": {},
   "source": [
    "## Courses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-luxury",
   "metadata": {},
   "source": [
    "File `LV_cleaned.csv`, sample stored in `courses.csv`\n",
    "* `STP_SP_NR`: rename to `lecture_id`\n",
    "* `STP_SP_LVNR`: drop\n",
    "* `SJ_NAME`: drop\n",
    "* `SEMESTER_KB`: drop\n",
    "* `STP_SP_TITEL`: drop\n",
    "* `STP_SP_TITEL_ENGL`: rename to `course_name`\n",
    "* `STP_SP_SST`: drop\n",
    "* `STP_LV_ART_KURZ`: rename to `course_type`, provide dictionary\n",
    "* `STP_LV_ART_NAME`: drop\n",
    "* `BETREUENDE_ORG_NR`: drop\n",
    "* `BETREUENDE_ORG_NAME`: drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "operational-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lectures was manually cleaned, since for some rows, the entries starting\n",
    "# from the column STP_LV_ART_KURZ were shifted to the right by one column\n",
    "\n",
    "# list of lectures with information about their type, their name, their module\n",
    "# (this is only relevant for how studies are composed at TU Graz) and the \n",
    "# organisational unit (institute, faculty) which is responsible for the lecture.\n",
    "df = pd.read_csv(join('../../data/cleaned', 'LV_cleaned.csv'), encoding=\"utf-8\")\n",
    "df = df.rename(columns={\n",
    "    'STP_SP_NR':'course_id', # unique course id\n",
    "    'STP_SP_TITEL_ENGL':'course_name', # english lecture name\n",
    "    'STP_LV_ART_KURZ':'course_type', # type of the lecture (tutorial, lab, ...)\n",
    "})\n",
    "df = df.drop(columns=[\n",
    "    \"SJ_NAME\",\n",
    "    \"SEMESTER_KB\",\n",
    "    \"STP_SP_SST\",\n",
    "    \"STP_LV_ART_NAME\",\n",
    "    \"STP_SP_TITEL\",\n",
    "    'STP_SP_LVNR',\n",
    "    'BETREUENDE_ORG_NR',\n",
    "    'BETREUENDE_ORG_NAME',\n",
    "    \"Unnamed: 11\"\n",
    "])\n",
    "df.to_csv(join(dst, \"courses.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-handy",
   "metadata": {},
   "source": [
    "## Course enrollment by students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-sitting",
   "metadata": {},
   "source": [
    "File `Studierende_pro_LV_mit_Idf.csv`, sample stored in `course_enrollment.csv`\n",
    "* `ST_PERSON_NR`: rename to `student_id`, hash\n",
    "* `STUDIENIDENTIFIKATOR`: rename to `study_id`\n",
    "* `STP_SP_NR`: rename to `course_id`\n",
    "* `LV_GRP_NR`: rename to `group_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "killing-tractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85505/85505 [36:15<00:00, 39.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# List of enrolled lectures of the WiSe 2019/20 for every student. A lecture\n",
    "# can have several groups (for example for tutorial parts). The group\n",
    "# identifier is also listed for every student. It is not completely unique\n",
    "# as there are a number of overlapping groups (for example same time, \n",
    "# different rooms). These are disambiguated at a later point in the data\n",
    "# cleaning process.\n",
    "# The data also includes the identifier of the study through which the \n",
    "# student enrolled in a given lecture. \n",
    "df = pd.read_csv(join(src, 'Studierende_pro_LV_mit_Idf.csv'))\n",
    "df = df.rename(columns={\n",
    "    'ST_PERSON_NR':'student_id', # unique student identifier\n",
    "    'STUDIENIDENTIFIKATOR':'study_id', # unique study identifier\n",
    "    'STP_SP_NR':'course_id', # unique course identifier\n",
    "    'LV_GRP_NR':'group_id', # (almost) unique group identifier \n",
    "    }) \n",
    "\n",
    "# hash student IDs with the given salt\n",
    "hashed_IDs = []\n",
    "pool = Pool(12)\n",
    "for hashed_ID in tqdm(\n",
    "        pool.imap_unordered(func=hash_id, iterable=df[\"student_id\"]),\n",
    "        total=len(df[\"student_id\"])\n",
    "    ):\n",
    "    hashed_IDs.append(hashed_ID)\n",
    "    \n",
    "df[\"student_id\"] = hashed_IDs   \n",
    "df.to_csv(join(dst, \"course_enrollment.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-president",
   "metadata": {},
   "source": [
    "## Exam enrollment by students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-statistics",
   "metadata": {},
   "source": [
    "File `Prüfungen-2.csv`, sample stored in `exam_students_P.csv`: \n",
    "* `PV_TERM_NR`: rename to `exam_id`\n",
    "* `PRUEFUNGSDATUM`: drop\n",
    "* `ST_PERSON_NR`: rename to `student_id`, hash\n",
    "* `STUDIENIDENTIFIKATOR`: rename to `study_id`\n",
    "* `STP_SP_NR`: rename to `course_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "magnetic-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57815/57815 [24:12<00:00, 39.79it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(join(src, 'Prüfungen-2.csv'), encoding='latin_1')\n",
    "df = df.rename(columns={\n",
    "    'PV_TERM_NR':'exam_id',\n",
    "    'ST_PERSON_NR':'student_id',\n",
    "    'STUDIENIDENTIFIKATOR':'study_id',\n",
    "    'STP_SP_NR':'course_id'})\n",
    "\n",
    "df = df.drop(columns=[\n",
    "    'PRUEFUNGSDATUM'\n",
    "])\n",
    "\n",
    "# hash student IDs with the given salt\n",
    "hashed_IDs = []\n",
    "pool = Pool(12)\n",
    "for hashed_ID in tqdm(\n",
    "        pool.imap_unordered(func=hash_id, iterable=df[\"student_id\"]),\n",
    "        total=len(df[\"student_id\"])\n",
    "    ):\n",
    "    hashed_IDs.append(hashed_ID)\n",
    "\n",
    "df[\"student_id\"] = hashed_IDs\n",
    "df.to_csv(join(dst, \"exam_enrollment.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-flood",
   "metadata": {},
   "source": [
    "## Course supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-finder",
   "metadata": {},
   "source": [
    "File `Lehrende.csv`, sample stored in `lecturers_P.csv`\n",
    "* `PERSON_NR`: rename to `lecturer_id`, hash\n",
    "* `STP_SP_NR`: rename to `course_id`\n",
    "* `LV_GRP_NR`: rename to `group_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lecturers which are responsible for lectures and groups within\n",
    "# lectures. Similar to the list of students, the group_id is disambiguated\n",
    "# later in the data cleaning process\n",
    "df = pd.read_csv(join(src, 'Lehrende.csv'))\n",
    "df = df.rename(columns={\n",
    "    'PERSON_NR':'lecturer_id', # unique lecturer id\n",
    "    'STP_SP_NR':'course_id', # unique lecture id\n",
    "    'LV_GRP_NR':'group_id'# (almost) unique group id\n",
    "})\n",
    "\n",
    "# hash lecturer IDs with the given salt\n",
    "hashed_IDs = []\n",
    "pool = Pool(12)\n",
    "for hashed_ID in tqdm(\n",
    "        pool.imap_unordered(func=hash_id, iterable=df[\"lecturer_id\"]),\n",
    "        total=len(df[\"lecturer_id\"])\n",
    "    ):\n",
    "    hashed_IDs.append(hashed_ID)\n",
    "    \n",
    "df[\"lecturer_id\"] = hashed_IDs\n",
    "df.to_csv(join(dst, \"course_supervision.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-success",
   "metadata": {},
   "source": [
    "## Exam supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-planning",
   "metadata": {},
   "source": [
    "File `Prüfungstermine_mit_Räumen.csv`, sample stored in `exam_dates_P.csv`:\n",
    "* `PV_TERM_NR`: rename to `exam_id`\n",
    "* `PERSON_NR`: rename to `lecturer_id`, hash\n",
    "* `DATUM`: drop\n",
    "* `BEGINNZEIT`: drop\n",
    "* `ENDEZEIT`: drop\n",
    "* `RES_NR`: drop\n",
    "* `STP_SP_NR`: rename to `course_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "regular-authorization",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5633/5633 [02:22<00:00, 39.63it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(join(src, 'Prüfungstermine_mit_Räumen.csv'), encoding='latin_1',\n",
    "                     parse_dates=['DATUM'], dayfirst=True)\n",
    "df = df.rename(columns={\n",
    "    'PV_TERM_NR':'exam_id',\n",
    "    'PERSON_NR':'lecturer_id',\n",
    "    'STP_SP_NR':'course_id'})\n",
    "\n",
    "df = df.drop(columns=[\n",
    "    'DATUM',\n",
    "    'BEGINNZEIT',\n",
    "    'ENDEZEIT',\n",
    "    'RES_NR',\n",
    "])\n",
    "\n",
    "# hash lecturer IDs with the given salt\n",
    "hashed_IDs = []\n",
    "pool = Pool(12)\n",
    "for hashed_ID in tqdm(\n",
    "        pool.imap_unordered(func=hash_id, iterable=df[\"lecturer_id\"]),\n",
    "        total=len(df[\"lecturer_id\"])\n",
    "    ):\n",
    "    hashed_IDs.append(hashed_ID)\n",
    "    \n",
    "df[\"lecturer_id\"] = hashed_IDs\n",
    "df.to_csv(join(dst, \"exam_supervision.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-buyer",
   "metadata": {},
   "source": [
    "## Course dates and rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-scanning",
   "metadata": {},
   "source": [
    "File `Termine_mit_LV Bezug.csv`, sample stored in `dates.csv`\n",
    "* `RES_NR`: rename to `room_id`\n",
    "* `DATUM_AM`: rename to `date`\n",
    "* `ZEIT_VON`: rename to `start_time`\n",
    "* `ZEIT_BIS`: rename to `end_time`\n",
    "* `STP_SP_NR`: rename to `course_id`\n",
    "* `LV_GRP_NR`: rename to `group_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "relevant-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events (start time, end time, room) for every lecture and group in WiSe 2019/20\n",
    "df = pd.read_csv(join(src, 'Termine_mit_LV Bezug.csv'),\n",
    "                parse_dates=['DATUM_AM', 'ZEIT_VON', 'ZEIT_BIS'], dayfirst=True)\n",
    "df = df.rename(columns={\n",
    "    'RES_NR':'room_id', # unique room id\n",
    "    'DATUM_AM':'date', # date\n",
    "    'ZEIT_VON':'start_time', # start time\n",
    "    'ZEIT_BIS':'end_time', # end time\n",
    "    'STP_SP_NR':'course_id', # unique lecture id\n",
    "    'LV_GRP_NR':'group_id'# (almost) unique group id\n",
    "})\n",
    "df.to_csv(join(dst, \"course_dates.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-leeds",
   "metadata": {},
   "source": [
    "## Exam dates and rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-fairy",
   "metadata": {},
   "source": [
    "File `Prüfungstermine_mit_Räumen.csv`, sample stored in `exam_dates_P.csv`:\n",
    "* `PV_TERM_NR`: rename to `exam_id`\n",
    "* `PERSON_NR`: drop\n",
    "* `DATUM`: rename to `date`\n",
    "* `BEGINNZEIT`: rename to `start_time`\n",
    "* `ENDEZEIT`: rename to `end_time`\n",
    "* `RES_NR`: rename to `room_id`\n",
    "* `STP_SP_NR`: rename to `course_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "casual-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5633/5633 [02:22<00:00, 39.63it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(join(src, 'Prüfungstermine_mit_Räumen.csv'), encoding='latin_1',\n",
    "                     parse_dates=['DATUM'], dayfirst=True)\n",
    "df = df.rename(columns={\n",
    "    'PV_TERM_NR':'exam_id',\n",
    "    'DATUM':'date',\n",
    "    'BEGINNZEIT':'start_time',\n",
    "    'ENDEZEIT':'end_time',\n",
    "    'RES_NR':'room_id',\n",
    "    'STP_SP_NR':'course_id'})\n",
    "\n",
    "df = df.drop(columns=[\n",
    "    'PERSON_NR',\n",
    "])\n",
    "\n",
    "# hash lecturer IDs with the given salt\n",
    "hashed_IDs = []\n",
    "pool = Pool(12)\n",
    "for hashed_ID in tqdm(\n",
    "        pool.imap_unordered(func=hash_id, iterable=df[\"lecturer_id\"]),\n",
    "        total=len(df[\"lecturer_id\"])\n",
    "    ):\n",
    "    hashed_IDs.append(hashed_ID)\n",
    "    \n",
    "df[\"lecturer_id\"] = hashed_IDs\n",
    "df.to_csv(join(dst, \"exam_dates.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-adventure",
   "metadata": {},
   "source": [
    "## Rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-immunology",
   "metadata": {},
   "source": [
    "File `Räume_cleaned.csv`, sample stored in `rooms.csv`\n",
    "* `RES_NR`: rename to `room_id`\n",
    "* `RAUM_CODE`: drop\n",
    "* `RAUM_ZUSATZBEZEICHNUNG`: drop\n",
    "* `RAUM_SITZPLAETZE`: rename to `seats`, impute\n",
    "* `QUADRATMETER`: remame to `area`, impute\n",
    "* `RAUM_GEBAEUDE_BEREICH_NAME`: rename to `campus`\n",
    "* `STRASSE`: rename to `address`, convert to longitude & latitude\n",
    "* `PLZ`: rename to `postal_code`\n",
    "* `ORT`: rename to `city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fewer-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of rooms and information about them (number of seats, square meters).\n",
    "# TU Graz has three campuses: Alte Technik, Neue Technik and Inffeldgasse. The\n",
    "# mapping of every room to a campus is also stored.\n",
    "\n",
    "# Information for rooms outside TU Graz premises was missing. Jana Lasser \n",
    "# manually searched for and filled in room information for rooms at Uni Graz \n",
    "# and added the information to the file /data/raw/Räume.csv. The updated file \n",
    "# is stored in /data/cleaned/Räume_cleaned.csv. These rooms are excluded from\n",
    "# the further analysis anyways though.\n",
    "\n",
    "df = pd.read_csv(join('../../data/cleaned', 'Räume_cleaned.csv'), \n",
    "                    encoding='latin_1')\n",
    "df = df.rename(columns={\n",
    "    'RES_NR':'room_id', # unique room id\n",
    "    'RAUM_SITZPLAETZE':'seats', # number of seats in the room\n",
    "    'QUADRATMETER':'area', # number of square meters in the room\n",
    "    'RAUM_GEBAEUDE_BEREICH_NAME':'campus', # campus where the room is located\n",
    "    'STRASSE':'address',\n",
    "    'PLZ':'postal_code',\n",
    "    'ORT':'city',\n",
    "})\n",
    "df = df.drop(columns=[\n",
    "    \"RAUM_CODE\",\n",
    "    \"RAUM_ZUSATZBEZEICHNUNG\"\n",
    "])\n",
    "df.to_csv(join(dst, \"rooms.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
