{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and clean the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from os.path import join\n",
    "import datetime\n",
    "import string\n",
    "import network_creation_functions as ncf\n",
    "from importlib import reload\n",
    "\n",
    "# parallelisation functionality\n",
    "from multiprocess import Pool\n",
    "import psutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '../../data/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_dates.csv\texam_dates.csv\t      missing_study_names.csv\n",
      "course_enrollment.csv\texam_enrollment.csv   rooms.csv\n",
      "courses.csv\t\texam_supervision.csv  students.csv\n",
      "course_supervision.csv\tlecturers.csv\t      study_labels.csv\n"
     ]
    }
   ],
   "source": [
    "! ls ../../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of students with enrolled studies. A student can have more than one study,\n",
    "# which will show up as separate entries (row) for the same student_id. Each\n",
    "# study also has a term number, i.e. the number of semesters the student has\n",
    "# been enrolled in the given study.\n",
    "students = pd.read_csv(join(src, 'students.csv'))\n",
    "\n",
    "# Mapping of lecturers to organisations (institute, faculty). A lecturer can\n",
    "# be associated with more than one organisation.\n",
    "lecturers = pd.read_csv(join(src, 'lecturers.csv'))\n",
    "\n",
    "# List of lectures with information about their type, their name, their module\n",
    "# (this is only relevant for how studies are composed at TU Graz) and the \n",
    "# organisational unit (institute, faculty) which is responsible for the lecture.\n",
    "courses = pd.read_csv(join(src, 'courses.csv'))\n",
    "\n",
    "# List of enrolled students for courses in the WiSe 2019/20. A courses\n",
    "# can have several groups (for example for tutorial parts). The group enrollment\n",
    "# is also listed for every student. It is not completely unique\n",
    "# as there are a number of overlapping groups (for example same time, \n",
    "# different rooms). These are disambiguated at a later point in the data\n",
    "# cleaning process. The data also includes the identifier of the study through \n",
    "# which the student enrolled in a given lecture. \n",
    "course_enrollment = pd.read_csv(join(src, 'course_enrollment.csv'))\n",
    "\n",
    "# List of enrolled students for exams in the WiSe 2019/20.\n",
    "exam_enrollment = pd.read_csv(join(src, 'exam_enrollment.csv'))\n",
    "\n",
    "# List of lecturers which are responsible for lectures and groups within\n",
    "# lectures. Similar to the course enrollment table, the group_id is \n",
    "# disambiguated later in the data cleaning process\n",
    "course_supervision = pd.read_csv(join(src, 'course_supervision.csv'))\n",
    "\n",
    "# List of lecturers which are responsible for exams. Similar to the course \n",
    "# enrollment table, the exam_id is disambiguated later in the data cleaning \n",
    "# process\n",
    "exam_supervision = pd.read_csv(join(src, 'exam_supervision.csv'))\n",
    "\n",
    "# Courses (start time, end time, room) for every course and group in WiSe \n",
    "# 2019/20\n",
    "course_dates = pd.read_csv(join(src, 'course_dates.csv'), \n",
    "                           parse_dates=[\"date\", \"start_time\", \"end_time\"])\n",
    "\n",
    "# Exams (start time, end time, room) for every exam in WiSe 2019/20\n",
    "exam_dates = pd.read_csv(join(src, 'exam_dates.csv'), \n",
    "                           parse_dates=[\"date\"])\n",
    "\n",
    "# List of rooms and information about them (number of seats, square meters).\n",
    "# TU Graz has three campuses: Alte Technik, Neue Technik and Inffeldgasse. The\n",
    "# mapping of every room to a campus is also stored.\n",
    "# Information for rooms outside TU Graz premises was missing. Jana Lasser \n",
    "# manually searched for and filled in room information for rooms at Uni Graz \n",
    "# and added the information to the file /data/raw/Räume.csv. The updated file \n",
    "# is stored in /data/cleaned/Räume_cleaned.csv. These rooms are excluded from\n",
    "# the further analysis anyways though.\n",
    "rooms = pd.read_csv(join(src, 'rooms.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| data | cleaning | checks |\n",
    "| ---- | -------- | ------ |\n",
    "| course dates | dropped: dates outside normal hours, dates longer than 13 hours | no dates outside the semester |\n",
    "| exam dates | dropped: dates outside normal hours, dates without a start time, dates longer than 13 hours| no dates outside the semester, all exams have a supervising lecturer |\n",
    "| course enrollment | dropped: enrollments without dates |\n",
    "| exam enrollment | dropped: enrollments without dates |\n",
    "| courses | dropped: courses without enrollment |\n",
    "| students | dropped: students without enrollments in courses or exams |\n",
    "| course supervision | dropped: lecturers who don't supervise a course or exam |\n",
    "| exam supervision | dropped: lecturers who don't supervise a course or exam |\n",
    "| lecturers | dropped: organisations without active lecturers |\n",
    "| rooms | dropped: rooms without courses or exams |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all course & exam dates occur inside the semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of the semester start\n",
    "semester_start = pd.to_datetime(ncf.semester_start)\n",
    "# date of the semester end\n",
    "semester_end = pd.to_datetime(ncf.semester_end)\n",
    "\n",
    "# Make sure all events take place within the time specified by the semester\n",
    "# start (2019-10-01) and semester end (2020-02-28).\n",
    "assert len(course_dates) == len(course_dates[course_dates['date'] >= semester_start])\n",
    "assert len(course_dates) == len(course_dates[course_dates['date'] <= semester_end])\n",
    "\n",
    "# Make sure all events take place within the time specified by the semester\n",
    "# start (2019-10-01) and semester end (2020-02-28).\n",
    "assert len(exam_dates) == len(exam_dates[exam_dates['date'] >= semester_start])\n",
    "assert len(exam_dates) == len(exam_dates[exam_dates['date'] <= semester_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop course dates that occured outside normal lecture hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 31/29147 courses with a start time later than 8:00 PM\n",
      "dropped 133/29116 courses with a start time earlier than 7:00 AM\n",
      "dropped 0/28983 courses with a start time at 00:00\n"
     ]
    }
   ],
   "source": [
    "# convert the start and end datetime to a time and drop all courses\n",
    "# which occured outside normal lecture hours, i.e. had a start time\n",
    "# before 7:00 AM, after 8:00 PM or at exactly midnight (not covered\n",
    "# by either of the two conditions). We assume these courses are either\n",
    "# erroneous entries or placeholder courses.\n",
    "course_dates['start_time'] = course_dates['start_time'].dt.time\n",
    "course_dates['end_time'] = course_dates['end_time'].dt.time\n",
    "N = len(course_dates)\n",
    "course_dates = course_dates[course_dates['start_time'] <= datetime.time(20, 0)]\n",
    "print('dropped {}/{} courses with a start time later than 8:00 PM'\\\n",
    "      .format(N - len(course_dates), N))\n",
    "N = len(course_dates)\n",
    "course_dates = course_dates[course_dates['start_time'] >= datetime.time(7, 0)]\n",
    "print('dropped {}/{} courses with a start time earlier than 7:00 AM'\\\n",
    "      .format(N - len(course_dates), N))\n",
    "N = len(course_dates)\n",
    "course_dates = course_dates[course_dates['start_time'] >= datetime.time(0, 0)]\n",
    "print('dropped {}/{} courses with a start time at 00:00'\\\n",
    "      .format(N - len(course_dates), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop exams without start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 144/5633 exams without start time\n",
      "2745 (50.01%) exams do not have an end time\n",
      "3517 (64.07%) exams do not have an assigned room\n"
     ]
    }
   ],
   "source": [
    "N = len(exam_dates)\n",
    "exam_dates = exam_dates.dropna(subset=[\"start_time\"])\n",
    "print('dropped {}/{} exams without start time'\\\n",
    "      .format(N - len(exam_dates), N))\n",
    "N = len(exam_dates)\n",
    "print('{} ({:1.2f}%) exams do not have an end time'\\\n",
    "      .format(N - len(exam_dates[\"end_time\"].dropna()), \n",
    "              (N - len(exam_dates[\"end_time\"].dropna())) / N * 100))\n",
    "\n",
    "print('{} ({:1.2f}%) exams do not have an assigned room'\\\n",
    "      .format(N - len(exam_dates[\"room_id\"].dropna()), \n",
    "              (N - len(exam_dates[\"room_id\"].dropna())) / N * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge course and exam dates to event dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_dates = exam_dates.rename(columns={\"exam_id\":\"group_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(timestring):\n",
    "    if timestring != timestring:\n",
    "        return np.nan\n",
    "    else:\n",
    "        hour, minute = timestring.split(':')\n",
    "        return datetime.time(int(hour), int(minute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the start and end time string to a time object\n",
    "exam_dates['start_time'] = exam_dates['start_time']\\\n",
    "    .apply(get_time)\n",
    "exam_dates['end_time'] = exam_dates['end_time']\\\n",
    "    .apply(get_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = pd.concat([course_dates, exam_dates])\n",
    "event_dates = event_dates.reset_index(drop=True)\n",
    "del course_dates\n",
    "del exam_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop events with duration > 780 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 2/34472 events that were longer than 780 minutes\n"
     ]
    }
   ],
   "source": [
    "# Calculate the duration of events and drop all events that have a duration\n",
    "# of more than 13 hours. We assume these events are either erroneous entries \n",
    "# or placeholder events.\n",
    "event_dates['duration'] = event_dates.apply(ncf.calculate_duration, axis=1)\n",
    "duration_threshold = 13 * 60\n",
    "\n",
    "def nan_leq(duration):\n",
    "    '''Returns true in the duration is <= duration_threshold or NaN'''\n",
    "    if duration != duration:\n",
    "        return True\n",
    "    elif duration <= duration_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "N = len(event_dates) \n",
    "event_dates = event_dates[event_dates['duration'].apply(nan_leq)]\n",
    "print(\"dropped {}/{} events that were longer than {} minutes\"\\\n",
    "      .format(N - len(event_dates), N, duration_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge course and exam enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_enrollment = exam_enrollment.rename(columns={\"exam_id\":\"group_id\"})\n",
    "enrollment = pd.concat([course_enrollment, exam_enrollment])\n",
    "enrollment = enrollment.reset_index(drop=True)\n",
    "del course_enrollment\n",
    "del exam_enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop event enrollments without dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 5859/143320 enrollments without dates\n"
     ]
    }
   ],
   "source": [
    "group_IDs = set(event_dates[\"group_id\"])\n",
    "\n",
    "N = len(enrollment)\n",
    "enrollment = enrollment[enrollment[\"group_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} enrollments without dates'\\\n",
    "      .format(N - len(enrollment), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop events dates without enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 4917/34470 event dates without enrollment\n"
     ]
    }
   ],
   "source": [
    "group_IDs = set(enrollment[\"group_id\"])\n",
    "\n",
    "N = len(event_dates)\n",
    "event_dates = event_dates[event_dates[\"group_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} event dates without enrollment'\\\n",
    "      .format(N - len(event_dates), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = set(event_dates[\"group_id\"].unique()).difference(set(enrollment[\"group_id\"].unique()))\n",
    "assert len(diff) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop course supervision entries without enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 465/1853 course supervisions with no enrollment in supervised event\n"
     ]
    }
   ],
   "source": [
    "# filter out lecturers without courses\n",
    "N = len(course_supervision[\"lecturer_id\"].unique())\n",
    "course_supervision = course_supervision[course_supervision[\"group_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} course supervisions with no enrollment in supervised event'\\\n",
    "      .format(N - len(course_supervision[\"lecturer_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop exam supervision entries without enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 20/870 exam supervisions with no enrollment in supervised exam\n"
     ]
    }
   ],
   "source": [
    "# filter out lecturers without courses\n",
    "N = len(exam_supervision[\"lecturer_id\"].unique())\n",
    "exam_supervision = exam_supervision[exam_supervision[\"exam_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} exam supervisions with no enrollment in supervised exam'\\\n",
    "      .format(N - len(exam_supervision[\"lecturer_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge course and exam supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_supervision = exam_supervision.rename(columns={\"exam_id\":\"group_id\"})\n",
    "supervision = pd.concat([course_supervision, exam_supervision])\n",
    "supervision = supervision.reset_index(drop=True)\n",
    "del course_supervision\n",
    "del exam_supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert group IDs to string format, because we are going to add letters to\n",
    "# them for disambiguation\n",
    "enrollment[\"group_id\"] = enrollment[\"group_id\"].astype(int).astype(str)\n",
    "event_dates[\"group_id\"] = event_dates[\"group_id\"].astype(int).astype(str)\n",
    "supervision[\"group_id\"] = supervision[\"group_id\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = enrollment[['course_id', 'group_id']].drop_duplicates().copy()\n",
    "groups = groups[groups['group_id'].isin(event_dates['group_id'].unique())]\n",
    "groups = groups.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disambiguate group IDs for events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_group(date):\n",
    "    '''\n",
    "    Checks whether for a given group id and date there is more than one\n",
    "    event at the same time. If this is the case, the group ID is split into a\n",
    "    number of subgroups equal to the number of events that take place at the\n",
    "    same time. This is done by adding a letter (from \"a\" to \"z\") to the group\n",
    "    ID. Mappings of datetime indices in the event_date data frame to new group \n",
    "    IDs are returned as a data frame.\n",
    "    '''\n",
    "    new_group_ids = pd.DataFrame()\n",
    "    curr_date = event_dates[event_dates[\"date\"] == date]\n",
    "    for group_id in curr_date['group_id']:\n",
    "        # dates that happen at the same time for the same group\n",
    "        group_dates = event_dates[(event_dates['group_id'] == group_id) & \\\n",
    "                            (event_dates['date'] == date)]\n",
    "        # is there more than one date for the same group id on a given day?\n",
    "        # do the duplicate dates start at the same time?\n",
    "        if (len(group_dates) > 1) and \\\n",
    "           (len(group_dates['start_time'].drop_duplicates()) < len(group_dates)):\n",
    "            \n",
    "            # de-duplicate group ids stat start at the same time by adding a \n",
    "            # letter at the end of the id\n",
    "            for dt in group_dates['datetime']:\n",
    "                group_datetimes = group_dates[group_dates['datetime'] == dt]\n",
    "                assert len(group_datetimes) <= len(letter_list)\n",
    "                \n",
    "                for index, letter in zip(group_datetimes.index, letter_list):\n",
    "                    #event_dates.loc[index, 'new_group_id'] = '{}{}'.format(group_id, letter)\n",
    "                    new_group_ids = new_group_ids.append({\n",
    "                        \"index\":index,\n",
    "                        \"new_group_id\":f'{group_id}{letter}'\n",
    "                    }, ignore_index=True)\n",
    "                    \n",
    "    return new_group_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:15<00:00,  8.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a temporary datetime entry for easy checking if something happens on\n",
    "# the same day at the same time\n",
    "event_dates[\"datetime\"] = event_dates\\\n",
    "    .apply(lambda x: datetime.datetime.combine(x['date'], x['start_time']), axis=1)\n",
    "\n",
    "# list of letters to append to create new group IDs\n",
    "letter_list = list(string.ascii_lowercase)\n",
    "\n",
    "# do this on many cores to speed it up\n",
    "pool = Pool(15)\n",
    "dates = event_dates['date'].unique()\n",
    "new_group_ids = pd.DataFrame()\n",
    "for IDs in tqdm(\n",
    "        pool.imap_unordered(func=deduplicate_group, iterable=dates), total=len(dates)\n",
    "    ):\n",
    "    new_group_ids = pd.concat([new_group_ids, IDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the old group IDs with the new group IDs on the given \n",
    "# datetimes (indices)\n",
    "new_group_ids[\"index\"] = new_group_ids[\"index\"].astype(int)\n",
    "event_dates[\"new_group_id\"] = event_dates[\"group_id\"]\n",
    "event_dates.loc[new_group_ids[\"index\"].values, \"new_group_id\"] = \\\n",
    "    new_group_ids[\"new_group_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 groups had more than one date on the same day and at the same time and were split into 409 new groups\n"
     ]
    }
   ],
   "source": [
    "# create a list of groups that were split into subgroups for convenience\n",
    "group_splits = event_dates[event_dates[['group_id', 'new_group_id']]\\\n",
    "            .apply(lambda x: x[\"group_id\"] != x[\"new_group_id\"], 1)]\\\n",
    "            [[\"group_id\", \"new_group_id\"]].drop_duplicates()\n",
    "print('{} groups had more than one date on the same day and at the same time '\\\n",
    "      .format(len(group_splits['group_id'].unique())) + \\\n",
    "     'and were split into {} new groups'.format(len(group_splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new group IDs to enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: found a case where there are fewer students than groups!\n",
      "1 students for 2 new groups\n",
      "adding 1 new groups to the list of unused groups\n",
      "WARNING: found a case where there are fewer students than groups!\n",
      "1 students for 6 new groups\n",
      "adding 5 new groups to the list of unused groups\n"
     ]
    }
   ],
   "source": [
    "# We create new enrollment entries for students that are distributed into the\n",
    "# new subgroups. This is needed because some groups are only split into\n",
    "# subgroups on certain dates, while they take place as a single group on other\n",
    "# dates. Therefore for one group there might be events that are assigned to the\n",
    "# original group ID, while other events are assigned to the new group IDs.\n",
    "new_enrollment = pd.DataFrame()\n",
    "\n",
    "# Some new groups are not used, because there are not enough students enrolled\n",
    "# in the original group to populate all new subgroups. We record these unused\n",
    "# groups and remove them from the event_date table later.\n",
    "unused_new_group_IDs = []\n",
    "\n",
    "# iterate over all groups that were split into subgroups and distribute student\n",
    "# enrollment evenly between the new subgroups\n",
    "for group_id in group_splits['group_id'].unique():\n",
    "    # identify all students that were enrolled in the original group\n",
    "    students_in_group = enrollment[enrollment['group_id']  == group_id]\n",
    "    # fetch the newly disambiguated group IDs\n",
    "    new_group_ids = group_splits[\\\n",
    "            group_splits['group_id'] == group_id]['new_group_id'].values\n",
    "    # calculate how many students will be allocated in each of the subgroups\n",
    "    new_group_size = int(len(students_in_group) / len(new_group_ids))\n",
    "    \n",
    "    # make sure the new groups have each at least one student\n",
    "    if new_group_size >= 1:\n",
    "    \n",
    "        # distribute the new students equally to the subgroups\n",
    "        for i, ID in enumerate(new_group_ids[0:-1]):\n",
    "            tmp = students_in_group[\\\n",
    "                    i * new_group_size:(i + 1) * new_group_size].copy()\n",
    "            tmp['group_id'] = ID\n",
    "            new_enrollment = pd.concat([new_enrollment, tmp])\n",
    "        tmp = students_in_group[(i + 1) * new_group_size:].copy()\n",
    "        tmp['group_id'] = new_group_ids[-1]\n",
    "        new_enrollment = pd.concat([new_enrollment, tmp])\n",
    "        \n",
    "    # if this is not the case, assign one student each to the first N subgroups,\n",
    "    # where N is the number of available students. Record the rest of the\n",
    "    # subgroups as \"unused\" to be deleted later\n",
    "    else:\n",
    "        print(\"WARNING: found a case where there are fewer students than groups!\")\n",
    "        print(f\"{len(students_in_group)} students for {len(new_group_ids)} new groups\")\n",
    "        for ID, index in zip(new_group_ids, students_in_group.index):\n",
    "            tmp = students_in_group.loc[index].copy()\n",
    "            tmp['group_id'] = ID\n",
    "            new_enrollment = new_enrollment.append(tmp, ignore_index=True)\n",
    "               \n",
    "        tmp = new_group_ids[len(students_in_group):]\n",
    "        print(f\"adding {len(tmp)} new groups to the list of unused groups\")\n",
    "        unused_new_group_IDs.extend(tmp)\n",
    "        \n",
    "# add the new enrollment information to the enrollment table\n",
    "enrollment = pd.concat([enrollment, new_enrollment]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unused (because of lack of students) new groups again\n",
    "group_splits = group_splits\\\n",
    "    .drop(group_splits[group_splits[\"new_group_id\"].isin(unused_new_group_IDs)].index)\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "# drop event dates for unused groups\n",
    "event_dates = event_dates\\\n",
    "    .drop(event_dates[event_dates[\"new_group_id\"].isin(unused_new_group_IDs)].index)\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "event_dates[\"group_id\"] = event_dates[\"new_group_id\"]\n",
    "event_dates = event_dates.drop(columns=[\"new_group_id\", \"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 55 original group IDs that were completely replaced by new group IDs\n"
     ]
    }
   ],
   "source": [
    "# drop enrollments for groups that were entirely replaced by new groups\n",
    "group_IDs = set(event_dates[\"group_id\"].unique())\n",
    "N = len(enrollment[\"group_id\"].unique())\n",
    "enrollment = enrollment[enrollment[\"group_id\"].isin(group_IDs)]\n",
    "print(\"dropped {} original group IDs that were completely replaced by new group IDs\"\\\n",
    "     .format(N - len(enrollment[\"group_id\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = set(event_dates[\"group_id\"].unique()).difference(set(enrollment[\"group_id\"].unique()))\n",
    "assert len(diff) == 0\n",
    "diff = set(enrollment[\"group_id\"].unique()).difference(set(event_dates[\"group_id\"].unique()))\n",
    "assert len(diff) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new group IDs to supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 split groups have no lecturer now\n"
     ]
    }
   ],
   "source": [
    "new_supervision = pd.DataFrame()\n",
    "lonely_groups = 0\n",
    "\n",
    "for group_id in group_splits['group_id'].unique():\n",
    "    lecturers_in_group = supervision[supervision['group_id']  == group_id]\n",
    "    new_group_ids = group_splits[group_splits['group_id'] == group_id]['new_group_id'].values\n",
    "    new_group_size = int(len(lecturers_in_group) / len(new_group_ids))\n",
    "    \n",
    "    #since we are not cloning lecturers, if there is just one lecturer but two\n",
    "    # groups at the same time, the lecturer will go to only one of the groups\n",
    "    if new_group_size == 1:\n",
    "        lonely_groups += 1\n",
    "    \n",
    "    # distribute the new students equally to the subgroups\n",
    "    for i, ID in enumerate(new_group_ids[0:-1]):\n",
    "        tmp = lecturers_in_group[\\\n",
    "                i * new_group_size:(i + 1) * new_group_size].copy()\n",
    "        tmp['group_id'] = ID\n",
    "        new_supervision = pd.concat([new_supervision, tmp])\n",
    "    tmp = lecturers_in_group[(i + 1) * new_group_size:].copy()\n",
    "    tmp['group_id'] = new_group_ids[-1]\n",
    "    new_supervision = pd.concat([new_supervision, tmp])\n",
    "    \n",
    "print('{} split groups have no lecturer now'.format(lonely_groups))\n",
    "\n",
    "# add the new supervision information to the supervision table\n",
    "supervision = pd.concat([supervision, new_supervision]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 55 original group IDs that were completely replaced by new group IDs\n"
     ]
    }
   ],
   "source": [
    "# drop supervision for groups that were entirely replaced by new groups\n",
    "group_IDs = set(event_dates[\"group_id\"].unique())\n",
    "N = len(supervision[\"group_id\"].unique())\n",
    "supervision = supervision[supervision[\"group_id\"].isin(group_IDs)]\n",
    "print(\"dropped {} original group IDs that were completely replaced by new group IDs\"\\\n",
    "     .format(N - len(supervision[\"group_id\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all supervised groups have event dates\n",
    "diff = set(supervision[\"group_id\"].unique()).difference(set(event_dates[\"group_id\"].unique()))\n",
    "assert len(diff) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 groups have no supervision\n"
     ]
    }
   ],
   "source": [
    "diff = set(event_dates[\"group_id\"].unique()).difference(set(supervision[\"group_id\"].unique()))\n",
    "N_lonely_groups = len(event_dates[event_dates[\"group_id\"].isin(diff)][\"group_id\"].unique())\n",
    "print(f\"{N_lonely_groups} groups have no supervision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226598</td>\n",
       "      <td>260636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221416</td>\n",
       "      <td>258125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   course_id group_id\n",
       "0     226598   260636\n",
       "1     221416   258125"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = enrollment[['course_id', 'group_id']].drop_duplicates().copy()\n",
    "groups = groups[groups['group_id'].isin(event_dates['group_id'].unique())]\n",
    "groups = groups.reset_index(drop=True)\n",
    "groups.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge courses and exams into course table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_exam_courses = pd.DataFrame({\"course_id\":event_dates[~event_dates[\"course_id\"]\\\n",
    "                        .isin(courses[\"course_id\"])][\"course_id\"].unique()})\n",
    "\n",
    "only_exam_courses[\"course_name\"] = np.nan\n",
    "only_exam_courses[\"course_type\"] = \"EX\"\n",
    "courses = pd.concat([courses, only_exam_courses])\n",
    "courses = courses.reset_index(drop=True)\n",
    "del only_exam_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop courses without enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 4581/7542 courses without enrollment\n"
     ]
    }
   ],
   "source": [
    "course_IDs = groups[\"course_id\"].unique()\n",
    "N = len(courses)\n",
    "courses = courses[courses[\"course_id\"].isin(course_IDs)]\n",
    "print('dropped {}/{} courses without enrollment'\\\n",
    "      .format(N - len(courses[\"course_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = event_dates.drop(columns=[\"course_id\"])\n",
    "supervision = supervision.drop(columns=[\"course_id\"])\n",
    "enrollment = enrollment.drop(columns=[\"course_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary student + study identifier\n",
    "enrollment[\"student_study\"] = enrollment.apply(lambda x: x[\"student_id\"] + \"_\" + x[\"study_id\"], axis=1)\n",
    "students[\"student_study\"] = students.apply(lambda x: x[\"student_id\"] + \"_\" + x[\"study_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing student + study from enrollment to student table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 80420 student + study combinations from enrollment to the student table\n"
     ]
    }
   ],
   "source": [
    "diff = set(enrollment[\"student_study\"]).difference(set(students[\"student_study\"]))\n",
    "missing_students = enrollment[enrollment[\"student_study\"].isin(diff)]\\\n",
    "    [[\"student_id\", \"study_id\", \"student_study\"]].copy()\n",
    "missing_students[\"study_name\"] = np.nan\n",
    "missing_students[\"term_number\"] = np.nan\n",
    "students = pd.concat([students, missing_students]).reset_index(drop=True)\n",
    "print(f\"added {len(missing_students)} student + study combinations from enrollment to the student table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop student + study without enrollment from student table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " removed 15525 student + study combination without enrollment from the student table\n"
     ]
    }
   ],
   "source": [
    "N = len(students)\n",
    "students = students[students[\"student_study\"].isin(enrollment[\"student_study\"])]\n",
    "print(f\" removed {N - len(students)} student + study combination without enrollment from the student table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicate student + study combinations from student table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " removed 42328 student + study duplicates from the student table\n"
     ]
    }
   ],
   "source": [
    "N = len(students)\n",
    "students = students.drop_duplicates(subset=[\"student_study\"])\n",
    "print(f\" removed {N - len(students)} student + study duplicates from the student table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(enrollment[\"student_study\"]).difference(set(students[\"student_study\"]))) == 0\n",
    "assert len(set(students[\"student_study\"]).difference(set(enrollment[\"student_study\"]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(enrollment[\"student_id\"]).difference(set(students[\"student_id\"]))) == 0\n",
    "assert len(set(students[\"student_id\"]).difference(set(enrollment[\"student_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(enrollment[\"study_id\"]).difference(set(students[\"study_id\"]))) == 0\n",
    "assert len(set(students[\"study_id\"]).difference(set(enrollment[\"study_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = students.drop(columns=[\"student_study\"])\n",
    "enrollment = enrollment.drop(columns=[\"student_study\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecturers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop lecturers without active supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 3922/5302 lecturers without supervision of course or exam\n"
     ]
    }
   ],
   "source": [
    "# filter out lecturers without courses\n",
    "lecturer_IDs = set(supervision[\"lecturer_id\"])\n",
    "N = len(lecturers[\"lecturer_id\"].unique())\n",
    "lecturers = lecturers[lecturers[\"lecturer_id\"].isin(lecturer_IDs)]\n",
    "print('dropped {}/{} lecturers without supervision of course or exam'\\\n",
    "      .format(N - len(lecturers[\"lecturer_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing supervising lecturers to lecturer table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = set(supervision[\"lecturer_id\"]).difference(set(lecturers[\"lecturer_id\"]))\n",
    "missing_lecturers = supervision[supervision[\"lecturer_id\"].isin(diff)][[\"lecturer_id\"]].copy()\n",
    "missing_lecturers[\"organisation_name\"] = np.nan\n",
    "lecturers = pd.concat([lecturers, missing_lecturers]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecturers = lecturers.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(lecturers[\"lecturer_id\"]).difference(set(supervision[\"lecturer_id\"]))) == 0\n",
    "assert len(set(supervision[\"lecturer_id\"]).difference(set(lecturers[\"lecturer_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rooms without courses or exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates[\"room_id\"] = event_dates[\"room_id\"].replace({-999999.0:np.nan})\n",
    "rooms[\"room_id\"] = rooms[\"room_id\"].astype(int)\n",
    "room_IDs = set(event_dates[\"room_id\"].dropna().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 1902/2288 rooms without courses or exams\n",
      "386 rooms remaining\n"
     ]
    }
   ],
   "source": [
    "N = len(rooms[\"room_id\"].unique())\n",
    "rooms = rooms[rooms[\"room_id\"].isin(room_IDs)]\n",
    "print('dropped {}/{} rooms without courses or exams'\\\n",
    "      .format(N - len(rooms[\"room_id\"].unique()), N))\n",
    "\n",
    "# make sure there are no duplicate rooms\n",
    "assert len(rooms) == len(rooms[\"room_id\"].unique())\n",
    "print(f\"{len(rooms)} rooms remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing rooms to room table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{18955, 19956, 22368, 22408, 29134, 29135}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rooms for which there is no information in the room table\n",
    "set(room_IDs).difference(rooms[\"room_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found in KFU room search system\n",
    "room1 = {\"room_id\":18955, \"seats\":np.nan, \"area\":159, \"campus\":\"KFU\",\n",
    " \"address\":\"Universitätsplatz 1\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# found in KFU room search system\n",
    "room2 = {\"room_id\":19956, \"seats\":130, \"area\":147, \"campus\":\"KFU\",\n",
    " \"address\":\"Heinrichstraße 36\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# found in KFU room search system\n",
    "room3 = {\"room_id\":22368, \"seats\":105, \"area\":62, \"campus\":\"KFU\",\n",
    " \"address\":\"Universitätsplatz 5\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# somehwere in the institute for Electronics\n",
    "room4 = {\"room_id\":22408, \"seats\":np.nan, \"area\":np.nan, \"campus\":\"Inffeldgasse\",\n",
    " \"address\":\"Heinrichstraße 36\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# found and measured by hand in TU Graz online room search system\n",
    "room5 = {\"room_id\":29134, \"seats\":np.nan, \"area\":51, \"campus\":\"Alte Technik\",\n",
    " \"address\":\"Technikerstraße 4\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# not found in TU or KFU\n",
    "room6 = {\"room_id\":29135, \"seats\":np.nan, \"area\":np.nan, \"campus\":np.nan,\n",
    " \"address\":np.nan, \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "rooms = rooms.append([room1, room2, room3, room4, room5, room6], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(event_dates[\"room_id\"].dropna()).difference(set(rooms[\"room_id\"]))) == 0\n",
    "assert len(set(rooms[\"room_id\"]).difference(set(event_dates[\"room_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix room address encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_map = {\n",
    "    'Lessingstraï¿½e 25':'Lessingstraße 25',\n",
    "    'Rechbauerstraï¿½e 12':'Rechbauerstraße 12',\n",
    "    'Technikerstraï¿½e 4':'Technikerstraße 4',\n",
    "    'UniversitÃ¤tsplatz 1':'Universitätsplatz 1', \n",
    "    'UniversitÃ¤tsstraÃ\\x9fe 15':'Universitätsstraße 15',\n",
    "    'Mï¿½nzgrabenstraï¿½e 35A':'Münzgrabenstraße 35A',\n",
    "    'HeinrichstraÃ\\x9fe 36':'Heinrichstraße 36',\n",
    "    'Mandellstraï¿½e 11':'Mandellstraße 11',\n",
    "    'Mandellstraï¿½e 13':'Mandellstraße 13',\n",
    "    'UniversitÃ¤tsplatz 6':'Universitätsplatz 6',\n",
    "    'HeinrichstraÃ\\x9fe 28':'Heinrichstraße 28',\n",
    "    'Lessingstraï¿½e 27':'Lessingstraße 27'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms[\"address\"] = rooms[\"address\"].replace(address_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix room missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms[\"postal_code\"] = 8010\n",
    "rooms[\"city\"] = 'Graz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing study names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_names = students[[\"study_id\", \"study_name\"]].dropna().drop_duplicates()\n",
    "# missing mapping of study IDs to study names compiled by hand through google\n",
    "# searches\n",
    "missing_study_names = pd.read_csv(join(src, \"missing_study_names.csv\"))\n",
    "study_names = pd.concat([study_names, missing_study_names])\n",
    "study_name_map = {row[\"study_id\"]:row[\"study_name\"] for i, row in study_names.iterrows()}\n",
    "students[\"study_name\"] = students[\"study_id\"].map(study_name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add study levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_map = ncf.study_map # mapping of studies to degree levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>term_number</th>\n",
       "      <th>study_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ekijKawygVR8ULF1NZTkbY7vnKPhz22</td>\n",
       "      <td>UF 033 282</td>\n",
       "      <td>Bachelorstudium; Wirtschaftsingenieurwesen-Mas...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aThq4hjnVcaKTvBw7BoN0daZD7PZ1wi</td>\n",
       "      <td>UF 033 243</td>\n",
       "      <td>Bachelorstudium; Architektur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         student_id    study_id  \\\n",
       "15  ekijKawygVR8ULF1NZTkbY7vnKPhz22  UF 033 282   \n",
       "22  aThq4hjnVcaKTvBw7BoN0daZD7PZ1wi  UF 033 243   \n",
       "\n",
       "                                           study_name  term_number study_level  \n",
       "15  Bachelorstudium; Wirtschaftsingenieurwesen-Mas...         11.0    bachelor  \n",
       "22                       Bachelorstudium; Architektur          1.0    bachelor  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the text before the semicolon in the study_name field describes (approximately) \n",
    "# the degree and is mapped to a unified pre / post graduate degree scheme that was\n",
    "# informed by Timotheus Hell\n",
    "def get_study_level(study_name):\n",
    "    if study_name != study_name:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return study_map[study_name.split(';')[0]]\n",
    "\n",
    "students['study_level'] = students['study_name'].apply(get_study_level)\n",
    "students.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add study university labels (TU & NAWI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TU Graz offers a wide variety of studies. Some of them in cooperation with\n",
    "# other local universities, such as Uni Graz, the university of arts and\n",
    "# teaching studies (organised Austria-wide). The vast majority of these\n",
    "# collaborative studies are organised under the umbrella of \"NaWi Graz\"\n",
    "# (NaturWissenschaften Graz), in cooperation with Uni Graz. \n",
    "\n",
    "# Students who are enrolled in one of these collaboratively organised studies\n",
    "# have a high chance of having the majority of their classes at the premises \n",
    "# of other universities. We therefore assign the studies to a total of 6\n",
    "# labels, indicating which university they belong to. This will later enable\n",
    "# us to filter by study and exclude students which are not enrolled in \n",
    "# native TU Graz studies.\n",
    "\n",
    "# study labels (supplied by Timotheus Hell):\n",
    "# \"t\": TU Graz study\n",
    "# \"n\": NaWi Graz study (study with uni Graz)\n",
    "# \"l\": teaching study (study with 8 other universities)\n",
    "# \"k\": study with university of arts\n",
    "# \"w\": further training courses\n",
    "# \"a\": other university (includes non-NaWi studies with Uni Graz, former \"u\" label)\n",
    "study_labels = pd.read_csv(join('../../data/raw', 'study_labels.csv'))\n",
    "label_map = {row['study_id']:row['study_label'] for i, row in \\\n",
    "            study_labels.iterrows()}\n",
    "students['study_label'] = students['study_id'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add main study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students can have more than one study. Find a student's main study\n",
    "# by looking at the study id of the individual events they visit.\n",
    "# A student's main study in the given semester is the study from which\n",
    "# the majority of their visited events stems.\n",
    "group_counts = enrollment[['student_id', 'study_id', 'group_id']]\\\n",
    "    .groupby(by=['student_id', 'study_id'])\\\n",
    "    .agg('count')\\\n",
    "    .rename(columns={'group_id':'group_count'})\\\n",
    "    .sort_values(by='group_count', ascending=False)\\\n",
    "    .reset_index()\n",
    "main_studies = group_counts[['student_id', 'study_id']]\\\n",
    "    .drop_duplicates(subset=['student_id'])\\\n",
    "    .set_index('student_id')\n",
    "\n",
    "students[\"main_study\"] = students[\"student_id\"]\\\n",
    "    .apply(lambda x: main_studies.loc[x, \"study_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute event durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to impute missing event durations specific for each event type.\n",
    "# For this purpose, we add course type information to the event_dates data table\n",
    "groups = groups.set_index(\"group_id\")\n",
    "courses = courses.set_index(\"course_id\")\n",
    "\n",
    "event_dates[\"course_id\"] = event_dates[\"group_id\"].apply(lambda x: groups.loc[x])\n",
    "event_dates[\"course_type\"] = event_dates[\"course_id\"].apply(lambda x: courses.loc[x, \"course_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VU (N=4712): missing 4.435%, median duration 120.000 min\n",
      "LU (N=1803): missing 7.543%, median duration 240.000 min\n",
      "VO (N=9349): missing 3.615%, median duration 105.000 min\n",
      "SE (N=3179): missing 12.551%, median duration 105.000 min\n",
      "UE (N=6076): missing 4.460%, median duration 90.000 min\n",
      "KV (N=99): missing 7.071%, median duration 60.000 min\n",
      "PT (N=166): missing 26.506%, median duration 120.000 min\n",
      "KU (N=588): missing 5.272%, median duration 105.000 min\n",
      "PV (N=765): missing 3.399%, median duration 90.000 min\n",
      "SP (N=171): missing 60.819%, median duration 60.000 min\n",
      "OL (N=63): missing 12.698%, median duration 90.000 min\n",
      "RU (N=8): missing 12.500%, median duration 90.000 min\n",
      "RP (N=5): missing 0.000%, median duration 120.000 min\n",
      "EX (N=2562): missing 45.667%, median duration 120.000 min\n",
      "PR (N=1): missing 0.000%, median duration 60.000 min\n"
     ]
    }
   ],
   "source": [
    "# impute event durations based on event type\n",
    "event_dates[\"imputed_duration\"] = False\n",
    "event_dates[\"imputed_end_time\"] = False\n",
    "for course_type in event_dates[\"course_type\"].unique():\n",
    "    course_type_events = event_dates[event_dates[\"course_type\"] == course_type]\n",
    "    median_duration = course_type_events[\"duration\"].median()\n",
    "    N = len(course_type_events)\n",
    "    print(\"{} (N={}): missing {:1.3f}%, median duration {:1.3f} min\"\\\n",
    "          .format(course_type,\n",
    "                  len(course_type_events),\n",
    "                  (N - len(course_type_events[\"duration\"].dropna())) / N * 100,\n",
    "                  median_duration))\n",
    "    \n",
    "    \n",
    "    event_dates.loc[course_type_events.index, \"duration\"] = median_duration\n",
    "    event_dates.loc[course_type_events[\"duration\"].isna().index, \"imputed_duration\"] = True\n",
    "    event_dates.loc[course_type_events[\"duration\"].isna().index, \"imputed_end_time\"] = True\n",
    "\n",
    "# calculate end times for events with imputed durations\n",
    "event_dates[\"end_time\"] = event_dates.apply(ncf.calculate_end_time, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute room areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset = rooms[[\"seats\", \"area\"]].dropna().copy()\n",
    "subset[\"area\"] = subset[\"area\"].astype(float)\n",
    "subset[\"seats\"] = subset[\"seats\"].astype(int)\n",
    "subset[\"area_per_seat\"] = subset[\"area\"] / subset[\"seats\"]\n",
    "\n",
    "good_seat_info = subset[subset[\"area_per_seat\"] > 0.5]\n",
    "bad_seat_info = subset[subset[\"area_per_seat\"] <= 0.5]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(good_seat_info[\"seats\"], good_seat_info[\"area\"])\n",
    "ax.set_xlabel(\"seats\")\n",
    "ax.set_ylabel(\"area\")\n",
    "\n",
    "cor = good_seat_info[[\"area\", \"seats\"]].corr().loc[\"area\", \"seats\"]\n",
    "\n",
    "# since we have both cases with existing seat info but missing area info and\n",
    "# existing area info but missing seat info, we do both regressions to recover\n",
    "# the coefficients\n",
    "slope_seats, intercept_seats, rvalue, pvalue, stderr = \\\n",
    "    linregress(good_seat_info[\"seats\"], good_seat_info[\"area\"])\n",
    "\n",
    "slope_area, intercept_area, rvalue, pvalue, stderr = \\\n",
    "    linregress(good_seat_info[\"area\"], good_seat_info[\"seats\"])\n",
    "\n",
    "x = np.arange(1, good_seat_info[\"seats\"].max())\n",
    "y = intercept_seats + slope_seats * x\n",
    "ax.plot(x, y, color=\"red\")\n",
    "ax.set_title(\"R = {:1.2f}\".format(cor));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms[\"imputed_area\"] = False\n",
    "rooms[\"imputed_seats\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputing 104 rooms with bad area info using information from 230 trustworthy rooms\n",
      "imputing 49 rooms with missing areas\n",
      "imputing 3 rooms with missing seats\n",
      "imputing 6 rooms with both missing area and missing seats\n"
     ]
    }
   ],
   "source": [
    "# impute areas of rooms with existing but most likely faulty area information\n",
    "print(f\"imputing {len(bad_seat_info)} rooms with bad area info using information from {len(good_seat_info)} trustworthy rooms\")\n",
    "rooms.loc[bad_seat_info.index, \"area\"] = \\\n",
    "    round(bad_seat_info[\"seats\"] * slope_seats + intercept_seats, 1)\n",
    "rooms.loc[bad_seat_info.index, \"imputed_area\"] = True\n",
    "\n",
    "# impute areas of rooms with missing area information\n",
    "missing_areas = rooms[(rooms[\"area\"].isna()) & (~rooms[\"seats\"].isna())].index\n",
    "print(f\"imputing {len(missing_areas)} rooms with missing areas\")\n",
    "rooms.loc[missing_areas, \"area\"] = \\\n",
    "    round(rooms.loc[missing_areas, \"seats\"] * slope_seats + intercept_seats, 1)\n",
    "rooms.loc[missing_areas, \"imputed_area\"] = True\n",
    "\n",
    "# impute seats of rooms with missing seat information\n",
    "rooms[\"area\"] = rooms[\"area\"].astype(float)\n",
    "missing_seats = rooms[(rooms[\"seats\"].isna()) & (~rooms[\"area\"].isna())].index\n",
    "print(f\"imputing {len(missing_seats)} rooms with missing seats\")\n",
    "rooms.loc[missing_seats, \"seats\"] = \\\n",
    "    (rooms.loc[missing_seats, \"area\"] * slope_area + intercept_area).astype(int)\n",
    "rooms.loc[missing_seats, \"imputed_seats\"] = True\n",
    "\n",
    "# impute the rest of the rooms where both seats and areas are missing with the\n",
    "# median values of areas and seats of the most trustworthy part of the data\n",
    "missing_everything = rooms[rooms[\"seats\"].isna()].index\n",
    "print(f\"imputing {len(missing_everything)} rooms with both missing area and missing seats\")\n",
    "rooms.loc[missing_everything, \"seats\"] = rooms.loc[good_seat_info.index, \"seats\"].median()\n",
    "rooms.loc[missing_everything, \"imputed_seats\"] = True\n",
    "rooms.loc[missing_everything, \"area\"] = rooms.loc[good_seat_info.index, \"area\"].median()\n",
    "rooms.loc[missing_everything, \"imputed_area\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolve space-time continuum problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many students are enrolled in events that take place at the same time. Since students can't clone themselves, they have to decide for an event to participate in. The same is true for lecturers who are assigned to supervise more than one event at the same time. In the following, we resolve these duplicate attendances following a simple heuristic: Students give priority to events from their main study, and to exams. If the priority of two conflicting events is the same, the event that starts earlier takes precedent. If both events start at the same time, a random event is chosen.  \n",
    "\n",
    "For lecturers, events that start earlier take precedent. If two conflicting events start at the same time, a random event is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add information about the main study to the enrollment data. This is needed\n",
    "# to make decisions about which event the student should participate in. The\n",
    "# information is dropped again later.\n",
    "main_studies = students[[\"student_id\", \"main_study\"]].drop_duplicates().copy()\n",
    "main_studies = main_studies.set_index(\"student_id\")\n",
    "\n",
    "enrollment[\"main_study\"] = enrollment\\\n",
    "    .apply(lambda x: x.study_id == main_studies.loc[x.student_id], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst1 = \"../../data/clean/\"\n",
    "dst2 = \"../../data/\"\n",
    "\n",
    "all_days = list(event_dates['date'].unique())\n",
    "all_days = [pd.to_datetime(sd) for sd in all_days]\n",
    "all_days.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_participation(student_id):\n",
    "    '''\n",
    "    Given a student id, determine which events the student is enrolled in and\n",
    "    which they will actually participate in, avoiding overlaps between events.\n",
    "    When selecting events, priority is given in the following order:\n",
    "    exam from main study > exam > course from main study > course. If two \n",
    "    overlapping events have the same priority, the event that starts earlier\n",
    "    takes precedent.\n",
    "    '''\n",
    "    \n",
    "    tmp_event_participations = pd.DataFrame()\n",
    "    \n",
    "    # get the events the given student is enrolled in\n",
    "    student_day_enrollment = day_enrollment[\\\n",
    "            day_enrollment[\"student_id\"] == student_id]\n",
    "    \n",
    "    # determine the starting and ending times of the events, sort them by\n",
    "    # starting time in ascending order\n",
    "    student_day_times = day_events[\\\n",
    "        day_events[\"group_id\"].isin(student_day_enrollment[\"group_id\"])]\\\n",
    "        .sort_values(by=\"start_time\", ascending=True)\n",
    "    \n",
    "    # easy case: only one enrollment on the given day\n",
    "    if len(student_day_enrollment) == 1:\n",
    "        tmp_event_participations = tmp_event_participations.append({\n",
    "            \"student_id\":student_id,\n",
    "            \"group_id\":student_day_times[\"group_id\"].values[0],\n",
    "            \"date\":date,\n",
    "            \"start_time\":student_day_times[\"start_time\"].values[0],\n",
    "            \"end_time\":student_day_times[\"end_time\"].values[0]\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    # more than one enrollment on the given day - potential overlap\n",
    "    else:\n",
    "        # split into courses from the main and secondary studies\n",
    "        main_study_courses = student_day_enrollment[\\\n",
    "            student_day_enrollment[\"main_study\"] == True][\"group_id\"].values\n",
    "        main_study_day_times = student_day_times[\\\n",
    "            student_day_times[\"group_id\"].isin(main_study_courses)]\n",
    "        sec_study_day_times = student_day_times[\\\n",
    "            ~student_day_times[\"group_id\"].isin(main_study_courses)]\n",
    "        \n",
    "        # split courses further into exams and non-exams\n",
    "        main_study_day_exams = main_study_day_times[\\\n",
    "            main_study_day_times[\"course_type\"] == \"EX\"]\n",
    "        sec_study_day_exams = sec_study_day_times[\\\n",
    "            sec_study_day_times[\"course_type\"] == \"EX\"]\n",
    "        main_study_day_courses = main_study_day_times[\\\n",
    "            main_study_day_times[\"course_type\"] != \"EX\"]\n",
    "        sec_study_day_courses = sec_study_day_times[\\\n",
    "            sec_study_day_times[\"course_type\"] != \"EX\"]\n",
    "        \n",
    "        # start with exams associated with the main study\n",
    "        if len(main_study_day_exams) > 0:\n",
    "            tmp_event_participations = tmp_event_participations.append({\n",
    "                \"student_id\":student_id,\n",
    "                \"group_id\":main_study_day_exams[\"group_id\"].values[0],\n",
    "                \"date\":date,\n",
    "                \"start_time\":main_study_day_exams[\"start_time\"].values[0],\n",
    "                \"end_time\":main_study_day_exams[\"end_time\"].values[0]\n",
    "            }, ignore_index=True)\n",
    "            \n",
    "        if len(main_study_day_exams) > 1:\n",
    "                tmp_event_participations = ncf.determine_event_participation(\n",
    "                    main_study_day_exams.iloc[1:], \n",
    "                    tmp_event_participations,\n",
    "                    student_id, date\n",
    "                )\n",
    "                    \n",
    "        # continue with other exams\n",
    "        if len(sec_study_day_exams) > 0:\n",
    "            # no event participations yet? Add the first non-main study exam\n",
    "            # to the event participation list without checking overlap\n",
    "            if len(tmp_event_participations) == 0:\n",
    "                tmp_event_participations = tmp_event_participations.append({\n",
    "                    \"student_id\":student_id,\n",
    "                    \"group_id\":sec_study_day_exams[\"group_id\"].values[0],\n",
    "                    \"date\":date,\n",
    "                    \"start_time\":sec_study_day_exams[\"start_time\"].values[0],\n",
    "                    \"end_time\":sec_study_day_exams[\"end_time\"].values[0]\n",
    "                }, ignore_index=True)\n",
    "                \n",
    "                # check for overlap for the remaining non-main study exams\n",
    "                if len(sec_study_day_exams) > 1:\n",
    "                    tmp_event_participations = ncf.determine_event_participation(\n",
    "                        sec_study_day_exams.iloc[1:], \n",
    "                        tmp_event_participations,\n",
    "                        student_id, date\n",
    "                    )\n",
    "            # if there already is a participation recorded for the day, check\n",
    "            # overlap for all non-main study exams\n",
    "            else:\n",
    "                tmp_event_participations = ncf.determine_event_participation(\n",
    "                    sec_study_day_exams, \n",
    "                    tmp_event_participations,\n",
    "                    student_id, date\n",
    "                )\n",
    "                \n",
    "        # resolve attendance in main study courses first\n",
    "        if len(main_study_day_courses) > 0:\n",
    "            # no event participations yet? Add the first main study course\n",
    "            # to the event participation list without checking overlap\n",
    "            if len(tmp_event_participations) == 0:\n",
    "                tmp_event_participations = tmp_event_participations.append({\n",
    "                    \"student_id\":student_id,\n",
    "                    \"group_id\":main_study_day_courses[\"group_id\"].values[0],\n",
    "                    \"date\":date,\n",
    "                    \"start_time\":main_study_day_courses[\"start_time\"].values[0],\n",
    "                    \"end_time\":main_study_day_courses[\"end_time\"].values[0]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "                # check for overlap for the remaining main study courses\n",
    "                if len(main_study_day_courses) > 1:\n",
    "                    tmp_event_participations = ncf.determine_event_participation(\n",
    "                        main_study_day_courses.iloc[1:], \n",
    "                        tmp_event_participations,\n",
    "                        student_id, date\n",
    "                    )\n",
    "            # if there already is a participation recorded for the day, check\n",
    "            # overlap for all main study courses\n",
    "            else:\n",
    "                tmp_event_participations = ncf.determine_event_participation(\n",
    "                    main_study_day_courses, \n",
    "                    tmp_event_participations,\n",
    "                    student_id, date\n",
    "                )\n",
    "        \n",
    "        # resolve attendance in non-main study courses last\n",
    "        if len(sec_study_day_courses) > 0:\n",
    "            # no event participations yet? Add the first non-main study course\n",
    "            # to the event participation list without checking overlap\n",
    "            if len(tmp_event_participations) == 0:\n",
    "                tmp_event_participations = tmp_event_participations.append({\n",
    "                    \"student_id\":student_id,\n",
    "                    \"group_id\":sec_study_day_courses[\"group_id\"].values[0],\n",
    "                    \"date\":date,\n",
    "                    \"start_time\":sec_study_day_courses[\"start_time\"].values[0],\n",
    "                    \"end_time\":sec_study_day_courses[\"end_time\"].values[0]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "                # check for overlap for the remaining non-main study courses\n",
    "                if len(sec_study_day_courses) > 1:\n",
    "                    tmp_event_participations = ncf.determine_event_participation(\n",
    "                        sec_study_day_courses.iloc[1:], \n",
    "                        tmp_event_participations,\n",
    "                        student_id, date\n",
    "                    )            \n",
    "            # if there already is a participation recorded for the day, check\n",
    "            # overlap for all non-main study courses\n",
    "            else:\n",
    "                tmp_event_participations = ncf.determine_event_participation(\n",
    "                    sec_study_day_courses, \n",
    "                    tmp_event_participations,\n",
    "                    student_id, date\n",
    "                )\n",
    "                \n",
    "    tmp_event_participations[\"merge_col\"] = tmp_event_participations\\\n",
    "        .apply(lambda x: str(x[\"start_time\"]) + \"_\" + x[\"group_id\"], axis=1)\n",
    "    student_day_times[\"merge_col\"] = student_day_times\\\n",
    "        .apply(lambda x: str(x[\"start_time\"]) + \"_\" + x[\"group_id\"], axis=1)\n",
    "    \n",
    "    # we track the difference between the events the student is actually able\n",
    "    # to participate in, and the events they enrolled in. This is just for moni-\n",
    "    # toring purposes and not used later on.\n",
    "    diff = set(student_day_times[\"merge_col\"])\\\n",
    "        .difference(set(tmp_event_participations[\"merge_col\"]))\n",
    "    diff = student_day_times[student_day_times[\"merge_col\"].isin(diff)].copy()\n",
    "    diff[\"student_id\"] = student_id\n",
    "    diff = diff.drop(columns=[\"merge_col\"])\n",
    "    tmp_event_participations = tmp_event_participations.drop(columns=[\"merge_col\"])\n",
    "    \n",
    "    return tmp_event_participations, diff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_participations = pd.DataFrame()\n",
    "diff_participations = pd.DataFrame()\n",
    "\n",
    "for date in all_days:\n",
    "    day_events = event_dates[event_dates[\"date\"] == date]\n",
    "    day_enrollment = enrollment[enrollment[\"group_id\"].isin(day_events[\"group_id\"])]\n",
    "\n",
    "    pool = Pool(10)\n",
    "    day_student_ids = day_enrollment[\"student_id\"].unique()\n",
    "    for tmp_participation, tmp_diff_participation in tqdm(\n",
    "            pool.imap_unordered(\n",
    "                func=get_day_participation, \n",
    "                iterable=day_student_ids),\n",
    "                total=len(day_student_ids)\n",
    "        ):\n",
    "        event_participations = pd.concat([event_participations, tmp_participation])\n",
    "        diff_participations = pd.concat([diff_participations, tmp_diff_participation])\n",
    "        \n",
    "pool.close()\n",
    "\n",
    "event_participations.to_csv(join(dst1, \"day_participation.csv\"), index=False)\n",
    "diff_participations.to_csv(join(dst2, \"day_diff_participation\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_supervision(lecturer_id):\n",
    "    \n",
    "    tmp_event_supervisions = pd.DataFrame()\n",
    "    \n",
    "    # get the events the given lecturer supervises\n",
    "    lecturer_day_supervision = day_supervision[\\\n",
    "            day_supervision[\"lecturer_id\"] == lecturer_id]\n",
    "    \n",
    "    # determine the starting and ending times of the events, sort them by\n",
    "    # starting time in ascending order\n",
    "    lecturer_day_times = day_events[\\\n",
    "        day_events[\"group_id\"].isin(lecturer_day_supervision[\"group_id\"])]\\\n",
    "        .sort_values(by=\"start_time\", ascending=True)\n",
    "    \n",
    "    # easy case: only one supervision on the given day\n",
    "    if len(lecturer_day_supervision) == 1:\n",
    "        tmp_event_supervisions = tmp_event_supervisions.append({\n",
    "            \"lecturer_id\":lecturer_id,\n",
    "            \"group_id\":lecturer_day_times[\"group_id\"].values[0],\n",
    "            \"date\":date,\n",
    "            \"start_time\":lecturer_day_times[\"start_time\"].values[0],\n",
    "            \"end_time\":lecturer_day_times[\"end_time\"].values[0]\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    # more than one supervision on the given day - potential overlap\n",
    "    else:  \n",
    "        # add the earliest first supervision\n",
    "        tmp_event_supervisions = tmp_event_supervisions.append({\n",
    "            \"lecturer_id\":lecturer_id,\n",
    "            \"group_id\":lecturer_day_times[\"group_id\"].values[0],\n",
    "            \"date\":date,\n",
    "            \"start_time\":lecturer_day_times[\"start_time\"].values[0],\n",
    "            \"end_time\":lecturer_day_times[\"end_time\"].values[0]\n",
    "        }, ignore_index=True)\n",
    "            \n",
    " \n",
    "        tmp_event_supervisions = ncf.determine_event_supervision(\n",
    "            lecturer_day_times.iloc[1:], \n",
    "            tmp_event_supervisions,\n",
    "            lecturer_id, date\n",
    "        )\n",
    "                \n",
    "    tmp_event_supervisions[\"merge_col\"] = tmp_event_supervisions\\\n",
    "        .apply(lambda x: str(x[\"start_time\"]) + \"_\" + x[\"group_id\"], axis=1)\n",
    "    lecturer_day_times[\"merge_col\"] = lecturer_day_times\\\n",
    "        .apply(lambda x: str(x[\"start_time\"]) + \"_\" + x[\"group_id\"], axis=1)\n",
    "    \n",
    "    # we track the difference between the events the lecturer is actually able\n",
    "    # to supervise, and the events they are assigned to supervise. This is just \n",
    "    # for monitoring purposes and not used later on.\n",
    "    diff = set(lecturer_day_times[\"merge_col\"])\\\n",
    "        .difference(set(tmp_event_supervisions[\"merge_col\"]))\n",
    "    diff = lecturer_day_times[lecturer_day_times[\"merge_col\"].isin(diff)].copy()\n",
    "    diff[\"lecturer_id\"] = lecturer_id\n",
    "    diff = diff.drop(columns=[\"merge_col\"])\n",
    "    tmp_event_supervisions = tmp_event_supervisions.drop(columns=[\"merge_col\"])\n",
    "    \n",
    "    return tmp_event_supervisions, diff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_supervisions = pd.DataFrame()\n",
    "diff_supervisions = pd.DataFrame()\n",
    "\n",
    "for date in all_days:\n",
    "    day_events = event_dates[event_dates[\"date\"] == date]\n",
    "    day_supervision = supervision[supervision[\"group_id\"]\\\n",
    "                                  .isin(day_events[\"group_id\"])]\n",
    "\n",
    "    pool = Pool(10)\n",
    "    day_lecturer_ids = day_supervision[\"lecturer_id\"].unique()\n",
    "    for tmp_supervision, tmp_diff_supervision in tqdm(\n",
    "            pool.imap_unordered(\n",
    "                func=get_day_supervision, \n",
    "                iterable=day_lecturer_ids),\n",
    "                total=len(day_lecturer_ids)\n",
    "        ):\n",
    "        event_supervisions = pd.concat([event_supervisions, tmp_supervision])\n",
    "        diff_supervisions = pd.concat([diff_supervisions, tmp_diff_supervision])\n",
    "        \n",
    "pool.close()\n",
    "        \n",
    "event_supervisions.to_csv(join(dst1, \"day_supervision.csv\"), index=False)\n",
    "diff_supervisions.to_csv(join(dst2, \"day_diff_supervision.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure data types & completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZGurrNFKVy4WmDRc7OT8uA58EnrAJ22</td>\n",
       "      <td>UF 033 253</td>\n",
       "      <td>260636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xtah2duSvN2/1mA/1fvGoo.ldOOpuYa</td>\n",
       "      <td>UF 033 253</td>\n",
       "      <td>258125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        student_id    study_id group_id\n",
       "1  ZGurrNFKVy4WmDRc7OT8uA58EnrAJ22  UF 033 253   260636\n",
       "2  xtah2duSvN2/1mA/1fvGoo.ldOOpuYa  UF 033 253   258125"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollment = enrollment.drop(columns=[\"main_study\"])\n",
    "enrollment[\"student_id\"] = enrollment[\"student_id\"].astype(str)\n",
    "enrollment[\"study_id\"] = enrollment[\"study_id\"].astype(str)\n",
    "enrollment[\"group_id\"] = enrollment[\"group_id\"].astype(str)\n",
    "assert len(enrollment) == len(enrollment.dropna())\n",
    "enrollment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecturer_id</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hbYTpbGOGwYPqn425psX7oZSNXGSM9i</td>\n",
       "      <td>258144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jMfY6T8kg95Ehsa80LAjAVEpAi6jDUm</td>\n",
       "      <td>263699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lecturer_id group_id\n",
       "0  hbYTpbGOGwYPqn425psX7oZSNXGSM9i   258144\n",
       "1  jMfY6T8kg95Ehsa80LAjAVEpAi6jDUm   263699"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervision[\"lecturer_id\"] = supervision[\"lecturer_id\"].astype(str)\n",
    "supervision[\"group_id\"] = supervision[\"group_id\"].astype(str)\n",
    "assert len(supervision) == len(supervision.dropna())\n",
    "supervision.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_id: 11.90% missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room_id</th>\n",
       "      <th>date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>group_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>course_id</th>\n",
       "      <th>course_type</th>\n",
       "      <th>imputed_duration</th>\n",
       "      <th>imputed_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27716.0</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>10:15:00</td>\n",
       "      <td>12:15:00</td>\n",
       "      <td>269598</td>\n",
       "      <td>120</td>\n",
       "      <td>227979</td>\n",
       "      <td>VU</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27716.0</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>10:15:00</td>\n",
       "      <td>12:15:00</td>\n",
       "      <td>269598</td>\n",
       "      <td>120</td>\n",
       "      <td>227979</td>\n",
       "      <td>VU</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   room_id       date start_time  end_time group_id  duration  course_id  \\\n",
       "0  27716.0 2019-10-25   10:15:00  12:15:00   269598       120     227979   \n",
       "1  27716.0 2020-01-31   10:15:00  12:15:00   269598       120     227979   \n",
       "\n",
       "  course_type  imputed_duration  imputed_end_time  \n",
       "0          VU              True              True  \n",
       "1          VU              True              True  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_dates[\"group_id\"] = event_dates[\"group_id\"].astype(str)\n",
    "event_dates[\"course_id\"] = event_dates[\"course_id\"].astype(int)\n",
    "event_dates[\"course_type\"] = event_dates[\"course_type\"].astype(str)\n",
    "event_dates[\"duration\"] = event_dates[\"duration\"].astype(int)\n",
    "event_dates[\"imputed_duration\"] = event_dates[\"imputed_duration\"].astype(bool)\n",
    "event_dates[\"date\"] = event_dates[\"date\"].astype(np.datetime64)\n",
    "\n",
    "complete_cols = [\"date\", \"group_id\", \"course_id\", \"course_type\", \"duration\",\n",
    "                 \"imputed_duration\", \"start_time\", \"end_time\"]\n",
    "assert len(event_dates[complete_cols]) == len(event_dates[complete_cols].dropna())\n",
    "\n",
    "incomplete_cols = [\"room_id\"]\n",
    "\n",
    "N = len(event_dates)\n",
    "for col in incomplete_cols:\n",
    "    print(\"{}: {:1.2f}% missing values\"\\\n",
    "          .format(col, (N - len(event_dates[col].dropna())) / N * 100))\n",
    "event_dates.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260636</td>\n",
       "      <td>226598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258125</td>\n",
       "      <td>221416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group_id  course_id\n",
       "0   260636     226598\n",
       "1   258125     221416"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = groups.reset_index()\n",
    "groups[\"group_id\"] = groups[\"group_id\"].astype(str)\n",
    "groups[\"course_id\"] = groups[\"course_id\"].astype(int)\n",
    "assert len(groups) == len(groups.dropna())\n",
    "groups.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campus: 0.26% missing values\n",
      "address: 1.28% missing values\n"
     ]
    }
   ],
   "source": [
    "rooms[\"room_id\"] = rooms[\"room_id\"].astype(int)\n",
    "rooms[\"seats\"] = rooms[\"seats\"].astype(int)\n",
    "rooms[\"area\"] = rooms[\"area\"].astype(float)\n",
    "rooms[\"postal_code\"] = rooms[\"postal_code\"].astype(int)\n",
    "rooms[\"city\"] = rooms[\"city\"].astype(str)\n",
    "rooms[\"imputed_area\"] = rooms[\"imputed_area\"].astype(bool)\n",
    "rooms[\"imputed_seats\"] = rooms[\"imputed_seats\"].astype(bool)\n",
    "\n",
    "complete_cols = [\"room_id\", \"seats\", \"area\", \"postal_code\", \"city\",\n",
    "                 \"imputed_area\", \"imputed_seats\"]\n",
    "assert len(rooms[complete_cols]) == len(rooms[complete_cols].dropna())\n",
    "\n",
    "incomplete_cols = [\"campus\", \"address\"]\n",
    "N = len(rooms)\n",
    "for col in incomplete_cols:\n",
    "    print(\"{}: {:1.2f}% missing values\"\\\n",
    "          .format(col, (N - len(rooms[col].dropna())) / N * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term_number: 81.01% missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>term_number</th>\n",
       "      <th>study_level</th>\n",
       "      <th>study_label</th>\n",
       "      <th>main_study</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ekijKawygVR8ULF1NZTkbY7vnKPhz22</td>\n",
       "      <td>UF 033 282</td>\n",
       "      <td>Bachelorstudium; Wirtschaftsingenieurwesen-Mas...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>t</td>\n",
       "      <td>UF 033 282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aThq4hjnVcaKTvBw7BoN0daZD7PZ1wi</td>\n",
       "      <td>UF 033 243</td>\n",
       "      <td>Bachelorstudium; Architektur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>t</td>\n",
       "      <td>UF 033 243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         student_id    study_id  \\\n",
       "15  ekijKawygVR8ULF1NZTkbY7vnKPhz22  UF 033 282   \n",
       "22  aThq4hjnVcaKTvBw7BoN0daZD7PZ1wi  UF 033 243   \n",
       "\n",
       "                                           study_name  term_number  \\\n",
       "15  Bachelorstudium; Wirtschaftsingenieurwesen-Mas...         11.0   \n",
       "22                       Bachelorstudium; Architektur          1.0   \n",
       "\n",
       "   study_level study_label  main_study  \n",
       "15    bachelor           t  UF 033 282  \n",
       "22    bachelor           t  UF 033 243  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students[\"student_id\"] = students[\"student_id\"].astype(str)\n",
    "students[\"study_id\"] = students[\"study_id\"].astype(str)\n",
    "students[\"study_name\"] = students[\"study_name\"].astype(str)\n",
    "students[\"term_number\"] = students[\"term_number\"].astype(float)\n",
    "students[\"study_level\"] = students[\"study_level\"].astype(str)\n",
    "students[\"study_label\"] = students[\"study_label\"].astype(str)\n",
    "\n",
    "complete_cols = [\"student_id\", \"study_id\", \"study_name\", \"study_level\", \n",
    "                 \"study_label\"]\n",
    "assert len(students[complete_cols]) == len(students[complete_cols].dropna())\n",
    "\n",
    "incomplete_cols = [\"term_number\"]\n",
    "N = len(students)\n",
    "for col in incomplete_cols:\n",
    "    print(\"{}: {:1.2f}% missing values\"\\\n",
    "          .format(col, (N - len(students[col].dropna())) / N * 100))\n",
    "students.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecturers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecturer_id</th>\n",
       "      <th>organisation_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MJ5iMmHoY8GVDkpoqUWO1EYznHN1W42</td>\n",
       "      <td>Institut für Städtebau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lfv.0NZ5RRZzndZS6ZsBrZ7sPgZ7ZDi</td>\n",
       "      <td>Institut für Elektrische Antriebstechnik und M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lecturer_id  \\\n",
       "0  MJ5iMmHoY8GVDkpoqUWO1EYznHN1W42   \n",
       "1  lfv.0NZ5RRZzndZS6ZsBrZ7sPgZ7ZDi   \n",
       "\n",
       "                                   organisation_name  \n",
       "0                             Institut für Städtebau  \n",
       "1  Institut für Elektrische Antriebstechnik und M...  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecturers[\"lecturer_id\"] = lecturers[\"lecturer_id\"].astype(str)\n",
    "lecturers[\"organisation_name\"] = lecturers[\"organisation_name\"].astype(str)\n",
    "assert len(lecturers) == len(lecturers.dropna())\n",
    "\n",
    "lecturers.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>course_name</th>\n",
       "      <th>course_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223321</td>\n",
       "      <td>Image Understanding</td>\n",
       "      <td>KU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223319</td>\n",
       "      <td>Selected Topics Computer Vision</td>\n",
       "      <td>KU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   course_id                      course_name course_type\n",
       "0     223321              Image Understanding          KU\n",
       "1     223319  Selected Topics Computer Vision          KU"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses = courses.reset_index()\n",
    "courses[\"course_id\"] = courses[\"course_id\"].astype(int)\n",
    "courses[\"course_name\"] = courses[\"course_name\"].astype(str)\n",
    "courses[\"course_type\"] = courses[\"course_type\"].astype(str)\n",
    "assert len(courses) == len(courses.dropna())\n",
    "courses.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>end_time</th>\n",
       "      <th>group_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>student_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>17:15:00</td>\n",
       "      <td>257028</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>6msRo8506oZT0950nsRHJIIpbGDioIK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>257683</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>6msRo8506oZT0950nsRHJIIpbGDioIK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  end_time group_id start_time                       student_id\n",
       "0 2019-10-01  17:15:00   257028   15:30:00  6msRo8506oZT0950nsRHJIIpbGDioIK\n",
       "1 2019-10-01  14:00:00   257683   12:00:00  6msRo8506oZT0950nsRHJIIpbGDioIK"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_participations[\"student_id\"] = event_participations[\"student_id\"].astype(str)\n",
    "event_participations[\"group_id\"] = event_participations[\"group_id\"].astype(str)\n",
    "event_participations[\"date\"] = event_participations[\"date\"].astype(np.datetime64)\n",
    "\n",
    "assert len(event_participations) == len(event_participations.dropna())\n",
    "\n",
    "event_participations.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>end_time</th>\n",
       "      <th>group_id</th>\n",
       "      <th>lecturer_id</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>14:30:00</td>\n",
       "      <td>255982</td>\n",
       "      <td>1HH4K54Hw1bESQy8bTx7R/JaP0FK1Hu</td>\n",
       "      <td>13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>254912</td>\n",
       "      <td>OximEX6HRL2SFJZEM5VaBkjd8Br2idm</td>\n",
       "      <td>11:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  end_time group_id                      lecturer_id start_time\n",
       "0 2019-10-01  14:30:00   255982  1HH4K54Hw1bESQy8bTx7R/JaP0FK1Hu   13:00:00\n",
       "0 2019-10-01  15:00:00   254912  OximEX6HRL2SFJZEM5VaBkjd8Br2idm   11:00:00"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_supervisions[\"lecturer_id\"] = event_supervisions[\"lecturer_id\"].astype(str)\n",
    "event_supervisions[\"group_id\"] = event_supervisions[\"group_id\"].astype(str)\n",
    "event_supervisions[\"date\"] = event_supervisions[\"date\"].astype(np.datetime64)\n",
    "\n",
    "assert len(event_supervisions) == len(event_supervisions.dropna())\n",
    "\n",
    "event_supervisions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dst = '../../data/clean'\n",
    "\n",
    "enrollment.to_csv(join(processed_dst, 'enrollment.csv'), index=False)\n",
    "supervision.to_csv(join(processed_dst, 'supervision.csv'), index=False)\n",
    "event_dates.to_csv(join(processed_dst, 'event_dates.csv'), index=False)\n",
    "groups.to_csv(join(processed_dst, 'groups.csv'), index=False)\n",
    "rooms.to_csv(join(processed_dst, 'rooms.csv'), index=False)\n",
    "students.to_csv(join(processed_dst, 'students.csv'), index=False)\n",
    "lecturers.to_csv(join(processed_dst, 'lecturers.csv'), index=False)\n",
    "courses.to_csv(join(processed_dst, 'courses.csv'), index=False)\n",
    "event_participations.to_csv(join(processed_dst, 'event_participations.csv'), index=False)\n",
    "event_supervisions.to_csv(join(processed_dst, 'event_supervisions.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code graveyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually add missing studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PH 198 400 420 01',\n",
       " 'PH 198 404 426 01',\n",
       " 'UB 032 331 342',\n",
       " 'UB 190 406 344',\n",
       " 'UB 190 406 347',\n",
       " 'UB 190 406 482',\n",
       " 'UB 190 445 313',\n",
       " 'UB 190 445 412',\n",
       " 'UB 190 456 445',\n",
       " 'UB 198 411 435 01',\n",
       " 'UB 198 423 429 01',\n",
       " 'UB 199 514 520 01',\n",
       " 'UB 796 600 682',\n",
       " 'UE 033 273',\n",
       " 'UF 050 407',\n",
       " 'UF 066 434',\n",
       " 'UF 199 505 520 01',\n",
       " 'UG 033 206',\n",
       " 'UL 033 289'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDs of studies through which students are enrolled in courses and examx, but\n",
    "# which are not recorded in the student table. \n",
    "study_IDs = set(enrollment['study_id'])\n",
    "diff = set(study_IDs).difference(students[\"study_id\"])\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a number of studies through which students are either enrolled in courses or\n",
    "# exams are not contained in the student table. Therefore the name of the study\n",
    "# is missing and we have just the ID. We manually searched for the names of \n",
    "# these studies and add them to the student table here. Since we don't know the \n",
    "# term numbers for the students in these studies, we set them to NaN. \n",
    "missing_studies = enrollment[enrollment['study_id'].isin(diff)]\\\n",
    "    .drop_duplicates(subset=['study_id'])\\\n",
    "    .drop(columns=['course_id', 'group_id'])\n",
    "\n",
    "# manually searched study names\n",
    "missing_studies_names = {\n",
    "    'PH 198 400 420 01':'Lehramtsstudium; UF Bewegung und Sport; UF Mathematik',\n",
    "    'PH 198 404 426 01':'Lehramtsstudium; UF Chemie; UF Russisch',\n",
    "    'UB 032 331 342':'Bachelorstudium; Transkulturelle Kommunikation, Deutsch',\n",
    "    'UB 190 406 344':'Lehramtsstudium; UF Mathematik; UF Englisch',\n",
    "    'UB 190 406 347':'Lehramtsstudium; UF Mathematik; UF Französisch',\n",
    "    'UB 190 406 482':'Lehramtsstudium; UF Mathematik; UF Bewegung und Sport',\n",
    "    'UB 190 445 313':'Lehramtsstudium; UF Biologie und Umweltkunde; UF Geschichte, Sozialkunde, Polit.Bildg.',\n",
    "    'UB 190 445 412':'Lehramtsstudium; UF Biologie und Umweltkunde; UF Physik',\n",
    "    'UB 190 456 445':'Lehramtsstudium; UF Geographie und Wirtschaftskunde; UF Biologie und Umweltkunde',\n",
    "    'UB 198 411 435 01':'Lehramtsstudium; UF Geschichte/Sozialkunde/Polit. Bildung; UF Gestaltung: Technik.Textil',\n",
    "    'UB 198 423 429 01':'Lehramtsstudium; UF Physik; UF Spanisch',\n",
    "    'UB 199 514 520 01':'Lehramtsstudium; UF Informatik; UF Mathematik',\n",
    "    'UB 796 600 682':'Doktoratsstudium; Naturwissenschaften a.d. Naturwiss. Fak.; Physics',\n",
    "    'UE 033 273':'Bachelorstudium; Verfahrenstechnik',\n",
    "    'UF 050 407':'Erweiterungsstudium; UF Darstellende Geometrie',\n",
    "    'UF 066 434':'Masterstudium; Advanced Materials Science',\n",
    "    'UF 199 505 520 01':'Masterstudium; Lehramt Sek (AB) UF Darstellende Geometrie UF Mathematik',\n",
    "    'UG 033 206':'Bachelorstudium; Angewandte Geowissenschaften',\n",
    "    'UL 033 289':'Bachelorstudium; Informationstechnik'\n",
    "}\n",
    "missing_studies['study_name'] = missing_studies['study_id'].replace(missing_studies_names)\n",
    "missing_studies['term_number'] = np.nan\n",
    "\n",
    "# add missing studies to the study df and ensure that all studies of all students\n",
    "# are now contained in both the students and the studies df\n",
    "students = pd.concat([students, missing_studies]).reset_index(drop=True)\n",
    "assert len(study_IDs.difference(set(students['study_id']))) == 0\n",
    "del missing_studies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
