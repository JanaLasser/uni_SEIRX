{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and clean the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from os.path import join\n",
    "import datetime\n",
    "import string\n",
    "import network_creation_functions as ncf\n",
    "from importlib import reload\n",
    "\n",
    "# parallelisation functionality\n",
    "from multiprocess import Pool\n",
    "import psutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '../../data/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_dates.csv\texam_dates.csv\t      missing_study_names.csv\n",
      "course_enrollment.csv\texam_enrollment.csv   rooms.csv\n",
      "courses.csv\t\texam_supervision.csv  students.csv\n",
      "course_supervision.csv\tlecturers.csv\t      study_labels.csv\n"
     ]
    }
   ],
   "source": [
    "! ls ../../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of students with enrolled studies. A student can have more than one study,\n",
    "# which will show up as separate entries (row) for the same student_id. Each\n",
    "# study also has a term number, i.e. the number of semesters the student has\n",
    "# been enrolled in the given study.\n",
    "students = pd.read_csv(join(src, 'students.csv'))\n",
    "\n",
    "# Mapping of lecturers to organisations (institute, faculty). A lecturer can\n",
    "# be associated with more than one organisation.\n",
    "lecturers = pd.read_csv(join(src, 'lecturers.csv'))\n",
    "\n",
    "# List of lectures with information about their type, their name, their module\n",
    "# (this is only relevant for how studies are composed at TU Graz) and the \n",
    "# organisational unit (institute, faculty) which is responsible for the lecture.\n",
    "courses = pd.read_csv(join(src, 'courses.csv'))\n",
    "\n",
    "# List of enrolled students for courses in the WiSe 2019/20. A courses\n",
    "# can have several groups (for example for tutorial parts). The group enrollment\n",
    "# is also listed for every student. It is not completely unique\n",
    "# as there are a number of overlapping groups (for example same time, \n",
    "# different rooms). These are disambiguated at a later point in the data\n",
    "# cleaning process. The data also includes the identifier of the study through \n",
    "# which the student enrolled in a given lecture. \n",
    "course_enrollment = pd.read_csv(join(src, 'course_enrollment.csv'))\n",
    "\n",
    "# List of enrolled students for exams in the WiSe 2019/20.\n",
    "exam_enrollment = pd.read_csv(join(src, 'exam_enrollment.csv'))\n",
    "\n",
    "# List of lecturers which are responsible for lectures and groups within\n",
    "# lectures. Similar to the course enrollment table, the group_id is \n",
    "# disambiguated later in the data cleaning process\n",
    "course_supervision = pd.read_csv(join(src, 'course_supervision.csv'))\n",
    "\n",
    "# List of lecturers which are responsible for exams. Similar to the course \n",
    "# enrollment table, the exam_id is disambiguated later in the data cleaning \n",
    "# process\n",
    "exam_supervision = pd.read_csv(join(src, 'exam_supervision.csv'))\n",
    "\n",
    "# Courses (start time, end time, room) for every course and group in WiSe \n",
    "# 2019/20\n",
    "course_dates = pd.read_csv(join(src, 'course_dates.csv'), \n",
    "                           parse_dates=[\"date\", \"start_time\", \"end_time\"])\n",
    "\n",
    "# Exams (start time, end time, room) for every exam in WiSe 2019/20\n",
    "exam_dates = pd.read_csv(join(src, 'exam_dates.csv'), \n",
    "                           parse_dates=[\"date\"])\n",
    "\n",
    "# List of rooms and information about them (number of seats, square meters).\n",
    "# TU Graz has three campuses: Alte Technik, Neue Technik and Inffeldgasse. The\n",
    "# mapping of every room to a campus is also stored.\n",
    "# Information for rooms outside TU Graz premises was missing. Jana Lasser \n",
    "# manually searched for and filled in room information for rooms at Uni Graz \n",
    "# and added the information to the file /data/raw/Räume.csv. The updated file \n",
    "# is stored in /data/cleaned/Räume_cleaned.csv. These rooms are excluded from\n",
    "# the further analysis anyways though.\n",
    "rooms = pd.read_csv(join(src, 'rooms.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| data | cleaning | checks |\n",
    "| ---- | -------- | ------ |\n",
    "| course dates | dropped: dates outside normal hours, dates longer than 13 hours | no dates outside the semester |\n",
    "| exam dates | dropped: dates outside normal hours, dates without a start time, dates longer than 13 hours| no dates outside the semester, all exams have a supervising lecturer |\n",
    "| course enrollment | dropped: enrollments without dates |\n",
    "| exam enrollment | dropped: enrollments without dates |\n",
    "| courses | dropped: courses without enrollment |\n",
    "| students | dropped: students without enrollments in courses or exams |\n",
    "| course supervision | dropped: lecturers who don't supervise a course or exam |\n",
    "| exam supervision | dropped: lecturers who don't supervise a course or exam |\n",
    "| lecturers | dropped: organisations without active lecturers |\n",
    "| rooms | dropped: rooms without courses or exams |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all course & exam dates occur inside the semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of the semester start\n",
    "semester_start = pd.to_datetime(ncf.semester_start)\n",
    "# date of the semester end\n",
    "semester_end = pd.to_datetime(ncf.semester_end)\n",
    "\n",
    "# Make sure all events take place within the time specified by the semester\n",
    "# start (2019-10-01) and semester end (2020-02-28).\n",
    "assert len(course_dates) == len(course_dates[course_dates['date'] >= semester_start])\n",
    "assert len(course_dates) == len(course_dates[course_dates['date'] <= semester_end])\n",
    "\n",
    "# Make sure all events take place within the time specified by the semester\n",
    "# start (2019-10-01) and semester end (2020-02-28).\n",
    "assert len(exam_dates) == len(exam_dates[exam_dates['date'] >= semester_start])\n",
    "assert len(exam_dates) == len(exam_dates[exam_dates['date'] <= semester_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop course dates that occured outside normal lecture hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 31/29147 courses with a start time later than 8:00 PM\n",
      "dropped 133/29116 courses with a start time earlier than 7:00 AM\n",
      "dropped 0/28983 courses with a start time at 00:00\n"
     ]
    }
   ],
   "source": [
    "# convert the start and end datetime to a time and drop all courses\n",
    "# which occured outside normal lecture hours, i.e. had a start time\n",
    "# before 7:00 AM, after 8:00 PM or at exactly midnight (not covered\n",
    "# by either of the two conditions). We assume these courses are either\n",
    "# erroneous entries or placeholder courses.\n",
    "course_dates['start_time'] = course_dates['start_time'].dt.time\n",
    "course_dates['end_time'] = course_dates['end_time'].dt.time\n",
    "N = len(course_dates)\n",
    "course_dates = course_dates[course_dates['start_time'] <= datetime.time(20, 0)]\n",
    "print('dropped {}/{} courses with a start time later than 8:00 PM'\\\n",
    "      .format(N - len(course_dates), N))\n",
    "N = len(course_dates)\n",
    "course_dates = course_dates[course_dates['start_time'] >= datetime.time(7, 0)]\n",
    "print('dropped {}/{} courses with a start time earlier than 7:00 AM'\\\n",
    "      .format(N - len(course_dates), N))\n",
    "N = len(course_dates)\n",
    "course_dates = course_dates[course_dates['start_time'] >= datetime.time(0, 0)]\n",
    "print('dropped {}/{} courses with a start time at 00:00'\\\n",
    "      .format(N - len(course_dates), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop exams without start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 144/5633 exams without start time\n",
      "2745 (50.01%) exams do not have an end time\n",
      "3517 (64.07%) exams do not have an assigned room\n"
     ]
    }
   ],
   "source": [
    "N = len(exam_dates)\n",
    "exam_dates = exam_dates.dropna(subset=[\"start_time\"])\n",
    "print('dropped {}/{} exams without start time'\\\n",
    "      .format(N - len(exam_dates), N))\n",
    "N = len(exam_dates)\n",
    "print('{} ({:1.2f}%) exams do not have an end time'\\\n",
    "      .format(N - len(exam_dates[\"end_time\"].dropna()), \n",
    "              (N - len(exam_dates[\"end_time\"].dropna())) / N * 100))\n",
    "\n",
    "print('{} ({:1.2f}%) exams do not have an assigned room'\\\n",
    "      .format(N - len(exam_dates[\"room_id\"].dropna()), \n",
    "              (N - len(exam_dates[\"room_id\"].dropna())) / N * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge course and exam dates to event dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_dates = exam_dates.rename(columns={\"exam_id\":\"group_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(timestring):\n",
    "    if timestring != timestring:\n",
    "        return np.nan\n",
    "    else:\n",
    "        hour, minute = timestring.split(':')\n",
    "        return datetime.time(int(hour), int(minute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the start and end time string to a time object\n",
    "exam_dates['start_time'] = exam_dates['start_time']\\\n",
    "    .apply(get_time)\n",
    "exam_dates['end_time'] = exam_dates['end_time']\\\n",
    "    .apply(get_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = pd.concat([course_dates, exam_dates])\n",
    "event_dates = event_dates.reset_index(drop=True)\n",
    "del course_dates\n",
    "del exam_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop events with duration > 780 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 2/34472 events that were longer than 780 minutes\n"
     ]
    }
   ],
   "source": [
    "# Calculate the duration of events and drop all events that have a duration\n",
    "# of more than 13 hours. We assume these events are either erroneous entries \n",
    "# or placeholder events.\n",
    "event_dates['duration'] = event_dates.apply(ncf.calculate_duration, axis=1)\n",
    "duration_threshold = 13 * 60\n",
    "\n",
    "def nan_leq(duration):\n",
    "    '''Returns true in the duration is <= duration_threshold or NaN'''\n",
    "    if duration != duration:\n",
    "        return True\n",
    "    elif duration <= duration_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "N = len(event_dates) \n",
    "event_dates = event_dates[event_dates['duration'].apply(nan_leq)]\n",
    "print(\"dropped {}/{} events that were longer than {} minutes\"\\\n",
    "      .format(N - len(event_dates), N, duration_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge course and exam enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_enrollment = exam_enrollment.rename(columns={\"exam_id\":\"group_id\"})\n",
    "enrollment = pd.concat([course_enrollment, exam_enrollment])\n",
    "enrollment = enrollment.reset_index(drop=True)\n",
    "del course_enrollment\n",
    "del exam_enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop event enrollments without dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 5859/143320 enrollments without dates\n"
     ]
    }
   ],
   "source": [
    "group_IDs = set(event_dates[\"group_id\"])\n",
    "\n",
    "N = len(enrollment)\n",
    "enrollment = enrollment[enrollment[\"group_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} enrollments without dates'\\\n",
    "      .format(N - len(enrollment), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop events dates without enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 4917/34470 event dates without enrollment\n"
     ]
    }
   ],
   "source": [
    "group_IDs = set(enrollment[\"group_id\"])\n",
    "\n",
    "N = len(event_dates)\n",
    "event_dates = event_dates[event_dates[\"group_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} event dates without enrollment'\\\n",
    "      .format(N - len(event_dates), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = set(event_dates[\"group_id\"].unique()).difference(set(enrollment[\"group_id\"].unique()))\n",
    "assert len(diff) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop course supervision entries without enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 465/1853 course supervisions with no enrollment in supervised event\n"
     ]
    }
   ],
   "source": [
    "# filter out lecturers without courses\n",
    "N = len(course_supervision[\"lecturer_id\"].unique())\n",
    "course_supervision = course_supervision[course_supervision[\"group_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} course supervisions with no enrollment in supervised event'\\\n",
    "      .format(N - len(course_supervision[\"lecturer_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop exam supervision entries without enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 20/870 exam supervisions with no enrollment in supervised exam\n"
     ]
    }
   ],
   "source": [
    "# filter out lecturers without courses\n",
    "N = len(exam_supervision[\"lecturer_id\"].unique())\n",
    "exam_supervision = exam_supervision[exam_supervision[\"exam_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} exam supervisions with no enrollment in supervised exam'\\\n",
    "      .format(N - len(exam_supervision[\"lecturer_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge course and exam supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_supervision = exam_supervision.rename(columns={\"exam_id\":\"group_id\"})\n",
    "supervision = pd.concat([course_supervision, exam_supervision])\n",
    "supervision = supervision.reset_index(drop=True)\n",
    "del course_supervision\n",
    "del exam_supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert group IDs to string format, because we are going to add letters to\n",
    "# them for disambiguation\n",
    "enrollment[\"group_id\"] = enrollment[\"group_id\"].astype(int).astype(str)\n",
    "event_dates[\"group_id\"] = event_dates[\"group_id\"].astype(int).astype(str)\n",
    "supervision[\"group_id\"] = supervision[\"group_id\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = enrollment[['course_id', 'group_id']].drop_duplicates().copy()\n",
    "groups = groups[groups['group_id'].isin(event_dates['group_id'].unique())]\n",
    "groups = groups.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disambiguate group IDs for events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_group(date):\n",
    "    '''\n",
    "    Checks whether for a given group id and date there is more than one\n",
    "    event at the same time. If this is the case, the group ID is split into a\n",
    "    number of subgroups equal to the number of events that take place at the\n",
    "    same time. This is done by adding a letter (from \"a\" to \"z\") to the group\n",
    "    ID. Mappings of datetime indices in the event_date data frame to new group \n",
    "    IDs are returned as a data frame.\n",
    "    '''\n",
    "    new_group_ids = pd.DataFrame()\n",
    "    curr_date = event_dates[event_dates[\"date\"] == date]\n",
    "    for group_id in curr_date['group_id']:\n",
    "        # dates that happen at the same time for the same group\n",
    "        group_dates = event_dates[(event_dates['group_id'] == group_id) & \\\n",
    "                            (event_dates['date'] == date)]\n",
    "        # is there more than one date for the same group id on a given day?\n",
    "        # do the duplicate dates start at the same time?\n",
    "        if (len(group_dates) > 1) and \\\n",
    "           (len(group_dates['start_time'].drop_duplicates()) < len(group_dates)):\n",
    "            \n",
    "            # de-duplicate group ids stat start at the same time by adding a \n",
    "            # letter at the end of the id\n",
    "            for dt in group_dates['datetime']:\n",
    "                group_datetimes = group_dates[group_dates['datetime'] == dt]\n",
    "                assert len(group_datetimes) <= len(letter_list)\n",
    "                \n",
    "                for index, letter in zip(group_datetimes.index, letter_list):\n",
    "                    #event_dates.loc[index, 'new_group_id'] = '{}{}'.format(group_id, letter)\n",
    "                    new_group_ids = new_group_ids.append({\n",
    "                        \"index\":index,\n",
    "                        \"new_group_id\":f'{group_id}{letter}'\n",
    "                    }, ignore_index=True)\n",
    "                    \n",
    "    return new_group_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  9.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a temporary datetime entry for easy checking if something happens on\n",
    "# the same day at the same time\n",
    "event_dates[\"datetime\"] = event_dates\\\n",
    "    .apply(lambda x: datetime.datetime.combine(x['date'], x['start_time']), axis=1)\n",
    "\n",
    "# list of letters to append to create new group IDs\n",
    "letter_list = list(string.ascii_lowercase)\n",
    "\n",
    "# do this on many cores to speed it up\n",
    "pool = Pool(15)\n",
    "dates = event_dates['date'].unique()\n",
    "new_group_ids = pd.DataFrame()\n",
    "for IDs in tqdm(\n",
    "        pool.imap_unordered(func=deduplicate_group, iterable=dates), total=len(dates)\n",
    "    ):\n",
    "    new_group_ids = pd.concat([new_group_ids, IDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the old group IDs with the new group IDs on the given \n",
    "# datetimes (indices)\n",
    "new_group_ids[\"index\"] = new_group_ids[\"index\"].astype(int)\n",
    "event_dates[\"new_group_id\"] = event_dates[\"group_id\"]\n",
    "event_dates.loc[new_group_ids[\"index\"].values, \"new_group_id\"] = \\\n",
    "    new_group_ids[\"new_group_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 groups had more than one date on the same day and at the same time and were split into 409 new groups\n"
     ]
    }
   ],
   "source": [
    "# create a list of groups that were split into subgroups for convenience\n",
    "group_splits = event_dates[event_dates[['group_id', 'new_group_id']]\\\n",
    "            .apply(lambda x: x[\"group_id\"] != x[\"new_group_id\"], 1)]\\\n",
    "            [[\"group_id\", \"new_group_id\"]].drop_duplicates()\n",
    "print('{} groups had more than one date on the same day and at the same time '\\\n",
    "      .format(len(group_splits['group_id'].unique())) + \\\n",
    "     'and were split into {} new groups'.format(len(group_splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new group IDs to enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: found a case where there are fewer students than groups!\n",
      "1 students for 2 new groups\n",
      "adding 1 new groups to the list of unused groups\n",
      "WARNING: found a case where there are fewer students than groups!\n",
      "1 students for 6 new groups\n",
      "adding 5 new groups to the list of unused groups\n"
     ]
    }
   ],
   "source": [
    "# We create new enrollment entries for students that are distributed into the\n",
    "# new subgroups. This is needed because some groups are only split into\n",
    "# subgroups on certain dates, while they take place as a single group on other\n",
    "# dates. Therefore for one group there might be events that are assigned to the\n",
    "# original group ID, while other events are assigned to the new group IDs.\n",
    "new_enrollment = pd.DataFrame()\n",
    "\n",
    "# Some new groups are not used, because there are not enough students enrolled\n",
    "# in the original group to populate all new subgroups. We record these unused\n",
    "# groups and remove them from the event_date table later.\n",
    "unused_new_group_IDs = []\n",
    "\n",
    "# iterate over all groups that were split into subgroups and distribute student\n",
    "# enrollment evenly between the new subgroups\n",
    "for group_id in group_splits['group_id'].unique():\n",
    "    # identify all students that were enrolled in the original group\n",
    "    students_in_group = enrollment[enrollment['group_id']  == group_id]\n",
    "    # fetch the newly disambiguated group IDs\n",
    "    new_group_ids = group_splits[\\\n",
    "            group_splits['group_id'] == group_id]['new_group_id'].values\n",
    "    # calculate how many students will be allocated in each of the subgroups\n",
    "    new_group_size = int(len(students_in_group) / len(new_group_ids))\n",
    "    \n",
    "    # make sure the new groups have each at least one student\n",
    "    if new_group_size >= 1:\n",
    "    \n",
    "        # distribute the new students equally to the subgroups\n",
    "        for i, ID in enumerate(new_group_ids[0:-1]):\n",
    "            tmp = students_in_group[\\\n",
    "                    i * new_group_size:(i + 1) * new_group_size].copy()\n",
    "            tmp['group_id'] = ID\n",
    "            new_enrollment = pd.concat([new_enrollment, tmp])\n",
    "        tmp = students_in_group[(i + 1) * new_group_size:].copy()\n",
    "        tmp['group_id'] = new_group_ids[-1]\n",
    "        new_enrollment = pd.concat([new_enrollment, tmp])\n",
    "        \n",
    "    # if this is not the case, assign one student each to the first N subgroups,\n",
    "    # where N is the number of available students. Record the rest of the\n",
    "    # subgroups as \"unused\" to be deleted later\n",
    "    else:\n",
    "        print(\"WARNING: found a case where there are fewer students than groups!\")\n",
    "        print(f\"{len(students_in_group)} students for {len(new_group_ids)} new groups\")\n",
    "        for ID, index in zip(new_group_ids, students_in_group.index):\n",
    "            tmp = students_in_group.loc[index].copy()\n",
    "            tmp['group_id'] = ID\n",
    "            new_enrollment = new_enrollment.append(tmp, ignore_index=True)\n",
    "               \n",
    "        tmp = new_group_ids[len(students_in_group):]\n",
    "        print(f\"adding {len(tmp)} new groups to the list of unused groups\")\n",
    "        unused_new_group_IDs.extend(tmp)\n",
    "        \n",
    "# add the new enrollment information to the enrollment table\n",
    "enrollment = pd.concat([enrollment, new_enrollment]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unused (because of lack of students) new groups again\n",
    "group_splits = group_splits\\\n",
    "    .drop(group_splits[group_splits[\"new_group_id\"].isin(unused_new_group_IDs)].index)\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "# drop event dates for unused groups\n",
    "event_dates = event_dates\\\n",
    "    .drop(event_dates[event_dates[\"new_group_id\"].isin(unused_new_group_IDs)].index)\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "event_dates[\"group_id\"] = event_dates[\"new_group_id\"]\n",
    "event_dates = event_dates.drop(columns=[\"new_group_id\", \"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 55 original group IDs that were completely replaced by new group IDs\n"
     ]
    }
   ],
   "source": [
    "# drop enrollments for groups that were entirely replaced by new groups\n",
    "group_IDs = set(event_dates[\"group_id\"].unique())\n",
    "N = len(enrollment[\"group_id\"].unique())\n",
    "enrollment = enrollment[enrollment[\"group_id\"].isin(group_IDs)]\n",
    "print(\"dropped {} original group IDs that were completely replaced by new group IDs\"\\\n",
    "     .format(N - len(enrollment[\"group_id\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = set(event_dates[\"group_id\"].unique()).difference(set(enrollment[\"group_id\"].unique()))\n",
    "assert len(diff) == 0\n",
    "diff = set(enrollment[\"group_id\"].unique()).difference(set(event_dates[\"group_id\"].unique()))\n",
    "assert len(diff) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new group IDs to supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 split groups have no lecturer now\n"
     ]
    }
   ],
   "source": [
    "new_supervision = pd.DataFrame()\n",
    "lonely_groups = 0\n",
    "\n",
    "for group_id in group_splits['group_id'].unique():\n",
    "    lecturers_in_group = supervision[supervision['group_id']  == group_id]\n",
    "    new_group_ids = group_splits[group_splits['group_id'] == group_id]['new_group_id'].values\n",
    "    new_group_size = int(len(lecturers_in_group) / len(new_group_ids))\n",
    "    \n",
    "    #since we are not cloning lecturers, if there is just one lecturer but two\n",
    "    # groups at the same time, the lecturer will go to only one of the groups\n",
    "    if new_group_size == 1:\n",
    "        lonely_groups += 1\n",
    "    \n",
    "    # distribute the new students equally to the subgroups\n",
    "    for i, ID in enumerate(new_group_ids[0:-1]):\n",
    "        tmp = lecturers_in_group[\\\n",
    "                i * new_group_size:(i + 1) * new_group_size].copy()\n",
    "        tmp['group_id'] = ID\n",
    "        new_supervision = pd.concat([new_supervision, tmp])\n",
    "    tmp = lecturers_in_group[(i + 1) * new_group_size:].copy()\n",
    "    tmp['group_id'] = new_group_ids[-1]\n",
    "    new_supervision = pd.concat([new_supervision, tmp])\n",
    "    \n",
    "print('{} split groups have no lecturer now'.format(lonely_groups))\n",
    "\n",
    "# add the new supervision information to the supervision table\n",
    "supervision = pd.concat([supervision, new_supervision]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 55 original group IDs that were completely replaced by new group IDs\n"
     ]
    }
   ],
   "source": [
    "# drop supervision for groups that were entirely replaced by new groups\n",
    "group_IDs = set(event_dates[\"group_id\"].unique())\n",
    "N = len(supervision[\"group_id\"].unique())\n",
    "supervision = supervision[supervision[\"group_id\"].isin(group_IDs)]\n",
    "print(\"dropped {} original group IDs that were completely replaced by new group IDs\"\\\n",
    "     .format(N - len(supervision[\"group_id\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all supervised groups have event dates\n",
    "diff = set(supervision[\"group_id\"].unique()).difference(set(event_dates[\"group_id\"].unique()))\n",
    "assert len(diff) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 groups have no supervision\n"
     ]
    }
   ],
   "source": [
    "diff = set(event_dates[\"group_id\"].unique()).difference(set(supervision[\"group_id\"].unique()))\n",
    "N_lonely_groups = len(event_dates[event_dates[\"group_id\"].isin(diff)][\"group_id\"].unique())\n",
    "print(f\"{N_lonely_groups} groups have no supervision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226598</td>\n",
       "      <td>260636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221416</td>\n",
       "      <td>258125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   course_id group_id\n",
       "0     226598   260636\n",
       "1     221416   258125"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = enrollment[['course_id', 'group_id']].drop_duplicates().copy()\n",
    "groups = groups[groups['group_id'].isin(event_dates['group_id'].unique())]\n",
    "groups = groups.reset_index(drop=True)\n",
    "groups.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge courses and exams into course table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_exam_courses = pd.DataFrame({\"course_id\":event_dates[~event_dates[\"course_id\"]\\\n",
    "                        .isin(courses[\"course_id\"])][\"course_id\"].unique()})\n",
    "\n",
    "only_exam_courses[\"course_name\"] = np.nan\n",
    "only_exam_courses[\"course_type\"] = \"EX\"\n",
    "courses = pd.concat([courses, only_exam_courses])\n",
    "courses = courses.reset_index(drop=True)\n",
    "del only_exam_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop courses without enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 4581/7542 courses without enrollment\n"
     ]
    }
   ],
   "source": [
    "course_IDs = groups[\"course_id\"].unique()\n",
    "N = len(courses)\n",
    "courses = courses[courses[\"course_id\"].isin(course_IDs)]\n",
    "print('dropped {}/{} courses without enrollment'\\\n",
    "      .format(N - len(courses[\"course_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = event_dates.drop(columns=[\"course_id\"])\n",
    "supervision = supervision.drop(columns=[\"course_id\"])\n",
    "enrollment = enrollment.drop(columns=[\"course_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary student + study identifier\n",
    "enrollment[\"student_study\"] = enrollment.apply(lambda x: x[\"student_id\"] + \"_\" + x[\"study_id\"], axis=1)\n",
    "students[\"student_study\"] = students.apply(lambda x: x[\"student_id\"] + \"_\" + x[\"study_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing student + study from enrollment to student table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 80420 student + study combinations from enrollment to the student table\n"
     ]
    }
   ],
   "source": [
    "diff = set(enrollment[\"student_study\"]).difference(set(students[\"student_study\"]))\n",
    "missing_students = enrollment[enrollment[\"student_study\"].isin(diff)]\\\n",
    "    [[\"student_id\", \"study_id\", \"student_study\"]].copy()\n",
    "missing_students[\"study_name\"] = np.nan\n",
    "missing_students[\"term_number\"] = np.nan\n",
    "students = pd.concat([students, missing_students]).reset_index(drop=True)\n",
    "print(f\"added {len(missing_students)} student + study combinations from enrollment to the student table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop student + study without enrollment from student table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " removed 15525 student + study combination without enrollment from the student table\n"
     ]
    }
   ],
   "source": [
    "N = len(students)\n",
    "students = students[students[\"student_study\"].isin(enrollment[\"student_study\"])]\n",
    "print(f\" removed {N - len(students)} student + study combination without enrollment from the student table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicate student + study combinations from student table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " removed 42328 student + study duplicates from the student table\n"
     ]
    }
   ],
   "source": [
    "N = len(students)\n",
    "students = students.drop_duplicates(subset=[\"student_study\"])\n",
    "print(f\" removed {N - len(students)} student + study duplicates from the student table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(enrollment[\"student_study\"]).difference(set(students[\"student_study\"]))) == 0\n",
    "assert len(set(students[\"student_study\"]).difference(set(enrollment[\"student_study\"]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(enrollment[\"student_id\"]).difference(set(students[\"student_id\"]))) == 0\n",
    "assert len(set(students[\"student_id\"]).difference(set(enrollment[\"student_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(enrollment[\"study_id\"]).difference(set(students[\"study_id\"]))) == 0\n",
    "assert len(set(students[\"study_id\"]).difference(set(enrollment[\"study_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = students.drop(columns=[\"student_study\"])\n",
    "enrollment = enrollment.drop(columns=[\"student_study\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecturers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop lecturers without active supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 3922/5302 lecturers without supervision of course or exam\n"
     ]
    }
   ],
   "source": [
    "# filter out lecturers without courses\n",
    "lecturer_IDs = set(supervision[\"lecturer_id\"])\n",
    "N = len(lecturers[\"lecturer_id\"].unique())\n",
    "lecturers = lecturers[lecturers[\"lecturer_id\"].isin(lecturer_IDs)]\n",
    "print('dropped {}/{} lecturers without supervision of course or exam'\\\n",
    "      .format(N - len(lecturers[\"lecturer_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing supervising lecturers to lecturer table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = set(supervision[\"lecturer_id\"]).difference(set(lecturers[\"lecturer_id\"]))\n",
    "missing_lecturers = supervision[supervision[\"lecturer_id\"].isin(diff)][[\"lecturer_id\"]].copy()\n",
    "missing_lecturers[\"organisation_name\"] = np.nan\n",
    "lecturers = pd.concat([lecturers, missing_lecturers]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(lecturers[\"lecturer_id\"]).difference(set(supervision[\"lecturer_id\"]))) == 0\n",
    "assert len(set(supervision[\"lecturer_id\"]).difference(set(lecturers[\"lecturer_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rooms without courses or exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates[\"room_id\"] = event_dates[\"room_id\"].replace({-999999.0:np.nan})\n",
    "rooms[\"room_id\"] = rooms[\"room_id\"].astype(int)\n",
    "room_IDs = set(event_dates[\"room_id\"].dropna().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 1902/2288 rooms without courses or exams\n",
      "386 rooms remaining\n"
     ]
    }
   ],
   "source": [
    "N = len(rooms[\"room_id\"].unique())\n",
    "rooms = rooms[rooms[\"room_id\"].isin(room_IDs)]\n",
    "print('dropped {}/{} rooms without courses or exams'\\\n",
    "      .format(N - len(rooms[\"room_id\"].unique()), N))\n",
    "\n",
    "# make sure there are no duplicate rooms\n",
    "assert len(rooms) == len(rooms[\"room_id\"].unique())\n",
    "print(f\"{len(rooms)} rooms remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing rooms to room table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{18955, 19956, 22368, 22408, 29134, 29135}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rooms for which there is no information in the room table\n",
    "set(room_IDs).difference(rooms[\"room_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found in KFU room search system\n",
    "room1 = {\"room_id\":18955, \"seats\":np.nan, \"area\":159, \"campus\":\"KFU\",\n",
    " \"address\":\"Universitätsplatz 1\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# found in KFU room search system\n",
    "room2 = {\"room_id\":19956, \"seats\":130, \"area\":147, \"campus\":\"KFU\",\n",
    " \"address\":\"Heinrichstraße 36\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# found in KFU room search system\n",
    "room3 = {\"room_id\":22368, \"seats\":105, \"area\":62, \"campus\":\"KFU\",\n",
    " \"address\":\"Universitätsplatz 5\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# somehwere in the institute for Electronics\n",
    "room4 = {\"room_id\":22408, \"seats\":np.nan, \"area\":np.nan, \"campus\":\"Inffeldgasse\",\n",
    " \"address\":\"Heinrichstraße 36\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# found and measured by hand in TU Graz online room search system\n",
    "room5 = {\"room_id\":29134, \"seats\":np.nan, \"area\":51, \"campus\":\"Alte Technik\",\n",
    " \"address\":\"Technikerstraße 4\", \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "# not found in TU or KFU\n",
    "room6 = {\"room_id\":29135, \"seats\":np.nan, \"area\":np.nan, \"campus\":np.nan,\n",
    " \"address\":np.nan, \"postal_code\":8010, \"city\":\"Graz\"}\n",
    "\n",
    "rooms = rooms.append([room1, room2, room3, room4, room5, room6], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(event_dates[\"room_id\"].dropna()).difference(set(rooms[\"room_id\"]))) == 0\n",
    "assert len(set(rooms[\"room_id\"]).difference(set(event_dates[\"room_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix room address encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_map = {\n",
    "    'Lessingstraï¿½e 25':'Lessingstraße 25',\n",
    "    'Rechbauerstraï¿½e 12':'Rechbauerstraße 12',\n",
    "    'Technikerstraï¿½e 4':'Technikerstraße 4',\n",
    "    'UniversitÃ¤tsplatz 1':'Universitätsplatz 1', \n",
    "    'UniversitÃ¤tsstraÃ\\x9fe 15':'Universitätsstraße 15',\n",
    "    'Mï¿½nzgrabenstraï¿½e 35A':'Münzgrabenstraße 35A',\n",
    "    'HeinrichstraÃ\\x9fe 36':'Heinrichstraße 36',\n",
    "    'Mandellstraï¿½e 11':'Mandellstraße 11',\n",
    "    'Mandellstraï¿½e 13':'Mandellstraße 13',\n",
    "    'UniversitÃ¤tsplatz 6':'Universitätsplatz 6',\n",
    "    'HeinrichstraÃ\\x9fe 28':'Heinrichstraße 28',\n",
    "    'Lessingstraï¿½e 27':'Lessingstraße 27'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms[\"address\"] = rooms[\"address\"].replace(address_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix room missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms[\"postal_code\"] = 8010\n",
    "rooms[\"city\"] = 'Graz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing study names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_names = students[[\"study_id\", \"study_name\"]].dropna().drop_duplicates()\n",
    "# missing mapping of study IDs to study names compiled by hand through google\n",
    "# searches\n",
    "missing_study_names = pd.read_csv(join(src, \"missing_study_names.csv\"))\n",
    "study_names = pd.concat([study_names, missing_study_names])\n",
    "study_name_map = {row[\"study_id\"]:row[\"study_name\"] for i, row in study_names.iterrows()}\n",
    "students[\"study_name\"] = students[\"study_id\"].map(study_name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add study levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_map = ncf.study_map # mapping of studies to degree levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>term_number</th>\n",
       "      <th>study_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ekijKawygVR8ULF1NZTkbY7vnKPhz22</td>\n",
       "      <td>UF 033 282</td>\n",
       "      <td>Bachelorstudium; Wirtschaftsingenieurwesen-Mas...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aThq4hjnVcaKTvBw7BoN0daZD7PZ1wi</td>\n",
       "      <td>UF 033 243</td>\n",
       "      <td>Bachelorstudium; Architektur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         student_id    study_id  \\\n",
       "15  ekijKawygVR8ULF1NZTkbY7vnKPhz22  UF 033 282   \n",
       "22  aThq4hjnVcaKTvBw7BoN0daZD7PZ1wi  UF 033 243   \n",
       "\n",
       "                                           study_name  term_number study_level  \n",
       "15  Bachelorstudium; Wirtschaftsingenieurwesen-Mas...         11.0    bachelor  \n",
       "22                       Bachelorstudium; Architektur          1.0    bachelor  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the text before the semicolon in the study_name field describes (approximately) \n",
    "# the degree and is mapped to a unified pre / post graduate degree scheme that was\n",
    "# informed by Timotheus Hell\n",
    "def get_study_level(study_name):\n",
    "    if study_name != study_name:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return study_map[study_name.split(';')[0]]\n",
    "\n",
    "students['study_level'] = students['study_name'].apply(get_study_level)\n",
    "students.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add study university labels (TU & NAWI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TU Graz offers a wide variety of studies. Some of them in cooperation with\n",
    "# other local universities, such as Uni Graz, the university of arts and\n",
    "# teaching studies (organised Austria-wide). The vast majority of these\n",
    "# collaborative studies are organised under the umbrella of \"NaWi Graz\"\n",
    "# (NaturWissenschaften Graz), in cooperation with Uni Graz. \n",
    "\n",
    "# Students who are enrolled in one of these collaboratively organised studies\n",
    "# have a high chance of having the majority of their classes at the premises \n",
    "# of other universities. We therefore assign the studies to a total of 6\n",
    "# labels, indicating which university they belong to. This will later enable\n",
    "# us to filter by study and exclude students which are not enrolled in \n",
    "# native TU Graz studies.\n",
    "\n",
    "# study labels (supplied by Timotheus Hell):\n",
    "# \"t\": TU Graz study\n",
    "# \"n\": NaWi Graz study (study with uni Graz)\n",
    "# \"l\": teaching study (study with 8 other universities)\n",
    "# \"k\": study with university of arts\n",
    "# \"w\": further training courses\n",
    "# \"a\": other university (includes non-NaWi studies with Uni Graz, former \"u\" label)\n",
    "study_labels = pd.read_csv(join('../../data/raw', 'study_labels.csv'))\n",
    "label_map = {row['study_id']:row['study_label'] for i, row in \\\n",
    "            study_labels.iterrows()}\n",
    "students['study_label'] = students['study_id'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add main study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students can have more than one study. Find a student's main study\n",
    "# by looking at the study id of the individual events they visit.\n",
    "# A student's main study in the given semester is the study from which\n",
    "# the majority of their visited events stems.\n",
    "group_counts = enrollment[['student_id', 'study_id', 'group_id']]\\\n",
    "    .groupby(by=['student_id', 'study_id'])\\\n",
    "    .agg('count')\\\n",
    "    .rename(columns={'group_id':'group_count'})\\\n",
    "    .sort_values(by='group_count', ascending=False)\\\n",
    "    .reset_index()\n",
    "main_studies = group_counts[['student_id', 'study_id']]\\\n",
    "    .drop_duplicates(subset=['student_id'])\\\n",
    "    .set_index('student_id')\n",
    "\n",
    "students[\"main_study\"] = students[\"student_id\"]\\\n",
    "    .apply(lambda x: main_studies.loc[x, \"study_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute event durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to impute missing event durations specific for each event type.\n",
    "# For this purpose, we add course type information to the event_dates data table\n",
    "groups = groups.set_index(\"group_id\")\n",
    "courses = courses.set_index(\"course_id\")\n",
    "\n",
    "event_dates[\"course_id\"] = event_dates[\"group_id\"].apply(lambda x: groups.loc[x])\n",
    "event_dates[\"course_type\"] = event_dates[\"course_id\"].apply(lambda x: courses.loc[x, \"course_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VU (N=4712): missing 4.435%, median duration 120.000 min\n",
      "LU (N=1803): missing 7.543%, median duration 240.000 min\n",
      "VO (N=9349): missing 3.615%, median duration 105.000 min\n",
      "SE (N=3179): missing 12.551%, median duration 105.000 min\n",
      "UE (N=6076): missing 4.460%, median duration 90.000 min\n",
      "KV (N=99): missing 7.071%, median duration 60.000 min\n",
      "PT (N=166): missing 26.506%, median duration 120.000 min\n",
      "KU (N=588): missing 5.272%, median duration 105.000 min\n",
      "PV (N=765): missing 3.399%, median duration 90.000 min\n",
      "SP (N=171): missing 60.819%, median duration 60.000 min\n",
      "OL (N=63): missing 12.698%, median duration 90.000 min\n",
      "RU (N=8): missing 12.500%, median duration 90.000 min\n",
      "RP (N=5): missing 0.000%, median duration 120.000 min\n",
      "EX (N=2562): missing 45.667%, median duration 120.000 min\n",
      "PR (N=1): missing 0.000%, median duration 60.000 min\n"
     ]
    }
   ],
   "source": [
    "# impute event durations based on event type\n",
    "event_dates[\"imputed_duration\"] = False\n",
    "event_dates[\"imputed_end_time\"] = False\n",
    "for course_type in event_dates[\"course_type\"].unique():\n",
    "    course_type_events = event_dates[event_dates[\"course_type\"] == course_type]\n",
    "    median_duration = course_type_events[\"duration\"].median()\n",
    "    N = len(course_type_events)\n",
    "    print(\"{} (N={}): missing {:1.3f}%, median duration {:1.3f} min\"\\\n",
    "          .format(course_type,\n",
    "                  len(course_type_events),\n",
    "                  (N - len(course_type_events[\"duration\"].dropna())) / N * 100,\n",
    "                  median_duration))\n",
    "    \n",
    "    \n",
    "    event_dates.loc[course_type_events.index, \"duration\"] = median_duration\n",
    "    event_dates.loc[course_type_events[\"duration\"].isna().index, \"imputed_duration\"] = True\n",
    "    event_dates.loc[course_type_events[\"duration\"].isna().index, \"imputed_end_time\"] = True\n",
    "\n",
    "# calculate end times for events with imputed durations\n",
    "event_dates[\"end_time\"] = event_dates.apply(ncf.calculate_end_time, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute room areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtK0lEQVR4nO3dfZyVc/7H8denadREqZj61VQrlihRDLFZyl3ui9yum6wI6y5s1CoJEa3bXezGIkoKGW2WtCXJTSlFhRSFprY7jcKUafr8/riuGdN05v6cOTPnvJ+PxzzmnO+5zrm+1zzq+pzv3edr7o6IiAhAnXhXQEREag4FBRERKaSgICIihRQURESkkIKCiIgUUlAQEZFCCgoiIlJIQUGSjpmtMLNcM/vRzP5nZs+a2W4xOE9TM3vVzH4ys2/M7A+lHGtmdreZZZvZD2Y2w8w6FHn9ADObHr62zMzOjHZ9RUBBQZLX6e6+G9AJ6AwMisE5HgN+AZoDFwJPFL3RF3MOcBnwe6Ap8AHwPICZ1QVeAyaHr/UDxpjZfjGosyQ5BQVJau7+P2AKQXCIGjPbFegNDHH3H919FjAJuLiEt7QFZrn71+6eD4wB2oev7Q+0BB5y93x3nw68V8pniVSagoIkNTNrBZwMLCvlmMfNLKeEn09LeNt+QL67f1mk7BOgpJbCi8BvzWw/M0sF+gBvFlQhUrWAA0u5NJFKUVCQZJVlZpuB74C1wNCSDnT3P7l74xJ+DirhbbsBPxQr+wFoWMLxq4F3gSVALkF30o3ha1+EdRxgZqlmdiJwDNCg7MsUqRgFBUlWvdy9IdCNoHtmzyh//o9Ao2JljYDNJRw/FDgMaA3UB4YB082sgbvnAb2AU4H/ATcDE4CVUa6ziIKCJDd3fwd4FvhrSceY2T/CmUqRfhaX8LYvgbpmtm+RsoOBko4/GBjv7ivdfZu7Pws0IRxXcPdP3f0Yd9/D3XsAewNzKnKtIuWhoCACDwMnmFmnSC+6+1XuvlsJPxHHCNz9J2AicKeZ7WpmXYGehDOKIvgIOMfMmptZHTO7GEglHOsws4PMrL6ZNTCzPwMtCIKZSFQpKEjSc/d1wHPAkCh/9J+ANILxgHHA1e6+GMDM2oQtjTbhsfcRDEQvAHIIxhN6u3tO+PrFBOMOa4HjgBPcfWuU6yuCaZMdEREpoJaCiIgUUlAQEZFCCgoiIlJIQUFERArVjXcFqmLPPff0vfbaK97VEBGpVebNm7fe3dMjvVarg8Jee+3F3Llz410NEZFaxcy+Kek1dR+JiEghBQURESmkoCAiIoUUFEREpJCCgoiIFKrVs49ERJJN1vxsRk5ZwqqcXFo2TmNAj3b06pwRtc9XUBARqSWy5mczaOJCcvPyAcjOyWXQxIUAUQsM6j4SEaklRk5ZUhgQCuTm5TNyypKonUNBQUSklliVk1uh8spQUBARqSVaNk6rUHllKCiIiNQSA3q0Iy01ZYeytNQUBvRoF7VzaKBZRKSWKBhM1uwjEREBgsAQzSBQnLqPRESkkIKCiIgUUlAQEZFCCgoiIlJIQUFERArFNCiY2QozW2hmC8xsbljW1MymmtnS8HeTIscPMrNlZrbEzHrEsm4iIrKz6mgpdHf3Tu6eGT4fCExz932BaeFzzKw9cD7QATgJeNzMUiJ9oIiIxEY8uo96AqPDx6OBXkXKX3T3re6+HFgGHF791RMRSV6xDgoOvGVm88ysX1jW3N1XA4S/m4XlGcB3Rd67MiwTEZFqEusVzV3dfZWZNQOmmtkXpRxrEcp8p4OC4NIPoE2bNtGppYiIADFuKbj7qvD3WuBVgu6gNWbWAiD8vTY8fCXQusjbWwGrInzmKHfPdPfM9PT0WFZfRCTpxCwomNmuZtaw4DFwIrAImAT0CQ/rA7wWPp4EnG9m9cysLbAvMCdW9RMRkZ3FsvuoOfCqmRWc5wV3f9PMPgImmFlf4FvgHAB3X2xmE4DPgG3ANe6eH/mjRUQkFmIWFNz9a+DgCOUbgONKeM9wYHis6iQiIqXTimYRESmkoCAiIoUUFEREpJCCgoiIFFJQEBGpTTZsgLFjY/bxCgoiIrXBli0wciTssw9ceil8912Zb6kMBQURkZps+3Z4/nlo1w5uuQWOOgrmz4fWrct+byUoKIiI1FRTp8Khh8Ill0B6OkyfDpMnw4EHxuyUCgoiIjXNJ59Ajx5w4omQkwMvvABz5kD37jE/tYKCiEhN8d13wXhB587w0Ufw4IPwxRdwwQVQp3pu17FOnS0iImXJyYERI+Dhh4PnAwbAwIHQpElp74oJBQURkXjZuhWeeALuugs2boSLLgoe/+Y3cauSuo9ERKqbO4wfDwccADfeCIccAvPmwXPPxTUggIKCiEj1eucd6NIFzj8fGjaEKVOCWUadO8e7ZoCCgohI9fjsMzj9dOjWDVavhmefhY8/DmYY1SAKCiIisbRqFfTrBx07wsyZwYDyl19Cnz6QkhLv2u1EA80iIrGweXOQluKBByAvD66/Hm67DfbcM941K5WCgohINOXlwZNPwh13wLp1wdjB8OGw997xrlm5KCiIiESDO2RlBesLvvwSjj46SElx+OHxrlmFaExBRKSq3n8/SFR31lnBOMG//w0zZtS6gAAKCiIilffll9C7N3TtCl9/DaNGwaefwmmngVm8a1cpCgoiIhW1di1ccw20bw9vvQV33gnLlsEVV0Dd2t0rX7trLyJSnX76CR56CO67D3Jz4cor4fbboXnzeNcsahQURETKsm1bsNjs9tuDhWdnnQX33BNsfJNgFBREREriDv/5D9x6KyxeDEceCS+9FIwhJCiNKYiIRPLRR3DsscGg8S+/wCuvwHvvJXRAAAUFEZEdff11sKnN4YcHrYO//z34fdZZtXZGUUWo+0hEBGDDBrj7bnjssWAG0eDBwWY3jRrFu2bVSkFBRJJbbi48+ijce2+Qr+iyy2DYMGjZMt41iwsFBRFJTvn5MHZs0CL47rtg7GDECOjQId41i6uYjymYWYqZzTezyeHzpmY21cyWhr+bFDl2kJktM7MlZtYj1nUTkST11ltw6KFB+urmzWH69CA1RZIHBKiegeYbgM+LPB8ITHP3fYFp4XPMrD1wPtABOAl43MxqXrJxEam9FiyAHj2Cn02bYNw4mD0bunePd81qjJgGBTNrBZwKPFWkuCcwOnw8GuhVpPxFd9/q7suBZUDtyyYlIjXPt98GrYJDDoG5c4NVyZ9/HqS1rqNJmEXF+q/xMHALsL1IWXN3Xw0Q/m4WlmcA3xU5bmVYtgMz62dmc81s7rp162JSaRFJEDk5wcKz/faD8eOD2URffQX9+0O9evGuXY0Us6BgZqcBa919XnnfEqHMdypwH+Xume6emZ6eXqU6ikiC2ro1aA3ss0+w+9l55wUZTe+7Dxo3jnftarRYzj7qCpxhZqcA9YFGZjYGWGNmLdx9tZm1ANaGx68EWhd5fytgVQzrJyKJZvt2mDAB/vIXWL4cTjgB7r8fOnWKd81qjZi1FNx9kLu3cve9CAaQp7v7RcAkoE94WB/gtfDxJOB8M6tnZm2BfYE5saqfiCSYGTOgS5dgNXKjRjBlSjDLSAGhQuIxwjICOMHMlgInhM9x98XABOAz4E3gGnfPj0P9RKQ2Wbw4WGPQvTusWQOjR8O8eXDiifGuWa1k7jt129camZmZPnfu3HhXQ0TiYdUqGDoUnn4aGjYMuoyuuw7S0uJdsxrPzOa5e2ak17SiWURql02bgsHjBx4I9jm44Qa47TbYY4941ywhKCiISO2QlxfsgTxsGKxbF6wxGD4c9t473jVLKFq1ISI1mztMnBikoLj22mBf5DlzgtXICghRp6AgIjVXwaY2vXtDaipMngxvvw2HHRbvmiUsBQURqXmWLAk2tTnqKFixAp58Ej75BE49NSk2uoknBQURqTnWrIE//SnoKpo6Fe66C5YuhcsvDza+kZjTX1lE4u+nn+DBB4PVx1u2wFVXwe23Q7NmZb9XokpBQUTiZ9s2eOaZIAD8739Bl9G99wYJ7CQuFBREpPq5B4PGt94apLD+3e/glVeC3xJXGlMQker10UdBSoozzgi2xJw4EWbNUkCoIRQURKR6fPVVsODs8MOD1sHjj8OiRXDmmZpRVIOo+0hEYmvDhmAW0eOPB2sNhgwJNrtp2DDeNZMIFBREJDZyc+HRR4OB482boW9fuOMOaNky3jWTUigoiEh05efDmDEweDCsXAmnnw4jRgTpKaTGU1AQkUrLmp/NyClLWJWTS8vGaYxsuJrfjbofPv0UMjPh+eehW7d4V1MqQEFBRCola342gyYuJDcvnw5rvuLW8c/yuxXz+SmjDbu++CKccw7U0VyW2kZBQUQqZeSUJTRdv5qb3n2eMxfP4If6uzHsuCt4u9tZzDjvpHhXTypJQUFEKm7jRi559TEunfdvAP7ZpTdPHHE2m+rvhv2oXXRrMwUFESm/rVvhscfg7ru5IieHiR2O5cHfX8iqRr/mKGrZWNth1mYKCiJStu3bYfz4YB/kFSugRw9m/PFmhizKJzfv15ZBWmoKA3q0i189pco0CiQipXv77WAV8h/+AI0bw1tvwZtvcux5J3DvWR3JaJyGARmN07j3rI706pwR7xpLFailICKRLVoEAwfC669D69bw3HNw4YU7zCjq1TlDQSDBqKUgIjvKzg42tTn44CBR3f33w5dfwsUXa4ppElBLQUQCmzYFAeDBB4N9Dm64AW67DfbYI941k2qkoCCS7H75BUaNgmHDYP16uOACGD4c2raNd80kDtQWFElW7sHGNh06wHXXwYEHBnsdvPCCAkISU0tBJEEVz0s0oEe7XweFZ80K0ld/+GEQFF5/HU4+WfsaiIKCSCIqmpcIIDsnl0ETF7Lbiq84/rmHICsLWrSAp56CPn2grm4FEtC/BJEENHLKkh0Wle3500ZueG8c3e55E3bdFe6+G/r3Dx6LFBGzoGBm9YGZQL3wPC+7+1AzawqMB/YCVgDnuvvG8D2DgL5APnC9u0+JVf1EEtmqnFwAGvySy+UfZXHl7FfYJT+PFzqdzCVvPA3NmpXxCZKsYtlS2Aoc6+4/mlkqMMvM3gDOAqa5+wgzGwgMBG41s/bA+UAHoCXwXzPbz92VXUukglo33IWu707ixlljafbTRv6z3+8YeUwfftn7t1yigCCliFlQcHcHfgyfpoY/DvQEuoXlo4EZwK1h+YvuvhVYbmbLgMOBD2JVR5GE4w6TJzP5XzfTaPlSPspoz1Vn/oWPMw4gLTWFe5WXSMoQ0zEFM0sB5gG/BR5z99lm1tzdVwO4+2ozK/jakgF8WOTtK8Oy4p/ZD+gH0KZNm1hWX6RCSp3tUx3mzAlmFM2cSaP99mP2A09x09a9WPXDFjLiUR+plcodFMzsQKA9UL+gzN2fK+09YddPJzNrDLwafkaJp4j0ERE+cxQwCiAzM3On10XioaTZPkDsb8RffRVkL50wIRgrePxxuPxyuqSm8l5szywJqFyL18xsKPC38Kc7cD9wRnlP4u45BN1EJwFrzKxF+LktgLXhYSuB1kXe1gpYVd5ziMRT8dk+ALl5+YycsiR2J12/PkhFccABMHky3H47LFsGV18NqamxO68ktPKuaD4bOA74n7v/ETiYYFZRicwsPWwhYGZpwPHAF8AkoE94WB/gtfDxJOB8M6tnZm2BfYE55b8UkfgpmO1T3vIqyc2FESNgn33g73+HP/4xCAbDhkHDhtE/nySV8nYf5br7djPbZmaNCL7d713Ge1oAo8NxhTrABHefbGYfABPMrC/wLXAOgLsvNrMJwGfANuAazTyS2qJl4zSyIwSAqO5Clp8Pzz8PQ4bAypVw+ulBcGjfPnrnkKRX3qAwN/zW/yTBwPGPlPEt3t0/BTpHKN9A0OqI9J7hwPBy1kmkxhjQo90OYwoQxV3I3GHKFLjlFli4EA47DMaMgWOOqfpnixRTrqDg7n8KH/7DzN4EGoU3fRHh18HkqM8+mj8/mFE0bRrsvXewJeY55yhHkcRMuYKCmRlwIbC3u99pZm3M7HB3V5+/SCiqu5B98w0MHhy0CPbYAx5+GK66CuqVOpQnUmXlHWh+HDgSuCB8vhl4LCY1EklmGzcGLYP99oOXXw62w1y2LJhlpIAg1aC8Ywpd3P0QM5sP4O4bzWyXGNZLJLls3QqPPRYkqsvJCTKX3nlnsDeySDUqb0shL5xF5BBMNwW2x6xWIsli+/ZgU5v994ebb4YuXWDBAnjmGQUEiYvyBoVHgVeBZmY2HJgF3BOzWokkg+nTg5lEF14IjRvD1Knwxhtw0EHxrpkksTK7j8ysDrAcuIVgKqkBvdz98xjXTSQxLVwIt94aBIA2bYK1B3/4A9TR7rgSf2UGhXDR2gPufiTBimQRqYzs7CAVxbPPQqNGMHIkXHst1K9f5ltFqkt5B5rfMrPewMQwJbaIhMrMjvrDD3D//fDQQ8Gq5P79gwR2e+wRtzqLlKS8QeEmYFdgm5ltIehCcndvFLOaidQCpWZH7ZAO//xnMIto/fqgi+juu6Ft23hWWaRU5V3R3DDcRnNfiqTOFkl2EbOj/rKNj/46il5zXgjWGHTvHnQVHXponGopUn7lXdF8OXADQTrrBcARwPuUkMNIJFkUz4KauXIxt01/ms6rl0CHDvD663DyyUpLIbVGeac73AAcBnzj7t0JEt2tj1mtRGqJgiyo+2z4jlET7+blsbfSYvM67un9Z/jkEzjlFAUEqVXKO6awxd23mBlmVs/dvzAzbfYqSW/woU34YeADnD3/TXJT63H/0Zcw7sgzGXreYZCSEu/qiVRYeYPCyjB1dhYw1cw2ol3RJJn9+CM88AAnjxzJ9q1bmXjEGdybeQ71W/4fQ7UXstRi5R1oPjN8eIeZvQ3sDrwZs1qJ1FTbtsG//gVDh8KaNXD22dS55x7O3ndfzo533USioLwthULu/k4sKiJSo7nDpElB1tIvvoCuXSErC444It41E4mqCgcFkepQ5oKw6jR7dpDO+t13oV27IBiccYYGkCUhKdmK1DgFC8Kyc3Jxfl0QljU/u3orsmwZnHtu0BpYsgSeeAIWLYKePRUQJGEpKEiNE3FBWF4+I6csqZ4KrFsXbGrTvn2wzmDo0CBAXHUV1FXjWhKb/oXXADWqq6QGKL4grKzyqPn5Z3jkERgxIphddPnlcMcd0KJFbM8rUoOopRBnNaarpAYpWBBW3vIqy88PNrXZb78gUV23bkE30T//qYAgSUdBIc7i3lVSAw3o0Y601B0XfqWlpjCgR5TXS7rDm29C585w2WWQkQHvvAOvvQYHHBDdc4nUEgoKcRa3rpIarFfnDO49qyMZjdMwIKNxGvee1TG6XWoffwwnnBDkJfr5Z5gwAT78EI4+OnrnEKmFNKYQZy0bp5EdIQDErKuklujVOSM24yorVsDgwTB2bLCfwaOPwpVXwi67RP9cIrWQWgpxVm1dJQkka342XUdMp+3A1+k6Ynr5xl++/x7+/OdgncErr8CgQfDVV3DddQoIIkWopRBnBd+GNfuofErd1CbS32zLFnjsMRg+HHJy4NJLg01vWrWqvkqL1CIKCjVAzLpKElBpA/M7/A23b4dx4+C22+Cbb+Ckk+C+++Cgg6q5xiK1i4KC1CrlGpifNi1ISzF/fjCz6Kmn4PjjK3QerR2RZBWzMQUza21mb5vZ52a22MxuCMubmtlUM1sa/m5S5D2DzGyZmS0xsx6xqpvUXiUNwO+elsrF/Z9ixt6ZcPzx/Lx6LYwZA3PnViogaO2IJKtYDjRvA2529wMItu+8xszaAwOBae6+LzAtfE742vlAB+Ak4HEz0y4lsoNIA/Otf9zA4Il/ZfQj/ei86gvu7n4ZR176OFntu0Gdiv8T19oRSWYx6z5y99XA6vDxZjP7HMgAegLdwsNGAzOAW8PyF919K7DczJYBhwMfxKqOUvsUHZjfvGY9f16QxbmzXsF8O08d1ovHjjyXH9IagrPzOEM5ae2IJLNqGVMws70I9nWeDTQPAwbuvtrMmoWHZQAfFnnbyrCs+Gf1A/oBtGnTJoa1lpqqV4d0es2aCGPuhPXryWrfjb8efTErd2++w3GVvYlr7Ygks5ivUzCz3YBXgP7uvqm0QyOU+U4F7qPcPdPdM9PT06NVTakN3OGll4LspddfH8wkmjuXkRcP2SkgQNk38ZLWO2jtiCSzmLYUzCyVICCMdfeJYfEaM2sRthJaAGvD8pVA6yJvb4X2gU4qg7MWMm72d+S7k2LGBV1ac3evjsGL774bLD6bMwcOPBD+859gmqkZA+rsuHYByr6Jl2e9g2YfSTIy952+jEfng82MYMzge3fvX6R8JLDB3UeY2UCgqbvfYmYdgBcIxhFaEgxC7+vu+Tt/eiAzM9Pnzp0bk/pL9RqctZAxH367U/mNGdu44b9PB1thZmTAXXfBJZdAyo7f5Cs6hbTriOkRu4gyGqfx3sBjq35BIjWYmc1z98xIr8WypdAVuBhYaGYLwrK/ACOACWbWF/gWOAfA3Reb2QTgM4KZS9eUFhAksYyb/d0Oz9N/3MiNs8Zy3qdvwW67wj33BBvfNGgQ8f0VXQCowWSRyGI5+2gWkccJAI4r4T3DgeGxqpPU3EVZ+WGLtcEvufSbM5Er5rzKLvl5PHfIqfzxjX9BlMePNJgsEplWNCeRCucNqka7+HbOWfAm/d97gfSfcpjc7ihGHnMJK5tm8McYTCgY0KNdhcchRJKBgkISKStvUFxaEe4waRLvje1PevYK5rRqT78zBzM/Y38ALurSuowPqBwNJotEpqCQRErrR49LK+LDD4McRbNmkd6uHWMGPsJQ34d82Hn2UQwoEaHIzhQUkkhp/ejlzj4aDUuXBnshv/wyNG8O//gH9O3LRXXrclF0zyQiFaRNdpJIaYuyqmU2zrp1waY27dvDG2/AHXfAsmXBzmd19f1EpCbQ/8RaqjL9/6X1o4+csiR2s3F+/hkefhhGjAgeX345DB0KLVpU/bNFJKpitnitOiTr4rXi/f8QfOOvyub2kT7TCPKMZFR2EDY/H0aPhiFDYNUq6NkT7r0XDjigUnUUkegobfGauo9qoVikdu7VOYN7z+pIRtgyKAgIUIn9BNyDNBSdOkHfvtC6NcycCVlZCggiNZyCQi0Uq/7/Xp0zeG/gsWQ0TtspE2G5g868ecGmNqeeCrm5QQK7Dz6A3/++xLeUlJhORKqfgkItVFI/f7RW45YUXLJzcku+aa9YARdeCJmZ8Omn8Oij8NlncPbZYCUtbNcuZyI1jYJCLRTr1M6lBZedbtrffw833wzt2sHEicFU02XLgllGu+xS5rlivcuZWiEiFaOgUAsV7f83goHgqgwyFxcp6BSVm5fPoBc+4p7ufdmU8Rv8oYeCVsLSpTB8OOy+e7nPFcupsGqFiFScpqTWUrFajVsw1TU3L58Us8JEdQXMt9Pzs3f488znaLVpHW/vfSgPHd+Xy646g16tKl6fWCamq9YFeSIJQkFBChWfllo8IHRdsYBBM57hwDVfsbD5Ptxy8g28v1cnoPL7IccyMZ3SY4tUnIKCFIr0zRpg/7XLGTTjGY5Z/jErGzXj+tP/zL8POBq3X3sfK3ujjWViOqXHFqk4BQUpVPzG3mLTOm56dyy9F01jc70G3N39Mp4/5DS21t15ALkqN9pYdYUpPbZIxSkoSKGCb9YNt/7E1R++xGVzJ2G+nScPP5PHjziHH9IaAjsubIOae6NVemyRilNQqMWivf/BLce2ZdGQ+7n63RdomruJV9t344GjL2bl7s0Lj0lLTaH3oRm8/cW6WnGjVXpskYpRUKjBSrvpR3X/A3d46SV6DhpEz6+/Zu4+nbnkqD5s3L8j3fdPrzUBQESqTkEhxir7bb6sm37UplvOnBlsdDNnDnTsCG+8QWaPHkwuZRWyiCQuLV6LoaosniprpW+Vp1t+/jmccQYccwxkZ8Mzz8D8+XDSSaWmpRCRxKagEENVSeFQ1k2/0vmPVq8ONrU58EB4550glfWXX8Kll0JKyauYRSQ5KCjEUFW+zZd1069w/qPNm4ONbX77W3j6abj22iBH0cCB0KBBmfURkeSgoBBDVclmWtJNv/v+6XQdMZ0bxy+gXt06NGmQWnr+o7w8eOKJIBjceSecdlrQdfTII5CeXtlLE5EEpYHmGKrK4qlIc+y775/OK/OyCz8vJzePtNQUHjqv087BwB1eey1oCSxZEuxnMGkSdOkSvQsUkYSjoFBFpc0uquriqeJz7LuOmF6+GUcffBDMKHrvPVakt2H4WUP4LPMYBuzSil5Vu1wRSXAKClUwOGshYz/8dqdtKyG4oUd7cVmZYxRLl8KgQfDKK2zZI517TrmOsR2OJ79OCvywpfLrGEQkaSgoVFLW/OwdAkKBorOLora4LFRSgrf2dbcEA8f//CfUqwfDhnGaH8qyYocqbbSIlEUDzZU0csqSnQJCgVU5uTHZUaz44HP9vC30nz2BrIcvhX/8A664IphRdPvtfFXCBCeljRaR0sQsKJjZ02a21swWFSlramZTzWxp+LtJkdcGmdkyM1tiZj1iVa9oKe3m2rJxWkxy+RfsuNa60S6c98lbvPvUlfSf8RypJxwPixbB44/D//1fYR1KqpuISEli2X30LPB34LkiZQOBae4+wswGhs9vNbP2wPlAB6Al8F8z28/dd07uXw0GZy1k3OzvyHenjkG9unXYkrd9h3GBkrpyDOi+f3rh+4tzYK+Br9OkQSpDT+9Qsa4cd5rPmsboR4ey95oVLGp9AJ8/9CRHX3bmTocqbbSIVEbMWgruPhP4vlhxT2B0+Hg0FE6G6Qm86O5b3X05sAw4PFZ1K83grIWM+fDbwhv6dofcvO07panovn/kOf6/bbYrr8zLjhgQitr4cx79xy+g7cDXGZy1sNRjs+Zn0/faJ3h/r04ceX0f7JetXN1zIKddcD9XLk+LmDajoFXRpEFqYVm9uuotFJHSVfdAc3N3Xw3g7qvNrFlYngF8WOS4lWHZTsysH9APoE2bNlGv4NgPvy319bLGBb5e93OZAaEoB8aE57y7V8edXn9r8gfUHfgX/rV4BhvSGnH78VcyrtNJ5KWk7lCfSC2Oud98T87PeYXPc3LzNANJREpVU746RsrAFvHO6u6j3D3T3TPTo7wiN2t+domDx0Vl5+RG7DqCnfc1Lq9xs7/bsWDDBrjpJrr1OobjlnzA3448j2OufIrnDj29MCAUrU/x1kJ5ZkeJiBRX3S2FNWbWImwltADWhuUrgdZFjmsFrKrmupX7Zll857FoKAwmW7bA3/4Gw4fD5s282uE4Hvz9haxpuGep779x/AL6j19ARjjuUdbsKBGRSKq7pTAJ6BM+7gO8VqT8fDOrZ2ZtgX2BOdVct3LfLKMdEADq4vD889CuHdxyC3TtCgsW8OgfBpYZEIrWqWDco6SWDGgGkoiULJZTUscBHwDtzGylmfUFRgAnmNlS4ITwOe6+GJgAfAa8CVwTj5lH8bpZHrV8Pq89cwNccgk5DXaHadPg9dehY8eIifHKkpuXT0oJeyIYaAaSiJTIvJJ94DVBZmamz507N2qflzU/m/7jF0Tt88pywNqvGTjjWY5Z/jErGzXj/mMu4b8Hdeee3gcDv+ZMatwgFfdgoDjFrNzjFmmpKTtMSTXgwiPaRBzQFpHkYWbz3D0z0mtKc1GMWZBgNJZabFrHze+O4axF09lUf1fu6t6X5w85jV/qpsI258bxC3bootr4cx4GdN2nKSs2BIPcZY1rFB1biOb+ytHO5yQiNYuCQqhg68xYBoRGW37k6g9f5o/zJmHujDr8TB4/8lw21d9th+MiVcGB9776fofnVux3gYJFasWzrFZVWftGi0jtp6AQipSrKFpS8/O4aP5/uO798TTN3cQrHbrz4O8vJnv3ZmW/uRRO7FoEkZSWz0lBQSQxKCiEYjJN053TvniXATOf4zc5/2PWbw7m3u6Xsbj5PlE7xaqc3Ki3CEo7V0XKRaT2UVAIlZTLqLK6fLuQQTOeptPqpXyevheXnDOMmW0PCQYtQhUZNC5Jdc6YKulvpCmuIomjpqxojrvKTP2M5Lfrv+Wpl4cxftwgmv24kZtPuZFTL32EmXsfukNASK1T9YBQ3QnuSto3WlNcRRKHWgqhgu6Xyk5JbbZ5A/3fe4HzPp3KT6n1ue+YPjx96BlsTa0X8fi87RULCBnhHs1vf7GuymMHlZ1BVNXtRUWk5tM6hWK6jpheoW6kXbf+TL85E7nio1epm5/PmM6n8LffncfGBrtHrU4GLB9x6k7llbm5F59BBMG3/XvP6qibu0iS0DqFChjQo125Wgt187dx/idTuOG9caT/nMPk/X/P/UdfwrdNWkS9TsX77LPmZzPs34vZWCQDanmnh2oGkYiURkGhotzpsfQDbnlnNPt8n83s1gdyRe8hLGhZ9X71xmmpbN22vdSNcSJ90y9Qnpu7ZhCJSGkUFIopLVPqISs/5y8zniYz+3OW7tGavr2HMG2fw3cYQK6KO87oUFiHgi6h7vunM3LKEm4cv4CWjdP4+Zdtpa6nKOvmrhlEIlIaBYUiBmdFzi7a9vtsbnlnNCd/+T5rd23CwB7X8tJBJ5Bfp+qzlQoYv3b7FPyOtIK4LHXMyJqfXWJrQdt0ikhpFBRCBdtwFrXHTzlc//44/rDgTbbW3YUHjrqQpw47k9xd6kf9/BcesfMucpVZZZ3vXurYgmYQiUhpkjIoRJq1U3Tns7RfttB3bhZXzX6F+nlbGdfpJB7pegHrd20S9bqkmHFBl9YRM5dWtp+/rLGF6loBLSK1T9IFhZKSuuW7k7I9n7MX/pebZo2l+Y/f8+Z+R3L/0X34eo9WMalLRuM03ht4bImvV2WVtQaORaQyki4oRJyS+cs2un89l4EznqHd+m+Z13J//tRzIPNatY9ZPQr68UtbaxCp/7+ojHBwWAPHIhItSRcUin+D7rh6KX+Z8TRHfruQ5U1acFWvQby53++iNqMokoLMpkCpqagLgkPxNQmw4+CwBo5FJFqSLigUdMm0zvkfA2Y+xxmfz2R9g90ZcsJVjDv4JLalxO5PUnTl8IVPfrDD/ggFcvPy6T9+ASOnLNlhT4SyVi9r4FhEoiHp0lxkzc9m4kNjeWrsbeTXSeHJw3oxqktvfqzXIEa1DGQUuVmXFBCKU/oJEYkFpbkoolfnDOaffhxPL5nNM5lnsKbhnjE9X+O0VBYMPXGHsvIEBFD6CRGpfkkXFAAmfLqW3O6Xxfw8xq+rlCtLs4hEpDol5X4KuXnbY34OI1iQVtVv+ZpFJCLVKemCwuCshTE/R4oZD53XKeKCNICu+zSNWF6n2IQnzSISkeqWdEFh7Oxvyz6oCtJSU3jg3INLbSGMveLInQJD132a8uC5nchonIYRDExrkFlEqlvSjSnEYrKVAc6OM4zKMvaKIyOWKwiISDwlXVCItiYNUhl6egfdzEUkISgoVNH8208s+yARkVoi6cYUmjRIjdpnZWhmkIgkmKQLCkNP70Bqyo7TfFJTjIuOaFM4yNukQSqpxacCFaOZQSKSiGpc95GZnQQ8AqQAT7n7iGh+fnk3mSmea6j7/um8/cU65RcSkYRWo3IfmVkK8CVwArAS+Ai4wN0/i3R8ZXIfiYgku9JyH9W07qPDgWXu/rW7/wK8CPSMc51ERJJGTQsKGcB3RZ6vDMsKmVk/M5trZnPXrVtXrZUTEUl0NS0oRBrd3aF/y91HuXumu2emp6dXU7VERJJDTQsKK4HWRZ63AlbFqS4iIkmnpgWFj4B9zaytme0CnA9MinOdRESSRo2afQRgZqcADxNMSX3a3YeXcuw64JtKnmpPYH0l31ub6bqTi647uZT3un/j7hH732tcUKguZja3pClZiUzXnVx03cklGtdd07qPREQkjhQURESkUDIHhVHxrkCc6LqTi647uVT5upN2TEFERHaWzC0FEREpRkFBREQKJV1QMLOTzGyJmS0zs4Hxrk80mdnTZrbWzBYVKWtqZlPNbGn4u0mR1waFf4clZtYjPrWuOjNrbWZvm9nnZrbYzG4IyxP62s2svpnNMbNPwuseFpYn9HUXMLMUM5tvZpPD5wl/3Wa2wswWmtkCM5sblkX3ut09aX4IFsR9BewN7AJ8ArSPd72ieH1HA4cAi4qU3Q8MDB8PBO4LH7cPr78e0Db8u6TE+xoqed0tgEPCxw0J0q+3T/RrJ8gVtlv4OBWYDRyR6Ndd5PpvAl4AJofPE/66gRXAnsXKonrdydZSSOjU3O4+E/i+WHFPYHT4eDTQq0j5i+6+1d2XA8sI/j61jruvdvePw8ebgc8Jsusm9LV74MfwaWr44yT4dQOYWSvgVOCpIsUJf90liOp1J1tQKDM1dwJq7u6rIbh5As3C8oT8W5jZXkBngm/NCX/tYRfKAmAtMNXdk+K6CVLh3AJsL1KWDNftwFtmNs/M+oVlUb3uGrcdZ4yVmZo7iSTc38LMdgNeAfq7+yazEvfZTphrd/d8oJOZNQZeNbMDSzk8Ia7bzE4D1rr7PDPrVp63RCirddcd6uruq8ysGTDVzL4o5dhKXXeytRSSMTX3GjNrARD+XhuWJ9TfwsxSCQLCWHefGBYnxbUDuHsOMAM4icS/7q7AGWa2gqAL+FgzG0PiXzfuvir8vRZ4laA7KKrXnWxBIRlTc08C+oSP+wCvFSk/38zqmVlbYF9gThzqV2UWNAn+BXzu7g8WeSmhr93M0sMWAmaWBhwPfEGCX7e7D3L3Vu6+F8H/4enufhEJft1mtquZNSx4DJwILCLa1x3v0fQ4jN6fQjA75SvgtnjXJ8rXNg5YDeQRfEvoC+wBTAOWhr+bFjn+tvDvsAQ4Od71r8J1H0XQLP4UWBD+nJLo1w4cBMwPr3sRcHtYntDXXexv0I1fZx8l9HUTzJr8JPxZXHD/ivZ1K82FiIgUSrbuIxERKYWCgoiIFFJQEBGRQgoKIiJSSEFBREQKKSiIVBMz62Vm7eNdD5HSKCiIVJ9eBJkrRWosrVMQKYdwBekEglQBKcBdBFknHwR2A9YDl7r7ajO7AuhHkJ59GXAx0AmYDPwQ/vQmyPJ5FbAN+Mzdz6/GSxKJSEFBpBzMrDdwkrtfET7fHXgD6Onu68zsPKCHu19mZnu4+4bwuLuBNe7+NzN7lmD17cvha6uAtu6+1cwae5C/SCSuki1LqkhlLQT+amb3EXzj3wgcSJCpEoLWw+rw2APDYNCYoBUxpYTP/BQYa2ZZQFasKi5SEQoKIuXg7l+a2aEEOZXuBaYCi939yAiHPwv0cvdPzOxSgvw8kZxKsFveGcAQM+vg7tuiXXeRitBAs0g5mFlL4Gd3HwP8FegCpJvZkeHrqWbWITy8IbA6TOd9YZGP2Ry+hpnVAVq7+9sEm8U0JmhViMSVWgoi5dMRGGlm2wmy0F5NMED8aDi+UJdgN7DFwBCCnd++Ieh2ahh+xovAk2Z2PUHK53+F7zXgIY0pSE2ggWYRESmk7iMRESmkoCAiIoUUFEREpJCCgoiIFFJQEBGRQgoKIiJSSEFBREQK/T8VOUlh9jFZ8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset = rooms[[\"seats\", \"area\"]].dropna().copy()\n",
    "subset[\"area\"] = subset[\"area\"].astype(float)\n",
    "subset[\"seats\"] = subset[\"seats\"].astype(int)\n",
    "subset[\"area_per_seat\"] = subset[\"area\"] / subset[\"seats\"]\n",
    "\n",
    "good_seat_info = subset[subset[\"area_per_seat\"] > 0.5]\n",
    "bad_seat_info = subset[subset[\"area_per_seat\"] <= 0.5]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(good_seat_info[\"seats\"], good_seat_info[\"area\"])\n",
    "ax.set_xlabel(\"seats\")\n",
    "ax.set_ylabel(\"area\")\n",
    "\n",
    "cor = good_seat_info[[\"area\", \"seats\"]].corr().loc[\"area\", \"seats\"]\n",
    "\n",
    "# since we have both cases with existing seat info but missing area info and\n",
    "# existing area info but missing seat info, we do both regressions to recover\n",
    "# the coefficients\n",
    "slope_seats, intercept_seats, rvalue, pvalue, stderr = \\\n",
    "    linregress(good_seat_info[\"seats\"], good_seat_info[\"area\"])\n",
    "\n",
    "slope_area, intercept_area, rvalue, pvalue, stderr = \\\n",
    "    linregress(good_seat_info[\"area\"], good_seat_info[\"seats\"])\n",
    "\n",
    "x = np.arange(1, good_seat_info[\"seats\"].max())\n",
    "y = intercept_seats + slope_seats * x\n",
    "ax.plot(x, y, color=\"red\")\n",
    "ax.set_title(\"R = {:1.2f}\".format(cor));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms[\"imputed_area\"] = False\n",
    "rooms[\"imputed_seats\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputing 104 rooms with bad area info using information from 230 trustworthy rooms\n",
      "imputing 49 rooms with missing areas\n",
      "imputing 3 rooms with missing seats\n",
      "imputing 6 rooms with both missing area and missing seats\n"
     ]
    }
   ],
   "source": [
    "# impute areas of rooms with existing but most likely faulty area information\n",
    "print(f\"imputing {len(bad_seat_info)} rooms with bad area info using information from {len(good_seat_info)} trustworthy rooms\")\n",
    "rooms.loc[bad_seat_info.index, \"area\"] = \\\n",
    "    round(bad_seat_info[\"seats\"] * slope_seats + intercept_seats, 1)\n",
    "rooms.loc[bad_seat_info.index, \"imputed_area\"] = True\n",
    "\n",
    "# impute areas of rooms with missing area information\n",
    "missing_areas = rooms[(rooms[\"area\"].isna()) & (~rooms[\"seats\"].isna())].index\n",
    "print(f\"imputing {len(missing_areas)} rooms with missing areas\")\n",
    "rooms.loc[missing_areas, \"area\"] = \\\n",
    "    round(rooms.loc[missing_areas, \"seats\"] * slope_seats + intercept_seats, 1)\n",
    "rooms.loc[missing_areas, \"imputed_area\"] = True\n",
    "\n",
    "# impute seats of rooms with missing seat information\n",
    "rooms[\"area\"] = rooms[\"area\"].astype(float)\n",
    "missing_seats = rooms[(rooms[\"seats\"].isna()) & (~rooms[\"area\"].isna())].index\n",
    "print(f\"imputing {len(missing_seats)} rooms with missing seats\")\n",
    "rooms.loc[missing_seats, \"seats\"] = \\\n",
    "    (rooms.loc[missing_seats, \"area\"] * slope_area + intercept_area).astype(int)\n",
    "rooms.loc[missing_seats, \"imputed_seats\"] = True\n",
    "\n",
    "# impute the rest of the rooms where both seats and areas are missing with the\n",
    "# median values of areas and seats of the most trustworthy part of the data\n",
    "missing_everything = rooms[rooms[\"seats\"].isna()].index\n",
    "print(f\"imputing {len(missing_everything)} rooms with both missing area and missing seats\")\n",
    "rooms.loc[missing_everything, \"seats\"] = rooms.loc[good_seat_info.index, \"seats\"].median()\n",
    "rooms.loc[missing_everything, \"imputed_seats\"] = True\n",
    "rooms.loc[missing_everything, \"area\"] = rooms.loc[good_seat_info.index, \"area\"].median()\n",
    "rooms.loc[missing_everything, \"imputed_area\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure data types & completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZGurrNFKVy4WmDRc7OT8uA58EnrAJ22</td>\n",
       "      <td>UF 033 253</td>\n",
       "      <td>260636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xtah2duSvN2/1mA/1fvGoo.ldOOpuYa</td>\n",
       "      <td>UF 033 253</td>\n",
       "      <td>258125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        student_id    study_id group_id\n",
       "1  ZGurrNFKVy4WmDRc7OT8uA58EnrAJ22  UF 033 253   260636\n",
       "2  xtah2duSvN2/1mA/1fvGoo.ldOOpuYa  UF 033 253   258125"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollment[\"student_id\"] = enrollment[\"student_id\"].astype(str)\n",
    "enrollment[\"study_id\"] = enrollment[\"study_id\"].astype(str)\n",
    "enrollment[\"group_id\"] = enrollment[\"group_id\"].astype(str)\n",
    "assert len(enrollment) == len(enrollment.dropna())\n",
    "enrollment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecturer_id</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hbYTpbGOGwYPqn425psX7oZSNXGSM9i</td>\n",
       "      <td>258144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jMfY6T8kg95Ehsa80LAjAVEpAi6jDUm</td>\n",
       "      <td>263699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lecturer_id group_id\n",
       "0  hbYTpbGOGwYPqn425psX7oZSNXGSM9i   258144\n",
       "1  jMfY6T8kg95Ehsa80LAjAVEpAi6jDUm   263699"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervision[\"lecturer_id\"] = supervision[\"lecturer_id\"].astype(str)\n",
    "supervision[\"group_id\"] = supervision[\"group_id\"].astype(str)\n",
    "assert len(supervision) == len(supervision.dropna())\n",
    "supervision.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_id: 11.90% missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room_id</th>\n",
       "      <th>date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>group_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>course_id</th>\n",
       "      <th>course_type</th>\n",
       "      <th>imputed_duration</th>\n",
       "      <th>imputed_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27716.0</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>10:15:00</td>\n",
       "      <td>12:15:00</td>\n",
       "      <td>269598</td>\n",
       "      <td>120</td>\n",
       "      <td>227979</td>\n",
       "      <td>VU</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27716.0</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>10:15:00</td>\n",
       "      <td>12:15:00</td>\n",
       "      <td>269598</td>\n",
       "      <td>120</td>\n",
       "      <td>227979</td>\n",
       "      <td>VU</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   room_id       date start_time  end_time group_id  duration  course_id  \\\n",
       "0  27716.0 2019-10-25   10:15:00  12:15:00   269598       120     227979   \n",
       "1  27716.0 2020-01-31   10:15:00  12:15:00   269598       120     227979   \n",
       "\n",
       "  course_type  imputed_duration  imputed_end_time  \n",
       "0          VU              True              True  \n",
       "1          VU              True              True  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_dates[\"group_id\"] = event_dates[\"group_id\"].astype(str)\n",
    "event_dates[\"course_id\"] = event_dates[\"course_id\"].astype(int)\n",
    "event_dates[\"course_type\"] = event_dates[\"course_type\"].astype(str)\n",
    "event_dates[\"duration\"] = event_dates[\"duration\"].astype(int)\n",
    "event_dates[\"imputed_duration\"] = event_dates[\"imputed_duration\"].astype(bool)\n",
    "event_dates[\"date\"] = event_dates[\"date\"].astype(np.datetime64)\n",
    "\n",
    "complete_cols = [\"date\", \"group_id\", \"course_id\", \"course_type\", \"duration\",\n",
    "                 \"imputed_duration\", \"start_time\", \"end_time\"]\n",
    "assert len(event_dates[complete_cols]) == len(event_dates[complete_cols].dropna())\n",
    "\n",
    "incomplete_cols = [\"room_id\"]\n",
    "\n",
    "N = len(event_dates)\n",
    "for col in incomplete_cols:\n",
    "    print(\"{}: {:1.2f}% missing values\"\\\n",
    "          .format(col, (N - len(event_dates[col].dropna())) / N * 100))\n",
    "event_dates.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260636</td>\n",
       "      <td>226598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258125</td>\n",
       "      <td>221416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group_id  course_id\n",
       "0   260636     226598\n",
       "1   258125     221416"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = groups.reset_index()\n",
    "groups[\"group_id\"] = groups[\"group_id\"].astype(str)\n",
    "groups[\"course_id\"] = groups[\"course_id\"].astype(int)\n",
    "assert len(groups) == len(groups.dropna())\n",
    "groups.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campus: 0.26% missing values\n",
      "address: 1.28% missing values\n"
     ]
    }
   ],
   "source": [
    "rooms[\"room_id\"] = rooms[\"room_id\"].astype(int)\n",
    "rooms[\"seats\"] = rooms[\"seats\"].astype(int)\n",
    "rooms[\"area\"] = rooms[\"area\"].astype(float)\n",
    "rooms[\"postal_code\"] = rooms[\"postal_code\"].astype(int)\n",
    "rooms[\"city\"] = rooms[\"city\"].astype(str)\n",
    "rooms[\"imputed_area\"] = rooms[\"imputed_area\"].astype(bool)\n",
    "rooms[\"imputed_seats\"] = rooms[\"imputed_seats\"].astype(bool)\n",
    "\n",
    "complete_cols = [\"room_id\", \"seats\", \"area\", \"postal_code\", \"city\",\n",
    "                 \"imputed_area\", \"imputed_seats\"]\n",
    "assert len(rooms[complete_cols]) == len(rooms[complete_cols].dropna())\n",
    "\n",
    "incomplete_cols = [\"campus\", \"address\"]\n",
    "N = len(rooms)\n",
    "for col in incomplete_cols:\n",
    "    print(\"{}: {:1.2f}% missing values\"\\\n",
    "          .format(col, (N - len(rooms[col].dropna())) / N * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term_number: 81.01% missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>term_number</th>\n",
       "      <th>study_level</th>\n",
       "      <th>study_label</th>\n",
       "      <th>main_study</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ekijKawygVR8ULF1NZTkbY7vnKPhz22</td>\n",
       "      <td>UF 033 282</td>\n",
       "      <td>Bachelorstudium; Wirtschaftsingenieurwesen-Mas...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>t</td>\n",
       "      <td>UF 033 282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aThq4hjnVcaKTvBw7BoN0daZD7PZ1wi</td>\n",
       "      <td>UF 033 243</td>\n",
       "      <td>Bachelorstudium; Architektur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>t</td>\n",
       "      <td>UF 033 243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         student_id    study_id  \\\n",
       "15  ekijKawygVR8ULF1NZTkbY7vnKPhz22  UF 033 282   \n",
       "22  aThq4hjnVcaKTvBw7BoN0daZD7PZ1wi  UF 033 243   \n",
       "\n",
       "                                           study_name  term_number  \\\n",
       "15  Bachelorstudium; Wirtschaftsingenieurwesen-Mas...         11.0   \n",
       "22                       Bachelorstudium; Architektur          1.0   \n",
       "\n",
       "   study_level study_label  main_study  \n",
       "15    bachelor           t  UF 033 282  \n",
       "22    bachelor           t  UF 033 243  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students[\"student_id\"] = students[\"student_id\"].astype(str)\n",
    "students[\"study_id\"] = students[\"study_id\"].astype(str)\n",
    "students[\"study_name\"] = students[\"study_name\"].astype(str)\n",
    "students[\"term_number\"] = students[\"term_number\"].astype(float)\n",
    "students[\"study_level\"] = students[\"study_level\"].astype(str)\n",
    "students[\"study_label\"] = students[\"study_label\"].astype(str)\n",
    "\n",
    "complete_cols = [\"student_id\", \"study_id\", \"study_name\", \"study_level\", \n",
    "                 \"study_label\"]\n",
    "assert len(students[complete_cols]) == len(students[complete_cols].dropna())\n",
    "\n",
    "incomplete_cols = [\"term_number\"]\n",
    "N = len(students)\n",
    "for col in incomplete_cols:\n",
    "    print(\"{}: {:1.2f}% missing values\"\\\n",
    "          .format(col, (N - len(students[col].dropna())) / N * 100))\n",
    "students.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecturers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecturer_id</th>\n",
       "      <th>organisation_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MJ5iMmHoY8GVDkpoqUWO1EYznHN1W42</td>\n",
       "      <td>Institut für Städtebau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lfv.0NZ5RRZzndZS6ZsBrZ7sPgZ7ZDi</td>\n",
       "      <td>Institut für Elektrische Antriebstechnik und M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lecturer_id  \\\n",
       "0  MJ5iMmHoY8GVDkpoqUWO1EYznHN1W42   \n",
       "1  lfv.0NZ5RRZzndZS6ZsBrZ7sPgZ7ZDi   \n",
       "\n",
       "                                   organisation_name  \n",
       "0                             Institut für Städtebau  \n",
       "1  Institut für Elektrische Antriebstechnik und M...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecturers[\"lecturer_id\"] = lecturers[\"lecturer_id\"].astype(str)\n",
    "lecturers[\"organisation_name\"] = lecturers[\"organisation_name\"].astype(str)\n",
    "assert len(lecturers) == len(lecturers.dropna())\n",
    "lecturers.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>course_name</th>\n",
       "      <th>course_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223321</td>\n",
       "      <td>Image Understanding</td>\n",
       "      <td>KU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223319</td>\n",
       "      <td>Selected Topics Computer Vision</td>\n",
       "      <td>KU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   course_id                      course_name course_type\n",
       "0     223321              Image Understanding          KU\n",
       "1     223319  Selected Topics Computer Vision          KU"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses = courses.reset_index()\n",
    "courses[\"course_id\"] = courses[\"course_id\"].astype(int)\n",
    "courses[\"course_name\"] = courses[\"course_name\"].astype(str)\n",
    "courses[\"course_type\"] = courses[\"course_type\"].astype(str)\n",
    "assert len(courses) == len(courses.dropna())\n",
    "courses.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dst = '../../data/clean'\n",
    "\n",
    "enrollment.to_csv(join(processed_dst, 'enrollment.csv'), index=False)\n",
    "supervision.to_csv(join(processed_dst, 'supervision.csv'), index=False)\n",
    "event_dates.to_csv(join(processed_dst, 'event_dates.csv'), index=False)\n",
    "groups.to_csv(join(processed_dst, 'groups.csv'), index=False)\n",
    "rooms.to_csv(join(processed_dst, 'rooms.csv'), index=False)\n",
    "students.to_csv(join(processed_dst, 'students.csv'), index=False)\n",
    "lecturers.to_csv(join(processed_dst, 'lecturers.csv'), index=False)\n",
    "courses.to_csv(join(processed_dst, 'courses.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code graveyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student enrolled studies from long to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773/13220 students have more than one study\n"
     ]
    }
   ],
   "source": [
    "N_students = len(students[\"student_id\"].unique())\n",
    "N_multiple_studies = (students[\"student_id\"].value_counts() > 1).sum()\n",
    "print(f\"{N_multiple_studies}/{N_students} students have more than one study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_studies = students[\"student_id\"].value_counts().max()\n",
    "\n",
    "new_students = pd.DataFrame({\"student_id\":students[\"student_id\"].unique()})\n",
    "for study in range(1, max_studies + 1):\n",
    "    new_students[f\"study_id_{study}\"] = np.nan\n",
    "    new_students[f\"study_name_{study}\"] = np.nan\n",
    "new_students = new_students.set_index(\"student_id\")\n",
    "\n",
    "for student_id in new_students.index:\n",
    "    student_df = students[students[\"student_id\"] == student_id]\n",
    "    if len(student_df) == 1:\n",
    "        new_students.loc[student_id, \"study_id_1\"] = \\\n",
    "            student_df[\"study_id\"].values[0]\n",
    "        new_students.loc[student_id, \"study_name_1\"] = \\\n",
    "            student_df[\"study_name\"].values[0]\n",
    "    else:\n",
    "        j = 1\n",
    "        for index, row in student_df.iterrows():\n",
    "            new_students.loc[student_id, f\"study_id_{j}\"] = \\\n",
    "                row[\"study_id\"]\n",
    "            new_students.loc[student_id, f\"study_name_{j}\"] = \\\n",
    "                row[\"study_name\"]\n",
    "            j += 1\n",
    "            \n",
    "students = new_students.reset_index()\n",
    "\n",
    "# make sure that there are no students with more than one study anymore\n",
    "assert len(students) == len(students[\"student_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecturer affiliation from long to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/1492 lecturers have more than one affiliation\n"
     ]
    }
   ],
   "source": [
    "N_lectureres = len(lecturers[\"lecturer_id\"].unique())\n",
    "N_double_affiliations = (lecturers[\"lecturer_id\"].value_counts() > 1).sum()\n",
    "print(f\"{N_double_affiliations}/{N_lectureres} lecturers have more than one affiliation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_affiliations = lecturers[\"lecturer_id\"].value_counts().max()\n",
    "\n",
    "new_lecturers = pd.DataFrame({\"lecturer_id\":lecturers[\"lecturer_id\"].unique()})\n",
    "for affiliation in range(1, max_affiliations + 1):\n",
    "    new_lecturers[f\"organisation_id_{affiliation}\"] = np.nan\n",
    "    new_lecturers[f\"organisation_name_{affiliation}\"] = np.nan\n",
    "new_lecturers = new_lecturers.set_index(\"lecturer_id\")\n",
    "\n",
    "for lecturer_id in new_lecturers.index:\n",
    "    lecturer_df = lecturers[lecturers[\"lecturer_id\"] == lecturer_id]\n",
    "    if len(lecturer_df) == 1:\n",
    "        new_lecturers.loc[lecturer_id, \"organisation_name_1\"] = \\\n",
    "            lecturer_df[\"organisation_name\"].values[0]\n",
    "        new_lecturers.loc[lecturer_id, \"organisation_id_1\"] = \\\n",
    "            int(lecturer_df[\"organisation_id\"].values[0])\n",
    "    else:\n",
    "        j = 1\n",
    "        for index, row in lecturer_df.iterrows():\n",
    "            #print(j)\n",
    "            new_lecturers.loc[lecturer_id, f\"organisation_id_{j}\"] = \\\n",
    "                int(row[\"organisation_id\"])\n",
    "            new_lecturers.loc[lecturer_id, f\"organisation_name_{j}\"] = \\\n",
    "                row[\"organisation_name\"]\n",
    "            j += 1\n",
    "            \n",
    "lecturers = new_lecturers.reset_index()\n",
    "\n",
    "# make sure that there are no lecturers with more than one affiliation anymore\n",
    "assert len(lecturers) == len(lecturers[\"lecturer_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check enrollment time overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def check_time_conflict(student_id):\n",
    "    dates = event_dates['date'].unique()\n",
    "    student_groups = enrollment.loc[student_id].index\n",
    "    student_events = event_dates[event_dates[\"group_id\"].isin(student_groups)]\n",
    "    \n",
    "    drop_indices = []\n",
    "    conflict_days = 0\n",
    "    conflicts = 0\n",
    "    for date in dates:\n",
    "        student_date_events = student_events[student_events[\"date\"] == date]\n",
    "        if len(student_date_events) > 1:\n",
    "            tmp = check_conflict(student_id, student_date_events)\n",
    "            if len(tmp) > 0:\n",
    "                drop_indices.extend(tmp)\n",
    "                conflict_days += 1\n",
    "                conflicts += len(tmp)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return student_id, conflict_days, conflicts, drop_indices\n",
    "        \n",
    "def check_conflict(student_id, times):\n",
    "    times = times\\\n",
    "        .dropna(subset=[\"start_time\", \"end_time\"])\\\n",
    "        .sort_values(by=\"start_time\", ascending=True)\\\n",
    "        .reset_index()\n",
    "    \n",
    "    drop_indices = []\n",
    "    for i in range(1, len(times)):\n",
    "        if times.loc[i][\"start_time\"] < times.loc[i - 1][\"end_time\"]:\n",
    "            drop_indices.append(resolve_conflict(student_id, times.loc[i], times.loc[i - 1]))\n",
    "    return drop_indices\n",
    "    \n",
    "\n",
    "def resolve_conflict(student_id, event1, event2):\n",
    "    # get the studies through which the student enrolled in the events\n",
    "    study1 = enrollment.loc[student_id, event1[\"group_id\"]][\"study_id\"].values[0]\n",
    "    study2 = enrollment.loc[student_id, event2[\"group_id\"]][\"study_id\"].values[0]\n",
    "    main_study = main_studies.loc[student_id].values[0]\n",
    "    \n",
    "    #print(event1)\n",
    "    \n",
    "    if main_study == study1:\n",
    "        drop_index = event2[\"index\"]\n",
    "    elif main_study == study2:\n",
    "        drop_index = event1[\"index\"]\n",
    "    else:\n",
    "        drop_index = [event1[\"index\"], event2[\"index\"]][np.random.choice([0, 1])]\n",
    "    return drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students can have more than one study. Find a student's main study\n",
    "# by looking at the study id of the individual events they visit.\n",
    "# A student's main study in the given semester is the study from which\n",
    "# the majority of their visited events stems.\n",
    "group_counts = enrollment[['student_id', 'study_id', 'group_id']]\\\n",
    "    .groupby(by=['student_id', 'study_id'])\\\n",
    "    .agg('count')\\\n",
    "    .rename(columns={'group_id':'group_count'})\\\n",
    "    .sort_values(by='group_count', ascending=False)\\\n",
    "    .reset_index()\n",
    "main_studies = group_counts[['student_id', 'study_id']]\\\n",
    "    .drop_duplicates(subset=['student_id'])\\\n",
    "    .set_index('student_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "#enrollment = enrollment.reset_index()\n",
    "student_ids = enrollment[\"student_id\"].unique()[0:10]\n",
    "enrollment = enrollment.set_index([\"student_id\", \"group_id\"])\n",
    "enrollment = enrollment.sort_index()\n",
    "\n",
    "# do this on many cores to speed it up\n",
    "\n",
    "pool = Pool(1)\n",
    "conflicts = pd.DataFrame({\n",
    "    \"student_id\":student_ids,\n",
    "    \"conflict_days\":[np.nan] * len(student_ids),\n",
    "    \"conflicts\":[np.nan] * len(student_ids)})\n",
    "conflicts = conflicts.set_index(\"student_id\")\n",
    "\n",
    "drop_indices = []\n",
    "for student_id, c_days, c, indices in tqdm(\n",
    "        pool.imap_unordered(func=check_time_conflict, \n",
    "                            iterable=student_ids), total=len(student_ids)):\n",
    "    conflicts.loc[student_id] = c\n",
    "    drop_indices.extend(indices)\n",
    "    \n",
    "# 71.6% of students have at least one timing conflict on at least one day\n",
    "enrollment = enrollment.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency check group IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix group ID consistency with course IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 course ID(s) difference\n"
     ]
    }
   ],
   "source": [
    "# Two course IDs from the enrollment table have a different group ID in the\n",
    "# supervision table than in the enrollment table\n",
    "\n",
    "# the group IDs in the enrollment table are the ground truth\n",
    "group_IDs = set(enrollment[\"group_id\"])\n",
    "supervision_course_IDs = set(supervision[supervision[\"group_id\"].isin(group_IDs)][\"course_id\"].unique())\n",
    "diff = course_IDs.difference(supervision_course_IDs)\n",
    "print(f\"{len(diff)} course ID(s) difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the enrollment group IDs serve as our reference in the below iteration,\n",
    "# I do not want to change them during the iteration. I therefore collect all\n",
    "# necessary changes in a dict and apply them all at once at the end\n",
    "group_ID_swap_dict = {}\n",
    "\n",
    "for course_ID in list(diff):\n",
    "    enrollment_courses = enrollment[enrollment[\"course_id\"] == course_ID]\n",
    "    supervision_courses = supervision[supervision[\"course_id\"] == course_ID]\n",
    "    N_enrollment_groups = len(enrollment_courses[\"group_id\"].unique())\n",
    "    N_supervision_groups = len(supervision_courses[\"group_id\"].unique())\n",
    "    \n",
    "    # there are as many groups in enrollment as they are in supervision, but the\n",
    "    # group IDs are mismatched: match the group IDs from enrollment to the \n",
    "    # supervision table\n",
    "    if N_enrollment_groups == N_supervision_groups:\n",
    "        for group_ID_enrollment, group_ID_supervision in \\\n",
    "            zip(enrollment_courses[\"group_id\"].unique(), supervision_courses[\"group_id\"].unique()):\n",
    "            supervision.loc[supervision[\"group_id\"] == group_ID_supervision, \"group_id\"] = group_ID_enrollment\n",
    "    \n",
    "    # there is only one group ID in enrollment but many in the supervision \n",
    "    # table: overwrite all group IDs in the supervision table with the one ID \n",
    "    # from enrollment\n",
    "    elif N_enrollment_groups == 1:\n",
    "        supervision.loc[supervision[\"group_id\"].isin(supervision_courses[\"group_id\"]), \"group_id\"] = \\\n",
    "            enrollment_courses[\"group_id\"].unique()[0]\n",
    "        \n",
    "    # there is only one group ID in supervision but many in the enrollment: \n",
    "    # overwrite all group IDs in the enrollment table with the one ID from \n",
    "    # the supervision table\n",
    "    elif N_supervision_groups == 1:\n",
    "        for group_ID in enrollment_courses[\"group_id\"].unique():\n",
    "            assert group_ID not in group_ID_swap_dict.keys()\n",
    "            group_ID_swap_dict[group_ID] = supervision_courses[\"group_id\"].unique()[0]\n",
    "            \n",
    "    else:\n",
    "        print(\"this shouldn't happen ...\")\n",
    "        break\n",
    "        \n",
    "# map the new group IDs from the event dates to the enrollment data\n",
    "enrollment[\"group_id\"] = enrollment[\"group_id\"].replace(group_ID_swap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 course ID(s) difference\n"
     ]
    }
   ],
   "source": [
    "# the group IDs in the enrollment table are the ground truth\n",
    "group_IDs = set(enrollment[\"group_id\"])\n",
    "event_course_IDs = set(event_dates[event_dates[\"group_id\"].isin(group_IDs)][\"course_id\"].unique())\n",
    "diff = course_IDs.difference(event_course_IDs)\n",
    "print(f\"{len(diff)} course ID(s) difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the enrollment group IDs serve as our reference in the below iteration,\n",
    "# I do not want to change them during the iteration. I therefore collect all\n",
    "# necessary changes in a dict and apply them all at once at the end\n",
    "group_ID_swap_dict = {}\n",
    "\n",
    "for course_ID in list(diff):\n",
    "    enrollment_courses = enrollment[enrollment[\"course_id\"] == course_ID]\n",
    "    event_date_courses = event_dates[event_dates[\"course_id\"] == course_ID]\n",
    "    N_enrollment_groups = len(enrollment_courses[\"group_id\"].unique())\n",
    "    N_event_date_groups = len(event_date_courses[\"group_id\"].unique())\n",
    "    \n",
    "    # there are as many groups in enrollment as they are in events, but the\n",
    "    # group IDs are mismatched: match the group IDs from enrollment to the event\n",
    "    # date table\n",
    "    if N_enrollment_groups == N_event_date_groups:\n",
    "        for group_ID_enrollment, group_id_event_dates in \\\n",
    "            zip(enrollment_courses[\"group_id\"].unique(), event_date_courses[\"group_id\"].unique()):\n",
    "            event_dates.loc[event_dates[\"group_id\"] == group_id_event_dates, \"group_id\"] = group_ID_enrollment\n",
    "    \n",
    "    # there is only one group ID in enrollment but many in the events: overwrite\n",
    "    # all group IDs in the event date table with the one ID from enrollment\n",
    "    elif N_enrollment_groups == 1:\n",
    "        event_dates.loc[event_dates[\"group_id\"].isin(event_date_courses[\"group_id\"]), \"group_id\"] = \\\n",
    "            enrollment_courses[\"group_id\"].unique()[0]\n",
    "        \n",
    "    # there is only one group ID in event dates but many in the enrollment: \n",
    "    # overwrite all group IDs in the enrollment table with the one ID from \n",
    "    # the event dates\n",
    "    elif N_event_date_groups == 1:\n",
    "        for group_ID in enrollment_courses[\"group_id\"].unique():\n",
    "            assert group_ID not in group_ID_swap_dict.keys()\n",
    "            group_ID_swap_dict[group_ID] = event_date_courses[\"group_id\"].unique()[0]\n",
    "    \n",
    "    # there is more than one group ID in enrollment and more than one in the\n",
    "    # event date table, the number does not match but the number of group IDs\n",
    "    # in the event date table is smaller than the number of groups from \n",
    "    # enrollment: map the group IDs from enrollment evenly to the group IDs from\n",
    "    # the event date table.\n",
    "    elif N_event_date_groups < N_enrollment_groups:\n",
    "        enrollment_group_IDs = enrollment_courses[\"group_id\"].unique()\n",
    "        batch_size = int(N_enrollment_groups / N_event_date_groups)\n",
    "        for i, event_group_ID in enumerate(event_date_courses[\"group_id\"].unique()[0:-1]):\n",
    "            enrollment_group_ID_batch = enrollment_group_IDs[i * batch_size: (i + 1) * batch_size]\n",
    "            for enrollment_group_ID in enrollment_group_ID_batch:\n",
    "                 group_ID_swap_dict[enrollment_group_ID] = event_group_ID\n",
    "        enrollment_group_ID_batch = enrollment_group_IDs[(i + 1) * batch_size:]\n",
    "        for enrollment_group_ID in enrollment_group_ID_batch:\n",
    "                 group_ID_swap_dict[enrollment_group_ID] = event_group_ID\n",
    "    else:\n",
    "        print(\"this shouldn't happen ...\")\n",
    "        break\n",
    "        \n",
    "# map the new group IDs from the event dates to the enrollment data\n",
    "enrollment[\"group_id\"] = enrollment[\"group_id\"].replace(group_ID_swap_dict)\n",
    "# need to apply the mapping to supervision too, in case one of the group IDs\n",
    "# that was changed in enrollment also appears there\n",
    "supervision[\"group_id\"] = supervision[\"group_id\"].replace(group_ID_swap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 course ID(s) difference\n"
     ]
    }
   ],
   "source": [
    "# the group IDs in the enrollment table are the ground truth\n",
    "group_IDs = set(enrollment[\"group_id\"])\n",
    "event_date_course_IDs = set(event_dates[event_dates[\"group_id\"].isin(group_IDs)][\"course_id\"].unique())\n",
    "diff = course_IDs.difference(event_date_course_IDs)\n",
    "print(f\"{len(diff)} course ID(s) difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop events and supervision of groups that have no enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_IDs = set(enrollment[\"group_id\"])\n",
    "supervision = supervision[supervision[\"group_id\"].isin(group_IDs)]\n",
    "event_dates = event_dates[event_dates[\"group_id\"].isin(group_IDs)]\n",
    "\n",
    "supervision_course_IDs = set(supervision[supervision[\"group_id\"]\\\n",
    "                                    .isin(group_IDs)][\"course_id\"].unique())\n",
    "event_date_course_IDs = set(event_dates[event_dates[\"group_id\"]\\\n",
    "                                    .isin(group_IDs)][\"course_id\"].unique())\n",
    "\n",
    "diff = course_IDs.difference(supervision_course_IDs)\n",
    "assert len(diff) == 0\n",
    "\n",
    "diff = course_IDs.difference(event_date_course_IDs)\n",
    "assert len(diff) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop group enrollments without dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 511/8116 group enrollments without dates\n"
     ]
    }
   ],
   "source": [
    "group_IDs = set(event_dates[\"group_id\"])\n",
    "#exam_IDs = set(exam_dates[\"exam_id\"])\n",
    "\n",
    "N = len(enrollment[\"group_id\"].unique())\n",
    "enrollment = enrollment[enrollment[\"group_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} group enrollments without dates'\\\n",
    "      .format(N - len(enrollment[\"group_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop group supervision without dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 509/8089 group supervision without dates\n"
     ]
    }
   ],
   "source": [
    "group_IDs = set(event_dates[\"group_id\"])\n",
    "#exam_IDs = set(exam_dates[\"exam_id\"])\n",
    "\n",
    "N = len(supervision[\"group_id\"].unique())\n",
    "supervision = supervision[supervision[\"group_id\"].isin(group_IDs)]\n",
    "print('dropped {}/{} group supervision without dates'\\\n",
    "      .format(N - len(supervision[\"group_id\"].unique()), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(event_dates[\"group_id\"]).difference(set(enrollment[\"group_id\"]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 events have no supervision\n"
     ]
    }
   ],
   "source": [
    "diff = set(event_dates[\"group_id\"]).difference(set(supervision[\"group_id\"]))\n",
    "print(f\"{len(diff)} events have no supervision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually add missing studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PH 198 400 420 01',\n",
       " 'PH 198 404 426 01',\n",
       " 'UB 032 331 342',\n",
       " 'UB 190 406 344',\n",
       " 'UB 190 406 347',\n",
       " 'UB 190 406 482',\n",
       " 'UB 190 445 313',\n",
       " 'UB 190 445 412',\n",
       " 'UB 190 456 445',\n",
       " 'UB 198 411 435 01',\n",
       " 'UB 198 423 429 01',\n",
       " 'UB 199 514 520 01',\n",
       " 'UB 796 600 682',\n",
       " 'UE 033 273',\n",
       " 'UF 050 407',\n",
       " 'UF 066 434',\n",
       " 'UF 199 505 520 01',\n",
       " 'UG 033 206',\n",
       " 'UL 033 289'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDs of studies through which students are enrolled in courses and examx, but\n",
    "# which are not recorded in the student table. \n",
    "study_IDs = set(enrollment['study_id'])\n",
    "diff = set(study_IDs).difference(students[\"study_id\"])\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a number of studies through which students are either enrolled in courses or\n",
    "# exams are not contained in the student table. Therefore the name of the study\n",
    "# is missing and we have just the ID. We manually searched for the names of \n",
    "# these studies and add them to the student table here. Since we don't know the \n",
    "# term numbers for the students in these studies, we set them to NaN. \n",
    "missing_studies = enrollment[enrollment['study_id'].isin(diff)]\\\n",
    "    .drop_duplicates(subset=['study_id'])\\\n",
    "    .drop(columns=['course_id', 'group_id'])\n",
    "\n",
    "# manually searched study names\n",
    "missing_studies_names = {\n",
    "    'PH 198 400 420 01':'Lehramtsstudium; UF Bewegung und Sport; UF Mathematik',\n",
    "    'PH 198 404 426 01':'Lehramtsstudium; UF Chemie; UF Russisch',\n",
    "    'UB 032 331 342':'Bachelorstudium; Transkulturelle Kommunikation, Deutsch',\n",
    "    'UB 190 406 344':'Lehramtsstudium; UF Mathematik; UF Englisch',\n",
    "    'UB 190 406 347':'Lehramtsstudium; UF Mathematik; UF Französisch',\n",
    "    'UB 190 406 482':'Lehramtsstudium; UF Mathematik; UF Bewegung und Sport',\n",
    "    'UB 190 445 313':'Lehramtsstudium; UF Biologie und Umweltkunde; UF Geschichte, Sozialkunde, Polit.Bildg.',\n",
    "    'UB 190 445 412':'Lehramtsstudium; UF Biologie und Umweltkunde; UF Physik',\n",
    "    'UB 190 456 445':'Lehramtsstudium; UF Geographie und Wirtschaftskunde; UF Biologie und Umweltkunde',\n",
    "    'UB 198 411 435 01':'Lehramtsstudium; UF Geschichte/Sozialkunde/Polit. Bildung; UF Gestaltung: Technik.Textil',\n",
    "    'UB 198 423 429 01':'Lehramtsstudium; UF Physik; UF Spanisch',\n",
    "    'UB 199 514 520 01':'Lehramtsstudium; UF Informatik; UF Mathematik',\n",
    "    'UB 796 600 682':'Doktoratsstudium; Naturwissenschaften a.d. Naturwiss. Fak.; Physics',\n",
    "    'UE 033 273':'Bachelorstudium; Verfahrenstechnik',\n",
    "    'UF 050 407':'Erweiterungsstudium; UF Darstellende Geometrie',\n",
    "    'UF 066 434':'Masterstudium; Advanced Materials Science',\n",
    "    'UF 199 505 520 01':'Masterstudium; Lehramt Sek (AB) UF Darstellende Geometrie UF Mathematik',\n",
    "    'UG 033 206':'Bachelorstudium; Angewandte Geowissenschaften',\n",
    "    'UL 033 289':'Bachelorstudium; Informationstechnik'\n",
    "}\n",
    "missing_studies['study_name'] = missing_studies['study_id'].replace(missing_studies_names)\n",
    "missing_studies['term_number'] = np.nan\n",
    "\n",
    "# add missing studies to the study df and ensure that all studies of all students\n",
    "# are now contained in both the students and the studies df\n",
    "students = pd.concat([students, missing_studies]).reset_index(drop=True)\n",
    "assert len(study_IDs.difference(set(students['study_id']))) == 0\n",
    "del missing_studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
